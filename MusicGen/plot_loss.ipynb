{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = '''\n",
    "Epoch: 0/100, Batch: 0/143, Loss: 21.257972717285156\n",
    "Epoch: 0/100, Batch: 1/143, Loss: 35.611637115478516\n",
    "Current step: 1.0\n",
    "Epoch: 0/100, Batch: 2/143, Loss: 21.706836700439453\n",
    "Epoch: 0/100, Batch: 3/143, Loss: 21.800052642822266\n",
    "Current step: 2.0\n",
    "Epoch: 0/100, Batch: 4/143, Loss: 36.35921859741211\n",
    "Epoch: 0/100, Batch: 5/143, Loss: 21.442773818969727\n",
    "Current step: 3.0\n",
    "Epoch: 0/100, Batch: 6/143, Loss: 26.695199966430664\n",
    "Epoch: 0/100, Batch: 7/143, Loss: 36.1571159362793\n",
    "Current step: 4.0\n",
    "Epoch: 0/100, Batch: 8/143, Loss: 22.545360565185547\n",
    "Epoch: 0/100, Batch: 9/143, Loss: 34.185081481933594\n",
    "Current step: 5.0\n",
    "Epoch: 0/100, Batch: 10/143, Loss: 37.76951217651367\n",
    "Epoch: 0/100, Batch: 11/143, Loss: 34.78163146972656\n",
    "Current step: 6.0\n",
    "Epoch: 0/100, Batch: 12/143, Loss: 15.614236831665039\n",
    "Epoch: 0/100, Batch: 13/143, Loss: 15.888457298278809\n",
    "Current step: 7.0\n",
    "Epoch: 0/100, Batch: 14/143, Loss: 7.014136791229248\n",
    "Epoch: 0/100, Batch: 15/143, Loss: 6.990067481994629\n",
    "Current step: 8.0\n",
    "Epoch: 0/100, Batch: 16/143, Loss: 4.730969429016113\n",
    "Epoch: 0/100, Batch: 17/143, Loss: 9.78073787689209\n",
    "Current step: 9.0\n",
    "Epoch: 0/100, Batch: 18/143, Loss: 4.546058177947998\n",
    "Epoch: 0/100, Batch: 19/143, Loss: 6.152279853820801\n",
    "Current step: 10.0\n",
    "Epoch: 0/100, Batch: 20/143, Loss: 5.354976654052734\n",
    "Epoch: 0/100, Batch: 21/143, Loss: 5.126471996307373\n",
    "Current step: 11.0\n",
    "Epoch: 0/100, Batch: 22/143, Loss: 4.0301361083984375\n",
    "Epoch: 0/100, Batch: 23/143, Loss: 3.9492533206939697\n",
    "Current step: 12.0\n",
    "Epoch: 0/100, Batch: 24/143, Loss: 3.309458017349243\n",
    "Epoch: 0/100, Batch: 25/143, Loss: 2.785646438598633\n",
    "Current step: 13.0\n",
    "Epoch: 0/100, Batch: 26/143, Loss: 2.513470411300659\n",
    "Epoch: 0/100, Batch: 27/143, Loss: 2.5093436241149902\n",
    "Current step: 14.0\n",
    "Epoch: 0/100, Batch: 28/143, Loss: 1.9444966316223145\n",
    "Epoch: 0/100, Batch: 29/143, Loss: 1.935141682624817\n",
    "Current step: 15.0\n",
    "Epoch: 0/100, Batch: 30/143, Loss: 1.4531035423278809\n",
    "Epoch: 0/100, Batch: 31/143, Loss: 1.4509034156799316\n",
    "Current step: 16.0\n",
    "Epoch: 0/100, Batch: 32/143, Loss: 0.9654436707496643\n",
    "Epoch: 0/100, Batch: 33/143, Loss: 0.9714025855064392\n",
    "Current step: 17.0\n",
    "Epoch: 0/100, Batch: 34/143, Loss: 0.6935701966285706\n",
    "Epoch: 0/100, Batch: 35/143, Loss: 0.7120859622955322\n",
    "Current step: 18.0\n",
    "Epoch: 0/100, Batch: 36/143, Loss: 0.5893391966819763\n",
    "Epoch: 0/100, Batch: 37/143, Loss: 0.5918563604354858\n",
    "Current step: 19.0\n",
    "Epoch: 0/100, Batch: 38/143, Loss: 0.9336786270141602\n",
    "Epoch: 0/100, Batch: 39/143, Loss: 1.062097430229187\n",
    "Current step: 20.0\n",
    "Epoch: 0/100, Batch: 40/143, Loss: 0.4394150972366333\n",
    "Epoch: 0/100, Batch: 41/143, Loss: 0.6223888397216797\n",
    "Current step: 21.0\n",
    "Epoch: 0/100, Batch: 42/143, Loss: 0.633198618888855\n",
    "Epoch: 0/100, Batch: 43/143, Loss: 0.6343699097633362\n",
    "Current step: 22.0\n",
    "Epoch: 0/100, Batch: 44/143, Loss: 0.5027183294296265\n",
    "Epoch: 0/100, Batch: 45/143, Loss: 0.7199493646621704\n",
    "Current step: 23.0\n",
    "Epoch: 0/100, Batch: 46/143, Loss: 0.5286459922790527\n",
    "Epoch: 0/100, Batch: 47/143, Loss: 0.41377270221710205\n",
    "Current step: 24.0\n",
    "Epoch: 0/100, Batch: 48/143, Loss: 1.0095540285110474\n",
    "Epoch: 0/100, Batch: 49/143, Loss: 1.0279070138931274\n",
    "Current step: 25.0\n",
    "Epoch: 0/100, Batch: 50/143, Loss: 0.9976438283920288\n",
    "Epoch: 0/100, Batch: 51/143, Loss: 0.5665835738182068\n",
    "Current step: 26.0\n",
    "Epoch: 0/100, Batch: 52/143, Loss: 0.38909712433815\n",
    "Epoch: 0/100, Batch: 53/143, Loss: 0.6671620607376099\n",
    "Current step: 27.0\n",
    "Epoch: 0/100, Batch: 54/143, Loss: 0.2885938882827759\n",
    "Epoch: 0/100, Batch: 55/143, Loss: 0.28524765372276306\n",
    "Current step: 28.0\n",
    "Epoch: 0/100, Batch: 56/143, Loss: 0.4310549199581146\n",
    "Epoch: 0/100, Batch: 57/143, Loss: 0.46405676007270813\n",
    "Current step: 29.0\n",
    "Epoch: 0/100, Batch: 58/143, Loss: 0.7243091464042664\n",
    "Epoch: 0/100, Batch: 59/143, Loss: 0.7213947176933289\n",
    "Current step: 30.0\n",
    "Epoch: 0/100, Batch: 60/143, Loss: 0.6439153552055359\n",
    "Epoch: 0/100, Batch: 61/143, Loss: 0.6546884775161743\n",
    "Current step: 31.0\n",
    "Epoch: 0/100, Batch: 62/143, Loss: 0.3801010251045227\n",
    "Epoch: 0/100, Batch: 63/143, Loss: 0.385773241519928\n",
    "Current step: 32.0\n",
    "Epoch: 0/100, Batch: 64/143, Loss: 0.1976897418498993\n",
    "Epoch: 0/100, Batch: 65/143, Loss: 0.19853456318378448\n",
    "Current step: 33.0\n",
    "Epoch: 0/100, Batch: 66/143, Loss: 0.5563176274299622\n",
    "Epoch: 0/100, Batch: 67/143, Loss: 0.55499267578125\n",
    "Current step: 34.0\n",
    "Epoch: 0/100, Batch: 68/143, Loss: 0.5042729377746582\n",
    "Epoch: 0/100, Batch: 69/143, Loss: 0.8149397969245911\n",
    "Current step: 35.0\n",
    "Epoch: 0/100, Batch: 70/143, Loss: 0.569019079208374\n",
    "Epoch: 0/100, Batch: 71/143, Loss: 0.5810320377349854\n",
    "Current step: 36.0\n",
    "Epoch: 0/100, Batch: 72/143, Loss: 0.4780985414981842\n",
    "Epoch: 0/100, Batch: 73/143, Loss: 0.4093693494796753\n",
    "Current step: 37.0\n",
    "Epoch: 0/100, Batch: 74/143, Loss: 0.1969561129808426\n",
    "Epoch: 0/100, Batch: 75/143, Loss: 0.1988312155008316\n",
    "Current step: 38.0\n",
    "Epoch: 0/100, Batch: 76/143, Loss: 0.2170933037996292\n",
    "Epoch: 0/100, Batch: 77/143, Loss: 0.22183291614055634\n",
    "Current step: 39.0\n",
    "Epoch: 0/100, Batch: 78/143, Loss: 0.3711387515068054\n",
    "Epoch: 0/100, Batch: 79/143, Loss: 0.2266392856836319\n",
    "Current step: 40.0\n",
    "Epoch: 0/100, Batch: 80/143, Loss: 0.32817038893699646\n",
    "Epoch: 0/100, Batch: 81/143, Loss: 0.19171226024627686\n",
    "Current step: 41.0\n",
    "Epoch: 0/100, Batch: 82/143, Loss: 0.2534823715686798\n",
    "Epoch: 0/100, Batch: 83/143, Loss: 0.12996521592140198\n",
    "Current step: 42.0\n",
    "Epoch: 0/100, Batch: 84/143, Loss: 0.17335882782936096\n",
    "Epoch: 0/100, Batch: 85/143, Loss: 0.1742432415485382\n",
    "Current step: 43.0\n",
    "Epoch: 0/100, Batch: 86/143, Loss: 0.15814080834388733\n",
    "Epoch: 0/100, Batch: 87/143, Loss: 0.16180528700351715\n",
    "Current step: 44.0\n",
    "Epoch: 0/100, Batch: 88/143, Loss: 0.9176130890846252\n",
    "Epoch: 0/100, Batch: 89/143, Loss: 0.17997729778289795\n",
    "Current step: 45.0\n",
    "Epoch: 0/100, Batch: 90/143, Loss: 0.13261324167251587\n",
    "Epoch: 0/100, Batch: 91/143, Loss: 0.13271257281303406\n",
    "Current step: 46.0\n",
    "Epoch: 0/100, Batch: 92/143, Loss: 1.0310670137405396\n",
    "Epoch: 0/100, Batch: 93/143, Loss: 1.0340449810028076\n",
    "Current step: 47.0\n",
    "Epoch: 0/100, Batch: 94/143, Loss: 0.6920337677001953\n",
    "Epoch: 0/100, Batch: 95/143, Loss: 0.14232885837554932\n",
    "Current step: 48.0\n",
    "Epoch: 0/100, Batch: 96/143, Loss: 0.6125408411026001\n",
    "Epoch: 0/100, Batch: 97/143, Loss: 0.22343547642230988\n",
    "Current step: 49.0\n",
    "Epoch: 0/100, Batch: 98/143, Loss: 0.16352201998233795\n",
    "Epoch: 0/100, Batch: 99/143, Loss: 0.1615392118692398\n",
    "Current step: 50.0\n",
    "Epoch: 0/100, Batch: 100/143, Loss: 0.0907825157046318\n",
    "Epoch: 0/100, Batch: 101/143, Loss: 0.09019549936056137\n",
    "Current step: 51.0\n",
    "Epoch: 0/100, Batch: 102/143, Loss: 1.2277759313583374\n",
    "Epoch: 0/100, Batch: 103/143, Loss: 1.3325902223587036\n",
    "Current step: 52.0\n",
    "Epoch: 0/100, Batch: 104/143, Loss: 0.1479998081922531\n",
    "Epoch: 0/100, Batch: 105/143, Loss: 1.230489730834961\n",
    "Current step: 53.0\n",
    "Epoch: 0/100, Batch: 106/143, Loss: 0.16343048214912415\n",
    "Epoch: 0/100, Batch: 107/143, Loss: 0.1634712666273117\n",
    "Current step: 54.0\n",
    "Epoch: 0/100, Batch: 108/143, Loss: 0.11775608360767365\n",
    "Epoch: 0/100, Batch: 109/143, Loss: 0.12036265432834625\n",
    "Current step: 55.0\n",
    "Epoch: 0/100, Batch: 110/143, Loss: 0.2502058744430542\n",
    "Epoch: 0/100, Batch: 111/143, Loss: 0.09177916496992111\n",
    "Current step: 56.0\n",
    "Epoch: 0/100, Batch: 112/143, Loss: 0.11300322413444519\n",
    "Epoch: 0/100, Batch: 113/143, Loss: 0.09785839915275574\n",
    "Current step: 57.0\n",
    "Epoch: 0/100, Batch: 114/143, Loss: 0.08441813290119171\n",
    "Epoch: 0/100, Batch: 115/143, Loss: 0.07720745354890823\n",
    "Current step: 58.0\n",
    "Epoch: 0/100, Batch: 116/143, Loss: 0.12344536930322647\n",
    "Epoch: 0/100, Batch: 117/143, Loss: 0.07322027534246445\n",
    "Current step: 59.0\n",
    "Epoch: 0/100, Batch: 118/143, Loss: 0.12459629774093628\n",
    "Epoch: 0/100, Batch: 119/143, Loss: 0.12281522899866104\n",
    "Current step: 60.0\n",
    "Epoch: 0/100, Batch: 120/143, Loss: 0.0727171078324318\n",
    "Epoch: 0/100, Batch: 121/143, Loss: 0.07531094551086426\n",
    "Current step: 61.0\n",
    "Epoch: 0/100, Batch: 122/143, Loss: 0.06298938393592834\n",
    "Epoch: 0/100, Batch: 123/143, Loss: 0.06315366923809052\n",
    "Current step: 62.0\n",
    "Epoch: 0/100, Batch: 124/143, Loss: 0.07600709050893784\n",
    "Epoch: 0/100, Batch: 125/143, Loss: 0.07749678194522858\n",
    "Current step: 63.0\n",
    "Epoch: 0/100, Batch: 126/143, Loss: 0.05019904300570488\n",
    "Epoch: 0/100, Batch: 127/143, Loss: 0.052612997591495514\n",
    "Current step: 64.0\n",
    "Epoch: 0/100, Batch: 128/143, Loss: 0.03703340142965317\n",
    "Epoch: 0/100, Batch: 129/143, Loss: 0.037097908556461334\n",
    "Current step: 65.0\n",
    "Epoch: 0/100, Batch: 130/143, Loss: 0.05018744617700577\n",
    "Epoch: 0/100, Batch: 131/143, Loss: 0.05097801238298416\n",
    "Current step: 66.0\n",
    "Epoch: 0/100, Batch: 132/143, Loss: 0.06837425380945206\n",
    "Epoch: 0/100, Batch: 133/143, Loss: 0.06700004637241364\n",
    "Current step: 67.0\n",
    "Epoch: 0/100, Batch: 134/143, Loss: 0.2344367951154709\n",
    "Epoch: 0/100, Batch: 135/143, Loss: 0.04591657966375351\n",
    "Current step: 68.0\n",
    "Epoch: 0/100, Batch: 136/143, Loss: 0.026860946789383888\n",
    "Epoch: 0/100, Batch: 137/143, Loss: 0.027016915380954742\n",
    "Current step: 69.0\n",
    "Epoch: 0/100, Batch: 138/143, Loss: 0.029522137716412544\n",
    "Epoch: 0/100, Batch: 139/143, Loss: 0.1678307056427002\n",
    "Current step: 70.0\n",
    "Epoch: 0/100, Batch: 140/143, Loss: 0.06167437508702278\n",
    "Epoch: 0/100, Batch: 141/143, Loss: 0.09691309928894043\n",
    "Current step: 71.0\n",
    "Epoch: 0/100, Batch: 142/143, Loss: 0.03408179432153702\n",
    "Epoch: 1/100, Batch: 0/143, Loss: 0.03357149660587311\n",
    "Epoch: 1/100, Batch: 1/143, Loss: 0.03458099067211151\n",
    "Current step: 72.5\n",
    "Epoch: 1/100, Batch: 2/143, Loss: 0.08758803457021713\n",
    "Epoch: 1/100, Batch: 3/143, Loss: 0.3685360252857208\n",
    "Current step: 73.5\n",
    "Epoch: 1/100, Batch: 4/143, Loss: 0.19161199033260345\n",
    "Epoch: 1/100, Batch: 5/143, Loss: 0.48835039138793945\n",
    "Current step: 74.5\n",
    "Epoch: 1/100, Batch: 6/143, Loss: 0.22026963531970978\n",
    "Epoch: 1/100, Batch: 7/143, Loss: 0.3945137560367584\n",
    "Current step: 75.5\n",
    "Epoch: 1/100, Batch: 8/143, Loss: 0.24274082481861115\n",
    "Epoch: 1/100, Batch: 9/143, Loss: 0.19001471996307373\n",
    "Current step: 76.5\n",
    "Epoch: 1/100, Batch: 10/143, Loss: 0.11227892339229584\n",
    "Epoch: 1/100, Batch: 11/143, Loss: 0.1014869287610054\n",
    "Current step: 77.5\n",
    "Epoch: 1/100, Batch: 12/143, Loss: 0.07955038547515869\n",
    "Epoch: 1/100, Batch: 13/143, Loss: 0.04700420796871185\n",
    "Current step: 78.5\n",
    "Epoch: 1/100, Batch: 14/143, Loss: 0.08785226941108704\n",
    "Epoch: 1/100, Batch: 15/143, Loss: 0.07370555400848389\n",
    "Current step: 79.5\n",
    "Epoch: 1/100, Batch: 16/143, Loss: 0.10921623557806015\n",
    "Epoch: 1/100, Batch: 17/143, Loss: 0.10794811695814133\n",
    "Current step: 80.5\n",
    "Epoch: 1/100, Batch: 18/143, Loss: 0.06467406451702118\n",
    "Epoch: 1/100, Batch: 19/143, Loss: 0.0852159634232521\n",
    "Current step: 81.5\n",
    "Epoch: 1/100, Batch: 20/143, Loss: 0.04676610603928566\n",
    "Epoch: 1/100, Batch: 21/143, Loss: 0.04717804864048958\n",
    "Current step: 82.5\n",
    "Epoch: 1/100, Batch: 22/143, Loss: 0.05068983510136604\n",
    "Epoch: 1/100, Batch: 23/143, Loss: 0.05237460881471634\n",
    "Current step: 83.5\n",
    "Epoch: 1/100, Batch: 24/143, Loss: 0.07350849360227585\n",
    "Epoch: 1/100, Batch: 25/143, Loss: 0.07426567375659943\n",
    "Current step: 84.5\n",
    "Epoch: 1/100, Batch: 26/143, Loss: 0.07237850874662399\n",
    "Epoch: 1/100, Batch: 27/143, Loss: 0.07334005832672119\n",
    "Current step: 85.5\n",
    "Epoch: 1/100, Batch: 28/143, Loss: 0.03719643875956535\n",
    "Epoch: 1/100, Batch: 29/143, Loss: 0.03652923181653023\n",
    "Current step: 86.5\n",
    "Epoch: 1/100, Batch: 30/143, Loss: 0.02186608500778675\n",
    "Epoch: 1/100, Batch: 31/143, Loss: 0.022082822397351265\n",
    "Current step: 87.5\n",
    "Epoch: 1/100, Batch: 32/143, Loss: 0.07630233466625214\n",
    "Epoch: 1/100, Batch: 33/143, Loss: 0.0774058848619461\n",
    "Current step: 88.5\n",
    "Epoch: 1/100, Batch: 34/143, Loss: 0.02706124633550644\n",
    "Epoch: 1/100, Batch: 35/143, Loss: 0.06494566053152084\n",
    "Current step: 89.5\n",
    "Epoch: 1/100, Batch: 36/143, Loss: 0.020964184775948524\n",
    "Epoch: 1/100, Batch: 37/143, Loss: 0.02098061330616474\n",
    "Current step: 90.5\n",
    "Epoch: 1/100, Batch: 38/143, Loss: 0.02473311498761177\n",
    "Epoch: 1/100, Batch: 39/143, Loss: 0.02497311308979988\n",
    "Current step: 91.5\n",
    "Epoch: 1/100, Batch: 40/143, Loss: 0.02853982150554657\n",
    "Epoch: 1/100, Batch: 41/143, Loss: 0.028320368379354477\n",
    "Current step: 92.5\n",
    "Epoch: 1/100, Batch: 42/143, Loss: 0.01664087362587452\n",
    "Epoch: 1/100, Batch: 43/143, Loss: 0.016641277819871902\n",
    "Current step: 93.5\n",
    "Epoch: 1/100, Batch: 44/143, Loss: 0.026904882863163948\n",
    "Epoch: 1/100, Batch: 45/143, Loss: 0.02161499857902527\n",
    "Current step: 94.5\n",
    "Epoch: 1/100, Batch: 46/143, Loss: 0.02878093719482422\n",
    "Epoch: 1/100, Batch: 47/143, Loss: 0.02474602498114109\n",
    "Current step: 95.5\n",
    "Epoch: 1/100, Batch: 48/143, Loss: 0.04269026964902878\n",
    "Epoch: 1/100, Batch: 49/143, Loss: 0.017097584903240204\n",
    "Current step: 96.5\n",
    "Epoch: 1/100, Batch: 50/143, Loss: 0.01626334711909294\n",
    "Epoch: 1/100, Batch: 51/143, Loss: 0.014466900378465652\n",
    "Current step: 97.5\n",
    "Epoch: 1/100, Batch: 52/143, Loss: 0.0216099563986063\n",
    "Epoch: 1/100, Batch: 53/143, Loss: 0.02132297120988369\n",
    "Current step: 98.5\n",
    "Epoch: 1/100, Batch: 54/143, Loss: 0.013569523580372334\n",
    "Epoch: 1/100, Batch: 55/143, Loss: 0.01322400663048029\n",
    "Current step: 99.5\n",
    "Epoch: 1/100, Batch: 56/143, Loss: 0.014393605291843414\n",
    "Epoch: 1/100, Batch: 57/143, Loss: 0.01690666750073433\n",
    "Current step: 100.5\n",
    "Epoch: 1/100, Batch: 58/143, Loss: 0.06615379452705383\n",
    "Epoch: 1/100, Batch: 59/143, Loss: 0.022433597594499588\n",
    "Current step: 101.5\n",
    "Epoch: 1/100, Batch: 60/143, Loss: 0.0944768413901329\n",
    "Epoch: 1/100, Batch: 61/143, Loss: 0.012854453176259995\n",
    "Current step: 102.5\n",
    "Epoch: 1/100, Batch: 62/143, Loss: 0.016041945666074753\n",
    "Epoch: 1/100, Batch: 63/143, Loss: 0.015488820150494576\n",
    "Current step: 103.5\n",
    "Epoch: 1/100, Batch: 64/143, Loss: 0.2143527865409851\n",
    "Epoch: 1/100, Batch: 65/143, Loss: 0.023270484060049057\n",
    "Current step: 104.5\n",
    "Epoch: 1/100, Batch: 66/143, Loss: 0.014075072482228279\n",
    "Epoch: 1/100, Batch: 67/143, Loss: 0.18408918380737305\n",
    "Current step: 105.5\n",
    "Epoch: 1/100, Batch: 68/143, Loss: 0.09750941395759583\n",
    "Epoch: 1/100, Batch: 69/143, Loss: 0.010594976134598255\n",
    "Current step: 106.5\n",
    "Epoch: 1/100, Batch: 70/143, Loss: 0.012189068831503391\n",
    "Epoch: 1/100, Batch: 71/143, Loss: 0.011903436854481697\n",
    "Current step: 107.5\n",
    "Epoch: 1/100, Batch: 72/143, Loss: 0.008046071976423264\n",
    "Epoch: 1/100, Batch: 73/143, Loss: 0.008069121278822422\n",
    "Current step: 108.5\n",
    "Epoch: 1/100, Batch: 74/143, Loss: 0.007270321249961853\n",
    "Epoch: 1/100, Batch: 75/143, Loss: 0.00830691959708929\n",
    "Current step: 109.5\n",
    "Epoch: 1/100, Batch: 76/143, Loss: 0.00916079431772232\n",
    "Epoch: 1/100, Batch: 77/143, Loss: 0.050296150147914886\n",
    "Current step: 110.5\n",
    "Epoch: 1/100, Batch: 78/143, Loss: 0.03178151696920395\n",
    "Epoch: 1/100, Batch: 79/143, Loss: 0.030478617176413536\n",
    "Current step: 111.5\n",
    "Epoch: 1/100, Batch: 80/143, Loss: 0.038990091532468796\n",
    "Epoch: 1/100, Batch: 81/143, Loss: 0.03951501473784447\n",
    "Current step: 112.5\n",
    "Epoch: 1/100, Batch: 82/143, Loss: 0.019129516556859016\n",
    "Epoch: 1/100, Batch: 83/143, Loss: 0.027510512620210648\n",
    "Current step: 113.5\n",
    "Epoch: 1/100, Batch: 84/143, Loss: 0.011278129182755947\n",
    "Epoch: 1/100, Batch: 85/143, Loss: 0.01123388484120369\n",
    "Current step: 114.5\n",
    "Epoch: 1/100, Batch: 86/143, Loss: 0.013391321524977684\n",
    "Epoch: 1/100, Batch: 87/143, Loss: 0.013626521453261375\n",
    "Current step: 115.5\n",
    "Epoch: 1/100, Batch: 88/143, Loss: 0.012151900678873062\n",
    "Epoch: 1/100, Batch: 89/143, Loss: 0.012271551415324211\n",
    "Current step: 116.5\n",
    "Epoch: 1/100, Batch: 90/143, Loss: 0.02100655995309353\n",
    "Epoch: 1/100, Batch: 91/143, Loss: 0.018691066652536392\n",
    "Current step: 117.5\n",
    "Epoch: 1/100, Batch: 92/143, Loss: 0.013012073934078217\n",
    "Epoch: 1/100, Batch: 93/143, Loss: 0.013115303590893745\n",
    "Current step: 118.5\n",
    "Epoch: 1/100, Batch: 94/143, Loss: 0.009005982428789139\n",
    "Epoch: 1/100, Batch: 95/143, Loss: 0.008451083675026894\n",
    "Current step: 119.5\n",
    "Epoch: 1/100, Batch: 96/143, Loss: 0.070442333817482\n",
    "Epoch: 1/100, Batch: 97/143, Loss: 0.07043026387691498\n",
    "Current step: 120.5\n",
    "Epoch: 1/100, Batch: 98/143, Loss: 0.08085717260837555\n",
    "Epoch: 1/100, Batch: 99/143, Loss: 0.012524951249361038\n",
    "Current step: 121.5\n",
    "Epoch: 1/100, Batch: 100/143, Loss: 0.011130976490676403\n",
    "Epoch: 1/100, Batch: 101/143, Loss: 0.0697527602314949\n",
    "Current step: 122.5\n",
    "Epoch: 1/100, Batch: 102/143, Loss: 0.031217899173498154\n",
    "Epoch: 1/100, Batch: 103/143, Loss: 0.031198587268590927\n",
    "Current step: 123.5\n",
    "Epoch: 1/100, Batch: 104/143, Loss: 0.03979529067873955\n",
    "Epoch: 1/100, Batch: 105/143, Loss: 0.038790784776210785\n",
    "Current step: 124.5\n",
    "Epoch: 1/100, Batch: 106/143, Loss: 0.024179402738809586\n",
    "Epoch: 1/100, Batch: 107/143, Loss: 0.02434765174984932\n",
    "Current step: 125.5\n",
    "Epoch: 1/100, Batch: 108/143, Loss: 0.01194292213767767\n",
    "Epoch: 1/100, Batch: 109/143, Loss: 0.01170993410050869\n",
    "Current step: 126.5\n",
    "Epoch: 1/100, Batch: 110/143, Loss: 0.014981523156166077\n",
    "Epoch: 1/100, Batch: 111/143, Loss: 0.014758077450096607\n",
    "Current step: 127.5\n",
    "Epoch: 1/100, Batch: 112/143, Loss: 0.017261946573853493\n",
    "Epoch: 1/100, Batch: 113/143, Loss: 0.045515742152929306\n",
    "Current step: 128.5\n",
    "Epoch: 1/100, Batch: 114/143, Loss: 0.03521403670310974\n",
    "Epoch: 1/100, Batch: 115/143, Loss: 0.03551749885082245\n",
    "Current step: 129.5\n",
    "Epoch: 1/100, Batch: 116/143, Loss: 0.027383005246520042\n",
    "Epoch: 1/100, Batch: 117/143, Loss: 0.0222025066614151\n",
    "Current step: 130.5\n",
    "Epoch: 1/100, Batch: 118/143, Loss: 0.03263671323657036\n",
    "Epoch: 1/100, Batch: 119/143, Loss: 0.017682135105133057\n",
    "Current step: 131.5\n",
    "Epoch: 1/100, Batch: 120/143, Loss: 0.034423455595970154\n",
    "Epoch: 1/100, Batch: 121/143, Loss: 0.007392726372927427\n",
    "Current step: 132.5\n",
    "Epoch: 1/100, Batch: 122/143, Loss: 0.015397338196635246\n",
    "Epoch: 1/100, Batch: 123/143, Loss: 0.016465961933135986\n",
    "Current step: 133.5\n",
    "Epoch: 1/100, Batch: 124/143, Loss: 0.022393709048628807\n",
    "Epoch: 1/100, Batch: 125/143, Loss: 0.021955672651529312\n",
    "Current step: 134.5\n",
    "Epoch: 1/100, Batch: 126/143, Loss: 0.09205761551856995\n",
    "Epoch: 1/100, Batch: 127/143, Loss: 0.01437272597104311\n",
    "Current step: 135.5\n",
    "Epoch: 1/100, Batch: 128/143, Loss: 0.1639489382505417\n",
    "Epoch: 1/100, Batch: 129/143, Loss: 0.01552500855177641\n",
    "Current step: 136.5\n",
    "Epoch: 1/100, Batch: 130/143, Loss: 0.01866246573626995\n",
    "Epoch: 1/100, Batch: 131/143, Loss: 0.018801873549818993\n",
    "Current step: 137.5\n",
    "Epoch: 1/100, Batch: 132/143, Loss: 0.010818189941346645\n",
    "Epoch: 1/100, Batch: 133/143, Loss: 0.18581484258174896\n",
    "Current step: 138.5\n",
    "Epoch: 1/100, Batch: 134/143, Loss: 0.01116001233458519\n",
    "Epoch: 1/100, Batch: 135/143, Loss: 0.008402423933148384\n",
    "Current step: 139.5\n",
    "Epoch: 1/100, Batch: 136/143, Loss: 0.013577291741967201\n",
    "Epoch: 1/100, Batch: 137/143, Loss: 0.012023134157061577\n",
    "Current step: 140.5\n",
    "Epoch: 1/100, Batch: 138/143, Loss: 0.006617147009819746\n",
    "Epoch: 1/100, Batch: 139/143, Loss: 0.00623888848349452\n",
    "Current step: 141.5\n",
    "Epoch: 1/100, Batch: 140/143, Loss: 0.011483018286526203\n",
    "Epoch: 1/100, Batch: 141/143, Loss: 0.011410682462155819\n",
    "Current step: 142.5\n",
    "Epoch: 1/100, Batch: 142/143, Loss: 0.015256664715707302\n",
    "Epoch: 2/100, Batch: 0/143, Loss: 0.01546813640743494\n",
    "Epoch: 2/100, Batch: 1/143, Loss: 0.01567099615931511\n",
    "Current step: 144.0\n",
    "Epoch: 2/100, Batch: 2/143, Loss: 0.011619784869253635\n",
    "Epoch: 2/100, Batch: 3/143, Loss: 0.15193501114845276\n",
    "Current step: 145.0\n",
    "Epoch: 2/100, Batch: 4/143, Loss: 0.020648697391152382\n",
    "Epoch: 2/100, Batch: 5/143, Loss: 0.020512660965323448\n",
    "Current step: 146.0\n",
    "Epoch: 2/100, Batch: 6/143, Loss: 0.02468539960682392\n",
    "Epoch: 2/100, Batch: 7/143, Loss: 0.02511146478354931\n",
    "Current step: 147.0\n",
    "Epoch: 2/100, Batch: 8/143, Loss: 0.01505105197429657\n",
    "Epoch: 2/100, Batch: 9/143, Loss: 0.04432864487171173\n",
    "Current step: 148.0\n",
    "Epoch: 2/100, Batch: 10/143, Loss: 0.022143471986055374\n",
    "Epoch: 2/100, Batch: 11/143, Loss: 0.016644056886434555\n",
    "Current step: 149.0\n",
    "Epoch: 2/100, Batch: 12/143, Loss: 0.048035360872745514\n",
    "Epoch: 2/100, Batch: 13/143, Loss: 0.05035490542650223\n",
    "Current step: 150.0\n",
    "Epoch: 2/100, Batch: 14/143, Loss: 0.05787845700979233\n",
    "Epoch: 2/100, Batch: 15/143, Loss: 0.032466307282447815\n",
    "Current step: 151.0\n",
    "Epoch: 2/100, Batch: 16/143, Loss: 0.05274214595556259\n",
    "Epoch: 2/100, Batch: 17/143, Loss: 0.04987368732690811\n",
    "Current step: 152.0\n",
    "Epoch: 2/100, Batch: 18/143, Loss: 0.026345841586589813\n",
    "Epoch: 2/100, Batch: 19/143, Loss: 0.03022262081503868\n",
    "Current step: 153.0\n",
    "Epoch: 2/100, Batch: 20/143, Loss: 0.011371508240699768\n",
    "Epoch: 2/100, Batch: 21/143, Loss: 0.011090988293290138\n",
    "Current step: 154.0\n",
    "Epoch: 2/100, Batch: 22/143, Loss: 0.014550169929862022\n",
    "Epoch: 2/100, Batch: 23/143, Loss: 0.014726785942912102\n",
    "Current step: 155.0\n",
    "Epoch: 2/100, Batch: 24/143, Loss: 0.02617361955344677\n",
    "Epoch: 2/100, Batch: 25/143, Loss: 0.052998218685388565\n",
    "Current step: 156.0\n",
    "Epoch: 2/100, Batch: 26/143, Loss: 0.04680684953927994\n",
    "Epoch: 2/100, Batch: 27/143, Loss: 0.03573012351989746\n",
    "Current step: 157.0\n",
    "Epoch: 2/100, Batch: 28/143, Loss: 0.07278542965650558\n",
    "Epoch: 2/100, Batch: 29/143, Loss: 0.07389175146818161\n",
    "Current step: 158.0\n",
    "Epoch: 2/100, Batch: 30/143, Loss: 0.08264242112636566\n",
    "Epoch: 2/100, Batch: 31/143, Loss: 0.0827721431851387\n",
    "Current step: 159.0\n",
    "Epoch: 2/100, Batch: 32/143, Loss: 0.0657443031668663\n",
    "Epoch: 2/100, Batch: 33/143, Loss: 0.06700355559587479\n",
    "Current step: 160.0\n",
    "Epoch: 2/100, Batch: 34/143, Loss: 0.040464796125888824\n",
    "Epoch: 2/100, Batch: 35/143, Loss: 0.04033457115292549\n",
    "Current step: 161.0\n",
    "Epoch: 2/100, Batch: 36/143, Loss: 0.029187653213739395\n",
    "Epoch: 2/100, Batch: 37/143, Loss: 0.029434209689497948\n",
    "Current step: 162.0\n",
    "Epoch: 2/100, Batch: 38/143, Loss: 0.03809850290417671\n",
    "Epoch: 2/100, Batch: 39/143, Loss: 0.02519446611404419\n",
    "Current step: 163.0\n",
    "Epoch: 2/100, Batch: 40/143, Loss: 0.018247824162244797\n",
    "Epoch: 2/100, Batch: 41/143, Loss: 0.018620464950799942\n",
    "Current step: 164.0\n",
    "Epoch: 2/100, Batch: 42/143, Loss: 0.01801251247525215\n",
    "Epoch: 2/100, Batch: 43/143, Loss: 0.01764751225709915\n",
    "Current step: 165.0\n",
    "Epoch: 2/100, Batch: 44/143, Loss: 0.022235415875911713\n",
    "Epoch: 2/100, Batch: 45/143, Loss: 0.02198525331914425\n",
    "Current step: 166.0\n",
    "Epoch: 2/100, Batch: 46/143, Loss: 0.01896742917597294\n",
    "Epoch: 2/100, Batch: 47/143, Loss: 0.018489008769392967\n",
    "Current step: 167.0\n",
    "Epoch: 2/100, Batch: 48/143, Loss: 0.017819566652178764\n",
    "Epoch: 2/100, Batch: 49/143, Loss: 0.11377307772636414\n",
    "Current step: 168.0\n",
    "Epoch: 2/100, Batch: 50/143, Loss: 0.06333781033754349\n",
    "Epoch: 2/100, Batch: 51/143, Loss: 0.06245237588882446\n",
    "Current step: 169.0\n",
    "Epoch: 2/100, Batch: 52/143, Loss: 0.12510979175567627\n",
    "Epoch: 2/100, Batch: 53/143, Loss: 0.043221209198236465\n",
    "Current step: 170.0\n",
    "Epoch: 2/100, Batch: 54/143, Loss: 0.04609609395265579\n",
    "Epoch: 2/100, Batch: 55/143, Loss: 0.04733387008309364\n",
    "Current step: 171.0\n",
    "Epoch: 2/100, Batch: 56/143, Loss: 0.25218456983566284\n",
    "Epoch: 2/100, Batch: 57/143, Loss: 0.25140392780303955\n",
    "Current step: 172.0\n",
    "Epoch: 2/100, Batch: 58/143, Loss: 0.03324427828192711\n",
    "Epoch: 2/100, Batch: 59/143, Loss: 0.23209413886070251\n",
    "Current step: 173.0\n",
    "Epoch: 2/100, Batch: 60/143, Loss: 0.03508302941918373\n",
    "Epoch: 2/100, Batch: 61/143, Loss: 0.17302167415618896\n",
    "Current step: 174.0\n",
    "Epoch: 2/100, Batch: 62/143, Loss: 0.11468546837568283\n",
    "Epoch: 2/100, Batch: 63/143, Loss: 0.1151183471083641\n",
    "Current step: 175.0\n",
    "Epoch: 2/100, Batch: 64/143, Loss: 0.08908302336931229\n",
    "Epoch: 2/100, Batch: 65/143, Loss: 0.08771981298923492\n",
    "Current step: 176.0\n",
    "Epoch: 2/100, Batch: 66/143, Loss: 0.20667652785778046\n",
    "Epoch: 2/100, Batch: 67/143, Loss: 0.08510564267635345\n",
    "Current step: 177.0\n",
    "Epoch: 2/100, Batch: 68/143, Loss: 0.07678468525409698\n",
    "Epoch: 2/100, Batch: 69/143, Loss: 0.254131942987442\n",
    "Current step: 178.0\n",
    "Epoch: 2/100, Batch: 70/143, Loss: 0.05833353102207184\n",
    "Epoch: 2/100, Batch: 71/143, Loss: 0.05849809572100639\n",
    "Current step: 179.0\n",
    "Epoch: 2/100, Batch: 72/143, Loss: 0.032103195786476135\n",
    "Epoch: 2/100, Batch: 73/143, Loss: 0.1382482498884201\n",
    "Current step: 180.0\n",
    "Epoch: 2/100, Batch: 74/143, Loss: 0.029651477932929993\n",
    "Epoch: 2/100, Batch: 75/143, Loss: 0.029511984437704086\n",
    "Current step: 181.0\n",
    "Epoch: 2/100, Batch: 76/143, Loss: 0.03543251380324364\n",
    "Epoch: 2/100, Batch: 77/143, Loss: 0.03704074025154114\n",
    "Current step: 182.0\n",
    "Epoch: 2/100, Batch: 78/143, Loss: 0.039787471294403076\n",
    "Epoch: 2/100, Batch: 79/143, Loss: 0.04007183015346527\n",
    "Current step: 183.0\n",
    "Epoch: 2/100, Batch: 80/143, Loss: 0.01775532402098179\n",
    "Epoch: 2/100, Batch: 81/143, Loss: 0.01776334084570408\n",
    "Current step: 184.0\n",
    "Epoch: 2/100, Batch: 82/143, Loss: 0.01171919796615839\n",
    "Epoch: 2/100, Batch: 83/143, Loss: 0.00761681143194437\n",
    "Current step: 185.0\n",
    "Epoch: 2/100, Batch: 84/143, Loss: 0.02541307359933853\n",
    "Epoch: 2/100, Batch: 85/143, Loss: 0.025943798944354057\n",
    "Current step: 186.0\n",
    "Epoch: 2/100, Batch: 86/143, Loss: 0.04169383645057678\n",
    "Epoch: 2/100, Batch: 87/143, Loss: 0.04106002300977707\n",
    "Current step: 187.0\n",
    "Epoch: 2/100, Batch: 88/143, Loss: 0.04754774644970894\n",
    "Epoch: 2/100, Batch: 89/143, Loss: 0.036084190011024475\n",
    "Current step: 188.0\n",
    "Epoch: 2/100, Batch: 90/143, Loss: 0.019222406670451164\n",
    "Epoch: 2/100, Batch: 91/143, Loss: 0.018971528857946396\n",
    "Current step: 189.0\n",
    "Epoch: 2/100, Batch: 92/143, Loss: 0.016067037358880043\n",
    "Epoch: 2/100, Batch: 93/143, Loss: 0.016013309359550476\n",
    "Current step: 190.0\n",
    "Epoch: 2/100, Batch: 94/143, Loss: 0.02322457730770111\n",
    "Epoch: 2/100, Batch: 95/143, Loss: 0.0499517060816288\n",
    "Current step: 191.0\n",
    "Epoch: 2/100, Batch: 96/143, Loss: 0.022662127390503883\n",
    "Epoch: 2/100, Batch: 97/143, Loss: 0.022636787965893745\n",
    "Current step: 192.0\n",
    "Epoch: 2/100, Batch: 98/143, Loss: 0.01629822701215744\n",
    "Epoch: 2/100, Batch: 99/143, Loss: 0.016594473272562027\n",
    "Current step: 193.0\n",
    "Epoch: 2/100, Batch: 100/143, Loss: 0.015599459409713745\n",
    "Epoch: 2/100, Batch: 101/143, Loss: 0.015891874209046364\n",
    "Current step: 194.0\n",
    "Epoch: 2/100, Batch: 102/143, Loss: 0.028226584196090698\n",
    "Epoch: 2/100, Batch: 103/143, Loss: 0.016199704259634018\n",
    "Current step: 195.0\n",
    "Epoch: 2/100, Batch: 104/143, Loss: 0.009937616996467113\n",
    "Epoch: 2/100, Batch: 105/143, Loss: 0.010426267981529236\n",
    "Current step: 196.0\n",
    "Epoch: 2/100, Batch: 106/143, Loss: 0.003615020075812936\n",
    "Epoch: 2/100, Batch: 107/143, Loss: 0.00383196328766644\n",
    "Current step: 197.0\n",
    "Epoch: 2/100, Batch: 108/143, Loss: 0.02567458525300026\n",
    "Epoch: 2/100, Batch: 109/143, Loss: 0.005374181549996138\n",
    "Current step: 198.0\n",
    "Epoch: 2/100, Batch: 110/143, Loss: 0.004519775044173002\n",
    "Epoch: 2/100, Batch: 111/143, Loss: 0.004495341330766678\n",
    "Current step: 199.0\n",
    "Epoch: 2/100, Batch: 112/143, Loss: 0.037659574300050735\n",
    "Epoch: 2/100, Batch: 113/143, Loss: 0.00411183713003993\n",
    "Current step: 200.0\n",
    "Epoch: 2/100, Batch: 114/143, Loss: 0.0038626811001449823\n",
    "Epoch: 2/100, Batch: 115/143, Loss: 0.002912241267040372\n",
    "Current step: 201.0\n",
    "Epoch: 2/100, Batch: 116/143, Loss: 0.026360495015978813\n",
    "Epoch: 2/100, Batch: 117/143, Loss: 0.028999123722314835\n",
    "Current step: 202.0\n",
    "Epoch: 2/100, Batch: 118/143, Loss: 0.008455871604382992\n",
    "Epoch: 2/100, Batch: 119/143, Loss: 0.013492288067936897\n",
    "Current step: 203.0\n",
    "Epoch: 2/100, Batch: 120/143, Loss: 0.030440006405115128\n",
    "Epoch: 2/100, Batch: 121/143, Loss: 0.030899150297045708\n",
    "Current step: 204.0\n",
    "Epoch: 2/100, Batch: 122/143, Loss: 0.03965609148144722\n",
    "Epoch: 2/100, Batch: 123/143, Loss: 0.04058664292097092\n",
    "Current step: 205.0\n",
    "Epoch: 2/100, Batch: 124/143, Loss: 0.029902685433626175\n",
    "Epoch: 2/100, Batch: 125/143, Loss: 0.02936745434999466\n",
    "Current step: 206.0\n",
    "Epoch: 2/100, Batch: 126/143, Loss: 0.010850399732589722\n",
    "Epoch: 2/100, Batch: 127/143, Loss: 0.01241637859493494\n",
    "Current step: 207.0\n",
    "Epoch: 2/100, Batch: 128/143, Loss: 0.014500584453344345\n",
    "Epoch: 2/100, Batch: 129/143, Loss: 0.007795984391123056\n",
    "Current step: 208.0\n",
    "Epoch: 2/100, Batch: 130/143, Loss: 0.012742972932755947\n",
    "Epoch: 2/100, Batch: 131/143, Loss: 0.04608401283621788\n",
    "Current step: 209.0\n",
    "Epoch: 2/100, Batch: 132/143, Loss: 0.06510034948587418\n",
    "Epoch: 2/100, Batch: 133/143, Loss: 0.017004195600748062\n",
    "Current step: 210.0\n",
    "Epoch: 2/100, Batch: 134/143, Loss: 0.010530101135373116\n",
    "Epoch: 2/100, Batch: 135/143, Loss: 0.06060018762946129\n",
    "Current step: 211.0\n",
    "Epoch: 2/100, Batch: 136/143, Loss: 0.014734901487827301\n",
    "Epoch: 2/100, Batch: 137/143, Loss: 0.03363659232854843\n",
    "Current step: 212.0\n",
    "Epoch: 2/100, Batch: 138/143, Loss: 0.05636400729417801\n",
    "Epoch: 2/100, Batch: 139/143, Loss: 0.008864584378898144\n",
    "Current step: 213.0\n",
    "Epoch: 2/100, Batch: 140/143, Loss: 0.020027397200465202\n",
    "Epoch: 2/100, Batch: 141/143, Loss: 0.16097401082515717\n",
    "Current step: 214.0\n",
    "Epoch: 2/100, Batch: 142/143, Loss: 0.050103042274713516\n",
    "Epoch: 3/100, Batch: 0/143, Loss: 0.23122499883174896\n",
    "Epoch: 3/100, Batch: 1/143, Loss: 0.23078124225139618\n",
    "Current step: 215.5\n",
    "Epoch: 3/100, Batch: 2/143, Loss: 0.06537950038909912\n",
    "Epoch: 3/100, Batch: 3/143, Loss: 0.2313029021024704\n",
    "Current step: 216.5\n",
    "Epoch: 3/100, Batch: 4/143, Loss: 0.16740624606609344\n",
    "Epoch: 3/100, Batch: 5/143, Loss: 0.1701185405254364\n",
    "Current step: 217.5\n",
    "Epoch: 3/100, Batch: 6/143, Loss: 0.08322270959615707\n",
    "Epoch: 3/100, Batch: 7/143, Loss: 0.08326995372772217\n",
    "Current step: 218.5\n",
    "Epoch: 3/100, Batch: 8/143, Loss: 0.021458910778164864\n",
    "Epoch: 3/100, Batch: 9/143, Loss: 0.021072089672088623\n",
    "Current step: 219.5\n",
    "Epoch: 3/100, Batch: 10/143, Loss: 0.031057190150022507\n",
    "Epoch: 3/100, Batch: 11/143, Loss: 0.007784092333167791\n",
    "Current step: 220.5\n",
    "Epoch: 3/100, Batch: 12/143, Loss: 0.01740100048482418\n",
    "Epoch: 3/100, Batch: 13/143, Loss: 0.017536194995045662\n",
    "Current step: 221.5\n",
    "Epoch: 3/100, Batch: 14/143, Loss: 0.01598299853503704\n",
    "Epoch: 3/100, Batch: 15/143, Loss: 0.01575547829270363\n",
    "Current step: 222.5\n",
    "Epoch: 3/100, Batch: 16/143, Loss: 0.006140552926808596\n",
    "Epoch: 3/100, Batch: 17/143, Loss: 0.16202682256698608\n",
    "Current step: 223.5\n",
    "Epoch: 3/100, Batch: 18/143, Loss: 0.12876538932323456\n",
    "Epoch: 3/100, Batch: 19/143, Loss: 0.007836995646357536\n",
    "Current step: 224.5\n",
    "Epoch: 3/100, Batch: 20/143, Loss: 0.01227464247494936\n",
    "Epoch: 3/100, Batch: 21/143, Loss: 0.13134562969207764\n",
    "Current step: 225.5\n",
    "Epoch: 3/100, Batch: 22/143, Loss: 0.03033209964632988\n",
    "Epoch: 3/100, Batch: 23/143, Loss: 0.03038250282406807\n",
    "Current step: 226.5\n",
    "Epoch: 3/100, Batch: 24/143, Loss: 0.031647682189941406\n",
    "Epoch: 3/100, Batch: 25/143, Loss: 0.031930338591337204\n",
    "Current step: 227.5\n",
    "Epoch: 3/100, Batch: 26/143, Loss: 0.014755950309336185\n",
    "Epoch: 3/100, Batch: 27/143, Loss: 0.016352513805031776\n",
    "Current step: 228.5\n",
    "Epoch: 3/100, Batch: 28/143, Loss: 0.003470510244369507\n",
    "Epoch: 3/100, Batch: 29/143, Loss: 0.003717471146956086\n",
    "Current step: 229.5\n",
    "Epoch: 3/100, Batch: 30/143, Loss: 0.013586544431746006\n",
    "Epoch: 3/100, Batch: 31/143, Loss: 0.013937147334218025\n",
    "Current step: 230.5\n",
    "Epoch: 3/100, Batch: 32/143, Loss: 0.023445896804332733\n",
    "Epoch: 3/100, Batch: 33/143, Loss: 0.025013141334056854\n",
    "Current step: 231.5\n",
    "Epoch: 3/100, Batch: 34/143, Loss: 0.2558448910713196\n",
    "Epoch: 3/100, Batch: 35/143, Loss: 0.2554037570953369\n",
    "Current step: 232.5\n",
    "Epoch: 3/100, Batch: 36/143, Loss: 0.18431149423122406\n",
    "Epoch: 3/100, Batch: 37/143, Loss: 0.008327914401888847\n",
    "Current step: 233.5\n",
    "Epoch: 3/100, Batch: 38/143, Loss: 0.007252122741192579\n",
    "Epoch: 3/100, Batch: 39/143, Loss: 0.007273681927472353\n",
    "Current step: 234.5\n",
    "Epoch: 3/100, Batch: 40/143, Loss: 0.01206188090145588\n",
    "Epoch: 3/100, Batch: 41/143, Loss: 0.01219973061233759\n",
    "Current step: 235.5\n",
    "Epoch: 3/100, Batch: 42/143, Loss: 0.008791147731244564\n",
    "Epoch: 3/100, Batch: 43/143, Loss: 0.008615829050540924\n",
    "Current step: 236.5\n",
    "Epoch: 3/100, Batch: 44/143, Loss: 0.07864174991846085\n",
    "Epoch: 3/100, Batch: 45/143, Loss: 0.08242763578891754\n",
    "Current step: 237.5\n",
    "Epoch: 3/100, Batch: 46/143, Loss: 0.0686449408531189\n",
    "Epoch: 3/100, Batch: 47/143, Loss: 0.003385033691301942\n",
    "Current step: 238.5\n",
    "Epoch: 3/100, Batch: 48/143, Loss: 0.0024003349244594574\n",
    "Epoch: 3/100, Batch: 49/143, Loss: 0.046870362013578415\n",
    "Current step: 239.5\n",
    "Epoch: 3/100, Batch: 50/143, Loss: 0.005191761534661055\n",
    "Epoch: 3/100, Batch: 51/143, Loss: 0.005077866837382317\n",
    "Current step: 240.5\n",
    "Epoch: 3/100, Batch: 52/143, Loss: 0.0047955382615327835\n",
    "Epoch: 3/100, Batch: 53/143, Loss: 0.004977577831596136\n",
    "Current step: 241.5\n",
    "Epoch: 3/100, Batch: 54/143, Loss: 0.0028562680818140507\n",
    "Epoch: 3/100, Batch: 55/143, Loss: 0.0029026565607637167\n",
    "Current step: 242.5\n",
    "Epoch: 3/100, Batch: 56/143, Loss: 0.009756013751029968\n",
    "Epoch: 3/100, Batch: 57/143, Loss: 0.0029855596367269754\n",
    "Current step: 243.5\n",
    "Epoch: 3/100, Batch: 58/143, Loss: 0.0029334865976125\n",
    "Epoch: 3/100, Batch: 59/143, Loss: 0.0025976812466979027\n",
    "Current step: 244.5\n",
    "Epoch: 3/100, Batch: 60/143, Loss: 0.02442110888659954\n",
    "Epoch: 3/100, Batch: 61/143, Loss: 0.02234751731157303\n",
    "Current step: 245.5\n",
    "Epoch: 3/100, Batch: 62/143, Loss: 0.014880234375596046\n",
    "Epoch: 3/100, Batch: 63/143, Loss: 0.0021773227490484715\n",
    "Current step: 246.5\n",
    "Epoch: 3/100, Batch: 64/143, Loss: 0.002562294714152813\n",
    "Epoch: 3/100, Batch: 65/143, Loss: 0.010890702717006207\n",
    "Current step: 247.5\n",
    "Epoch: 3/100, Batch: 66/143, Loss: 0.006848615128546953\n",
    "Epoch: 3/100, Batch: 67/143, Loss: 0.008758224546909332\n",
    "Current step: 248.5\n",
    "Epoch: 3/100, Batch: 68/143, Loss: 0.008206339552998543\n",
    "Epoch: 3/100, Batch: 69/143, Loss: 0.007298423442989588\n",
    "Current step: 249.5\n",
    "Epoch: 3/100, Batch: 70/143, Loss: 0.0028813404496759176\n",
    "Epoch: 3/100, Batch: 71/143, Loss: 0.002991040237247944\n",
    "Current step: 250.5\n",
    "Epoch: 3/100, Batch: 72/143, Loss: 0.008458662778139114\n",
    "Epoch: 3/100, Batch: 73/143, Loss: 0.007091892883181572\n",
    "Current step: 251.5\n",
    "Epoch: 3/100, Batch: 74/143, Loss: 0.006302579306066036\n",
    "Epoch: 3/100, Batch: 75/143, Loss: 0.006340832449495792\n",
    "Current step: 252.5\n",
    "Epoch: 3/100, Batch: 76/143, Loss: 0.00535585405305028\n",
    "Epoch: 3/100, Batch: 77/143, Loss: 0.01517410110682249\n",
    "Current step: 253.5\n",
    "Epoch: 3/100, Batch: 78/143, Loss: 0.02120339684188366\n",
    "Epoch: 3/100, Batch: 79/143, Loss: 0.005097636021673679\n",
    "Current step: 254.5\n",
    "Epoch: 3/100, Batch: 80/143, Loss: 0.006469516549259424\n",
    "Epoch: 3/100, Batch: 81/143, Loss: 0.006532158702611923\n",
    "Current step: 255.5\n",
    "Epoch: 3/100, Batch: 82/143, Loss: 0.12636330723762512\n",
    "Epoch: 3/100, Batch: 83/143, Loss: 0.013884383253753185\n",
    "Current step: 256.5\n",
    "Epoch: 3/100, Batch: 84/143, Loss: 0.011752325110137463\n",
    "Epoch: 3/100, Batch: 85/143, Loss: 0.1422772854566574\n",
    "Current step: 257.5\n",
    "Epoch: 3/100, Batch: 86/143, Loss: 0.1151079311966896\n",
    "Epoch: 3/100, Batch: 87/143, Loss: 0.004374949261546135\n",
    "Current step: 258.5\n",
    "Epoch: 3/100, Batch: 88/143, Loss: 0.0681147500872612\n",
    "Epoch: 3/100, Batch: 89/143, Loss: 0.006088390480726957\n",
    "Current step: 259.5\n",
    "Epoch: 3/100, Batch: 90/143, Loss: 0.011535817757248878\n",
    "Epoch: 3/100, Batch: 91/143, Loss: 0.011520829051733017\n",
    "Current step: 260.5\n",
    "Epoch: 3/100, Batch: 92/143, Loss: 0.008028022013604641\n",
    "Epoch: 3/100, Batch: 93/143, Loss: 0.007998429238796234\n",
    "Current step: 261.5\n",
    "Epoch: 3/100, Batch: 94/143, Loss: 0.0991453304886818\n",
    "Epoch: 3/100, Batch: 95/143, Loss: 0.0998324379324913\n",
    "Current step: 262.5\n",
    "Epoch: 3/100, Batch: 96/143, Loss: 0.0031635623890906572\n",
    "Epoch: 3/100, Batch: 97/143, Loss: 0.003013713750988245\n",
    "Current step: 263.5\n",
    "Epoch: 3/100, Batch: 98/143, Loss: 0.07598607242107391\n",
    "Epoch: 3/100, Batch: 99/143, Loss: 0.001690630684606731\n",
    "Current step: 264.5\n",
    "Epoch: 3/100, Batch: 100/143, Loss: 0.06686414033174515\n",
    "Epoch: 3/100, Batch: 101/143, Loss: 0.0024487485643476248\n",
    "Current step: 265.5\n",
    "Epoch: 3/100, Batch: 102/143, Loss: 0.002124095568433404\n",
    "Epoch: 3/100, Batch: 103/143, Loss: 0.070224829018116\n",
    "Current step: 266.5\n",
    "Epoch: 3/100, Batch: 104/143, Loss: 0.002017262624576688\n",
    "Epoch: 3/100, Batch: 105/143, Loss: 0.002047722926363349\n",
    "Current step: 267.5\n",
    "Epoch: 3/100, Batch: 106/143, Loss: 0.0018810323672369123\n",
    "Epoch: 3/100, Batch: 107/143, Loss: 0.001787900342606008\n",
    "Current step: 268.5\n",
    "Epoch: 3/100, Batch: 108/143, Loss: 0.0019362318562343717\n",
    "Epoch: 3/100, Batch: 109/143, Loss: 0.0018292504828423262\n",
    "Current step: 269.5\n",
    "Epoch: 3/100, Batch: 110/143, Loss: 0.001206559012643993\n",
    "Epoch: 3/100, Batch: 111/143, Loss: 0.0015049492940306664\n",
    "Current step: 270.5\n",
    "Epoch: 3/100, Batch: 112/143, Loss: 0.0124438451603055\n",
    "Epoch: 3/100, Batch: 113/143, Loss: 0.001875436631962657\n",
    "Current step: 271.5\n",
    "Epoch: 3/100, Batch: 114/143, Loss: 0.011493532918393612\n",
    "Epoch: 3/100, Batch: 115/143, Loss: 0.0017100860131904483\n",
    "Current step: 272.5\n",
    "Epoch: 3/100, Batch: 116/143, Loss: 0.0014969288604333997\n",
    "Epoch: 3/100, Batch: 117/143, Loss: 0.0014772422146052122\n",
    "Current step: 273.5\n",
    "Epoch: 3/100, Batch: 118/143, Loss: 0.0016336098778992891\n",
    "Epoch: 3/100, Batch: 119/143, Loss: 0.006030155811458826\n",
    "Current step: 274.5\n",
    "Epoch: 3/100, Batch: 120/143, Loss: 0.00567777082324028\n",
    "Epoch: 3/100, Batch: 121/143, Loss: 0.007768593728542328\n",
    "Current step: 275.5\n",
    "Epoch: 3/100, Batch: 122/143, Loss: 0.006029317621141672\n",
    "Epoch: 3/100, Batch: 123/143, Loss: 0.006050444673746824\n",
    "Current step: 276.5\n",
    "Epoch: 3/100, Batch: 124/143, Loss: 0.004636112600564957\n",
    "Epoch: 3/100, Batch: 125/143, Loss: 0.0045351749286055565\n",
    "Current step: 277.5\n",
    "Epoch: 3/100, Batch: 126/143, Loss: 0.011498834006488323\n",
    "Epoch: 3/100, Batch: 127/143, Loss: 0.009721516631543636\n",
    "Current step: 278.5\n",
    "Epoch: 3/100, Batch: 128/143, Loss: 0.0144805321469903\n",
    "Epoch: 3/100, Batch: 129/143, Loss: 0.01287088543176651\n",
    "Current step: 279.5\n",
    "Epoch: 3/100, Batch: 130/143, Loss: 0.007048160303384066\n",
    "Epoch: 3/100, Batch: 131/143, Loss: 0.0077791097573935986\n",
    "Current step: 280.5\n",
    "Epoch: 3/100, Batch: 132/143, Loss: 0.006167608313262463\n",
    "Epoch: 3/100, Batch: 133/143, Loss: 0.002696751616895199\n",
    "Current step: 281.5\n",
    "Epoch: 3/100, Batch: 134/143, Loss: 0.026746323332190514\n",
    "Epoch: 3/100, Batch: 135/143, Loss: 0.007263958919793367\n",
    "Current step: 282.5\n",
    "Epoch: 3/100, Batch: 136/143, Loss: 0.009707001969218254\n",
    "Epoch: 3/100, Batch: 137/143, Loss: 0.009705640375614166\n",
    "Current step: 283.5\n",
    "Epoch: 3/100, Batch: 138/143, Loss: 0.005520437378436327\n",
    "Epoch: 3/100, Batch: 139/143, Loss: 0.004781853407621384\n",
    "Current step: 284.5\n",
    "Epoch: 3/100, Batch: 140/143, Loss: 0.005169048439711332\n",
    "Epoch: 3/100, Batch: 141/143, Loss: 0.005243184510618448\n",
    "Current step: 285.5\n",
    "Epoch: 3/100, Batch: 142/143, Loss: 0.007549544330686331\n",
    "Epoch: 4/100, Batch: 0/143, Loss: 0.006317972671240568\n",
    "Epoch: 4/100, Batch: 1/143, Loss: 0.007468859199434519\n",
    "Current step: 287.0\n",
    "Epoch: 4/100, Batch: 2/143, Loss: 0.0019365816842764616\n",
    "Epoch: 4/100, Batch: 3/143, Loss: 0.002370271133258939\n",
    "Current step: 288.0\n",
    "Epoch: 4/100, Batch: 4/143, Loss: 0.0046275099739432335\n",
    "Epoch: 4/100, Batch: 5/143, Loss: 0.004562712740153074\n",
    "Current step: 289.0\n",
    "Epoch: 4/100, Batch: 6/143, Loss: 0.007540329825133085\n",
    "Epoch: 4/100, Batch: 7/143, Loss: 0.007506645750254393\n",
    "Current step: 290.0\n",
    "Epoch: 4/100, Batch: 8/143, Loss: 0.003717133542522788\n",
    "Epoch: 4/100, Batch: 9/143, Loss: 0.08722461760044098\n",
    "Current step: 291.0\n",
    "Epoch: 4/100, Batch: 10/143, Loss: 0.0038540009409189224\n",
    "Epoch: 4/100, Batch: 11/143, Loss: 0.00388796697370708\n",
    "Current step: 292.0\n",
    "Epoch: 4/100, Batch: 12/143, Loss: 0.004586368799209595\n",
    "Epoch: 4/100, Batch: 13/143, Loss: 0.003600153373554349\n",
    "Current step: 293.0\n",
    "Epoch: 4/100, Batch: 14/143, Loss: 0.038592319935560226\n",
    "Epoch: 4/100, Batch: 15/143, Loss: 0.001876523718237877\n",
    "Current step: 294.0\n",
    "Epoch: 4/100, Batch: 16/143, Loss: 0.005439660977572203\n",
    "Epoch: 4/100, Batch: 17/143, Loss: 0.06201746314764023\n",
    "Current step: 295.0\n",
    "Epoch: 4/100, Batch: 18/143, Loss: 0.008215110749006271\n",
    "Epoch: 4/100, Batch: 19/143, Loss: 0.05569647625088692\n",
    "Current step: 296.0\n",
    "Epoch: 4/100, Batch: 20/143, Loss: 0.0060526481829583645\n",
    "Epoch: 4/100, Batch: 21/143, Loss: 0.006095093209296465\n",
    "Current step: 297.0\n",
    "Epoch: 4/100, Batch: 22/143, Loss: 0.0030701872892677784\n",
    "Epoch: 4/100, Batch: 23/143, Loss: 0.0032867002300918102\n",
    "Current step: 298.0\n",
    "Epoch: 4/100, Batch: 24/143, Loss: 0.0032506228890269995\n",
    "Epoch: 4/100, Batch: 25/143, Loss: 0.003955226857215166\n",
    "Current step: 299.0\n",
    "Epoch: 4/100, Batch: 26/143, Loss: 0.004239211790263653\n",
    "Epoch: 4/100, Batch: 27/143, Loss: 0.004034361336380243\n",
    "Current step: 300.0\n",
    "Epoch: 4/100, Batch: 28/143, Loss: 0.0038480705115944147\n",
    "Epoch: 4/100, Batch: 29/143, Loss: 0.003928936552256346\n",
    "Current step: 301.0\n",
    "Epoch: 4/100, Batch: 30/143, Loss: 0.004047208931297064\n",
    "Epoch: 4/100, Batch: 31/143, Loss: 0.00407461216673255\n",
    "Current step: 302.0\n",
    "Epoch: 4/100, Batch: 32/143, Loss: 0.0025527349207550287\n",
    "Epoch: 4/100, Batch: 33/143, Loss: 0.0025274858344346285\n",
    "Current step: 303.0\n",
    "Epoch: 4/100, Batch: 34/143, Loss: 0.0036278716288506985\n",
    "Epoch: 4/100, Batch: 35/143, Loss: 0.003550071269273758\n",
    "Current step: 304.0\n",
    "Epoch: 4/100, Batch: 36/143, Loss: 0.015562881715595722\n",
    "Epoch: 4/100, Batch: 37/143, Loss: 0.015536148101091385\n",
    "Current step: 305.0\n",
    "Epoch: 4/100, Batch: 38/143, Loss: 0.003612681059166789\n",
    "Epoch: 4/100, Batch: 39/143, Loss: 0.0036757993511855602\n",
    "Current step: 306.0\n",
    "Epoch: 4/100, Batch: 40/143, Loss: 0.0037353530060499907\n",
    "Epoch: 4/100, Batch: 41/143, Loss: 0.0036795397754758596\n",
    "Current step: 307.0\n",
    "Epoch: 4/100, Batch: 42/143, Loss: 0.002135781105607748\n",
    "Epoch: 4/100, Batch: 43/143, Loss: 0.0019157089991495013\n",
    "Current step: 308.0\n",
    "Epoch: 4/100, Batch: 44/143, Loss: 0.0028972153086215258\n",
    "Epoch: 4/100, Batch: 45/143, Loss: 0.0030061216093599796\n",
    "Current step: 309.0\n",
    "Epoch: 4/100, Batch: 46/143, Loss: 0.002989577129483223\n",
    "Epoch: 4/100, Batch: 47/143, Loss: 0.003043942619115114\n",
    "Current step: 310.0\n",
    "Epoch: 4/100, Batch: 48/143, Loss: 0.007655316032469273\n",
    "Epoch: 4/100, Batch: 49/143, Loss: 0.002857884857803583\n",
    "Current step: 311.0\n",
    "Epoch: 4/100, Batch: 50/143, Loss: 0.0021301975939422846\n",
    "Epoch: 4/100, Batch: 51/143, Loss: 0.006946637760847807\n",
    "Current step: 312.0\n",
    "Epoch: 4/100, Batch: 52/143, Loss: 0.002551920711994171\n",
    "Epoch: 4/100, Batch: 53/143, Loss: 0.0035781702026724815\n",
    "Current step: 313.0\n",
    "Epoch: 4/100, Batch: 54/143, Loss: 0.004161588381975889\n",
    "Epoch: 4/100, Batch: 55/143, Loss: 0.004423967562615871\n",
    "Current step: 314.0\n",
    "Epoch: 4/100, Batch: 56/143, Loss: 0.005568940658122301\n",
    "Epoch: 4/100, Batch: 57/143, Loss: 0.005230466835200787\n",
    "Current step: 315.0\n",
    "Epoch: 4/100, Batch: 58/143, Loss: 0.004164856858551502\n",
    "Epoch: 4/100, Batch: 59/143, Loss: 0.004202459938824177\n",
    "Current step: 316.0\n",
    "Epoch: 4/100, Batch: 60/143, Loss: 0.0030335988849401474\n",
    "Epoch: 4/100, Batch: 61/143, Loss: 0.00579071044921875\n",
    "Current step: 317.0\n",
    "Epoch: 4/100, Batch: 62/143, Loss: 0.007375696208328009\n",
    "Epoch: 4/100, Batch: 63/143, Loss: 0.007367389742285013\n",
    "Current step: 318.0\n",
    "Epoch: 4/100, Batch: 64/143, Loss: 0.008052642457187176\n",
    "Epoch: 4/100, Batch: 65/143, Loss: 0.008257732726633549\n",
    "Current step: 319.0\n",
    "Epoch: 4/100, Batch: 66/143, Loss: 0.003936550579965115\n",
    "Epoch: 4/100, Batch: 67/143, Loss: 0.005198055412620306\n",
    "Current step: 320.0\n",
    "Epoch: 4/100, Batch: 68/143, Loss: 0.006852603051811457\n",
    "Epoch: 4/100, Batch: 69/143, Loss: 0.00710100494325161\n",
    "Current step: 321.0\n",
    "Epoch: 4/100, Batch: 70/143, Loss: 0.0123000992462039\n",
    "Epoch: 4/100, Batch: 71/143, Loss: 0.00899343192577362\n",
    "Current step: 322.0\n",
    "Epoch: 4/100, Batch: 72/143, Loss: 0.005757920444011688\n",
    "Epoch: 4/100, Batch: 73/143, Loss: 0.0056353225372731686\n",
    "Current step: 323.0\n",
    "Epoch: 4/100, Batch: 74/143, Loss: 0.004531228914856911\n",
    "Epoch: 4/100, Batch: 75/143, Loss: 0.0044886451214551926\n",
    "Current step: 324.0\n",
    "Epoch: 4/100, Batch: 76/143, Loss: 0.004803777206689119\n",
    "Epoch: 4/100, Batch: 77/143, Loss: 0.006591878365725279\n",
    "Current step: 325.0\n",
    "Epoch: 4/100, Batch: 78/143, Loss: 0.003864848054945469\n",
    "Epoch: 4/100, Batch: 79/143, Loss: 0.0038423414807766676\n",
    "Current step: 326.0\n",
    "Epoch: 4/100, Batch: 80/143, Loss: 0.008162799291312695\n",
    "Epoch: 4/100, Batch: 81/143, Loss: 0.004331936128437519\n",
    "Current step: 327.0\n",
    "Epoch: 4/100, Batch: 82/143, Loss: 0.003863690886646509\n",
    "Epoch: 4/100, Batch: 83/143, Loss: 0.0038041884545236826\n",
    "Current step: 328.0\n",
    "Epoch: 4/100, Batch: 84/143, Loss: 0.0018113788682967424\n",
    "Epoch: 4/100, Batch: 85/143, Loss: 0.0017660274170339108\n",
    "Current step: 329.0\n",
    "Epoch: 4/100, Batch: 86/143, Loss: 0.0034445864148437977\n",
    "Epoch: 4/100, Batch: 87/143, Loss: 0.003346837591379881\n",
    "Current step: 330.0\n",
    "Epoch: 4/100, Batch: 88/143, Loss: 0.009616628289222717\n",
    "Epoch: 4/100, Batch: 89/143, Loss: 0.0033330146688967943\n",
    "Current step: 331.0\n",
    "Epoch: 4/100, Batch: 90/143, Loss: 0.01946713961660862\n",
    "Epoch: 4/100, Batch: 91/143, Loss: 0.0026963094715029\n",
    "Current step: 332.0\n",
    "Epoch: 4/100, Batch: 92/143, Loss: 0.002502182964235544\n",
    "Epoch: 4/100, Batch: 93/143, Loss: 0.02193225733935833\n",
    "Current step: 333.0\n",
    "Epoch: 4/100, Batch: 94/143, Loss: 0.0025441159959882498\n",
    "Epoch: 4/100, Batch: 95/143, Loss: 0.012144804932177067\n",
    "Current step: 334.0\n",
    "Epoch: 4/100, Batch: 96/143, Loss: 0.005791857838630676\n",
    "Epoch: 4/100, Batch: 97/143, Loss: 0.005822756327688694\n",
    "Current step: 335.0\n",
    "Epoch: 4/100, Batch: 98/143, Loss: 0.019547706469893456\n",
    "Epoch: 4/100, Batch: 99/143, Loss: 0.018445780500769615\n",
    "Current step: 336.0\n",
    "Epoch: 4/100, Batch: 100/143, Loss: 0.017952777445316315\n",
    "Epoch: 4/100, Batch: 101/143, Loss: 0.01006366964429617\n",
    "Current step: 337.0\n",
    "Epoch: 4/100, Batch: 102/143, Loss: 0.005956313107162714\n",
    "Epoch: 4/100, Batch: 103/143, Loss: 0.010271781124174595\n",
    "Current step: 338.0\n",
    "Epoch: 4/100, Batch: 104/143, Loss: 0.005327780265361071\n",
    "Epoch: 4/100, Batch: 105/143, Loss: 0.0054945386946201324\n",
    "Current step: 339.0\n",
    "Epoch: 4/100, Batch: 106/143, Loss: 0.016928771510720253\n",
    "Epoch: 4/100, Batch: 107/143, Loss: 0.017128290608525276\n",
    "Current step: 340.0\n",
    "Epoch: 4/100, Batch: 108/143, Loss: 0.013851235620677471\n",
    "Epoch: 4/100, Batch: 109/143, Loss: 0.014365767128765583\n",
    "Current step: 341.0\n",
    "Epoch: 4/100, Batch: 110/143, Loss: 0.006718757562339306\n",
    "Epoch: 4/100, Batch: 111/143, Loss: 0.00619107810780406\n",
    "Current step: 342.0\n",
    "Epoch: 4/100, Batch: 112/143, Loss: 0.009063438512384892\n",
    "Epoch: 4/100, Batch: 113/143, Loss: 0.009077640250325203\n",
    "Current step: 343.0\n",
    "Epoch: 4/100, Batch: 114/143, Loss: 0.00962008722126484\n",
    "Epoch: 4/100, Batch: 115/143, Loss: 0.00969025120139122\n",
    "Current step: 344.0\n",
    "Epoch: 4/100, Batch: 116/143, Loss: 0.0329148955643177\n",
    "Epoch: 4/100, Batch: 117/143, Loss: 0.006767637096345425\n",
    "Current step: 345.0\n",
    "Epoch: 4/100, Batch: 118/143, Loss: 0.0022930996492505074\n",
    "Epoch: 4/100, Batch: 119/143, Loss: 0.0023686408530920744\n",
    "Current step: 346.0\n",
    "Epoch: 4/100, Batch: 120/143, Loss: 0.0049533359706401825\n",
    "Epoch: 4/100, Batch: 121/143, Loss: 0.004984492436051369\n",
    "Current step: 347.0\n",
    "Epoch: 4/100, Batch: 122/143, Loss: 0.009040623903274536\n",
    "Epoch: 4/100, Batch: 123/143, Loss: 0.009213556535542011\n",
    "Current step: 348.0\n",
    "Epoch: 4/100, Batch: 124/143, Loss: 0.007619758602231741\n",
    "Epoch: 4/100, Batch: 125/143, Loss: 0.007536831311881542\n",
    "Current step: 349.0\n",
    "Epoch: 4/100, Batch: 126/143, Loss: 0.004494613502174616\n",
    "Epoch: 4/100, Batch: 127/143, Loss: 0.07397955656051636\n",
    "Current step: 350.0\n",
    "Epoch: 4/100, Batch: 128/143, Loss: 0.07600666582584381\n",
    "Epoch: 4/100, Batch: 129/143, Loss: 0.004118874669075012\n",
    "Current step: 351.0\n",
    "Epoch: 4/100, Batch: 130/143, Loss: 0.05974126234650612\n",
    "Epoch: 4/100, Batch: 131/143, Loss: 0.002046011621132493\n",
    "Current step: 352.0\n",
    "Epoch: 4/100, Batch: 132/143, Loss: 0.0026728238444775343\n",
    "Epoch: 4/100, Batch: 133/143, Loss: 0.0025744186714291573\n",
    "Current step: 353.0\n",
    "Epoch: 4/100, Batch: 134/143, Loss: 0.0024112879764288664\n",
    "Epoch: 4/100, Batch: 135/143, Loss: 0.06050273776054382\n",
    "Current step: 354.0\n",
    "Epoch: 4/100, Batch: 136/143, Loss: 0.04212048649787903\n",
    "Epoch: 4/100, Batch: 137/143, Loss: 0.0037278467789292336\n",
    "Current step: 355.0\n",
    "Epoch: 4/100, Batch: 138/143, Loss: 0.04307638108730316\n",
    "Epoch: 4/100, Batch: 139/143, Loss: 0.002640696242451668\n",
    "Current step: 356.0\n",
    "Epoch: 4/100, Batch: 140/143, Loss: 0.002223874209448695\n",
    "Epoch: 4/100, Batch: 141/143, Loss: 0.002123486716300249\n",
    "Current step: 357.0\n",
    "Epoch: 4/100, Batch: 142/143, Loss: 0.001983806723728776\n",
    "Epoch: 5/100, Batch: 0/143, Loss: 0.032098155468702316\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expression to match the loss value\n",
    "loss_regex = re.compile(r'Loss: (\\d+\\.\\d+)')\n",
    "\n",
    "# Extract the loss values\n",
    "loss_values = [float(match.group(1)) for match in loss_regex.finditer(output)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "716"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss values\n",
    "plt.plot(loss_values)\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
