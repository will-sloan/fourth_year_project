{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads in the long files and converts them to 1 sec files\n",
    "# BUT it also combines the left and right ears!!!!\n",
    "import os\n",
    "import torchaudio\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads all the wav files in the old_data_path\n",
    "# Splits them into file_length second chunks\n",
    "# Saves the chunks in the new_data_path\n",
    "# But it also downsamples if necessary\n",
    "class AudioBreakdown():\n",
    "    def __init__(self, old_data_path, new_data_path, file_lengths):\n",
    "        # file_lengths is how long in seconds the files should be\n",
    "        self.file_lengths = file_lengths\n",
    "\n",
    "        # old_data_path: where the none 30 second files are stored with their .txt label files\n",
    "        self.old_path = old_data_path\n",
    "        # new_data_path: where to store the 30 second files, each with their own copy of the .txt label file\n",
    "        self.new_path = new_data_path\n",
    "        # baseline_file_name: the name of the baseline file, needed so we don't split into 30 second chunks\n",
    "        #self.baseline_file_name = baseline_file_name\n",
    "\n",
    "    def get_wav_files(self):\n",
    "        # returns a list of all the wav files in the old_data_path\n",
    "        temp_list = list()\n",
    "        for file in os.listdir(self.old_path):\n",
    "            # Check that file is not baseline file\n",
    "            #if file != self.baseline_file_name and file.endswith(\".wav\"):\n",
    "            if 'BKP' not in file and file.endswith(\".wav\"):\n",
    "                # Only get 1 ear\n",
    "                if 'EARS_1' in file:\n",
    "                    continue\n",
    "                temp_list.append(file)\n",
    "        return temp_list\n",
    "\n",
    "    def run(self):\n",
    "       \n",
    "        for file_name in self.get_wav_files():\n",
    "            # Combine the two ears into 1 file\n",
    "            if 'EARS' in file_name:\n",
    "                file_path1 = os.path.join(self.old_path, file_name)\n",
    "\n",
    "                # Get the other ear\n",
    "                file_name2 = file_name.replace('EARS_2', 'EARS_1')\n",
    "                file_path2 = os.path.join(self.old_path, file_name2)\n",
    "                print(file_path1, file_path2)\n",
    "\n",
    "                # Load both audio files\n",
    "                waveform1, sample_rate1 = torchaudio.load(file_path1)\n",
    "                waveform2, sample_rate2 = torchaudio.load(file_path2)\n",
    "                \n",
    "\n",
    "                # Combine the two waveforms\n",
    "                waveform = torch.cat((waveform1, waveform2), dim=0)\n",
    "                sample_rate = sample_rate1\n",
    "\n",
    "                print(f\"\\twaveform shape: {waveform.shape}\")\n",
    "                # calculate the number of chunks\n",
    "                chunk_length = self.file_lengths * sample_rate\n",
    "                print(f\"\\tChunk length: {chunk_length}\")\n",
    "                num_chunks = waveform.shape[1] // chunk_length\n",
    "                #num_chunks = (waveform.shape[1] + chunk_length - 1) // chunk_length\n",
    "                print(f\"\\tNumber of chunks: {num_chunks}\")\n",
    "\n",
    "                for i in range(num_chunks):\n",
    "                    # Get start index\n",
    "                    start_idx = i * chunk_length\n",
    "                    # Get end index\n",
    "                    end_idx = min((i + 1) * chunk_length, waveform.shape[1])\n",
    "\n",
    "                    # Get the chunk\n",
    "                    chunk = waveform[:, start_idx:end_idx]\n",
    "\n",
    "                    # Pad the chunk if it is too short\n",
    "                    if chunk.shape[1] < chunk_length:\n",
    "                        pad = torch.zeros((2, chunk_length - chunk.shape[1]))\n",
    "                        # stereo audio so we need to pad 2 channels\n",
    "                        chunk = torch.cat((chunk, pad), dim=1)\n",
    "\n",
    "                    # Save the chunk and a copy of the label file\n",
    "                    new_file_name = f\"{file_name.replace('.wav', '')}_{i}.wav\"\n",
    "                    new_file_path = os.path.join(self.new_path, new_file_name)\n",
    "                    torchaudio.save(new_file_path, chunk, sample_rate)\n",
    "\n",
    "            else: \n",
    "                \n",
    "                # Deals with mono files\n",
    "                print(f\"{file_name}\")\n",
    "                \n",
    "                #label_path = os.path.join(self.old_path, file_name.replace('.wav', '.txt'))\n",
    "                # Load audio file\n",
    "                file_path = os.path.join(self.old_path, file_name)\n",
    "                waveform, sample_rate = torchaudio.load(file_path)\n",
    "                \n",
    "                \n",
    "                print(f\"\\twaveform shape: {waveform.shape}\")\n",
    "                # calculate the number of 30 second chunks\n",
    "                chunk_length = self.file_lengths * sample_rate\n",
    "                print(f\"\\tChunk length: {chunk_length}\")\n",
    "                num_chunks = waveform.shape[1] // chunk_length\n",
    "                #num_chunks = (waveform.shape[1] + chunk_length - 1) // chunk_length\n",
    "                print(f\"\\tNumber of chunks: {num_chunks}\")\n",
    "\n",
    "                # Slice into chunks\n",
    "                for i in range(num_chunks):\n",
    "                    # Get start index\n",
    "                    start_idx = i * chunk_length\n",
    "                    # Get end index\n",
    "                    end_idx = min((i + 1) * chunk_length, waveform.shape[1])\n",
    "\n",
    "                    # Get the chunk\n",
    "                    chunk = waveform[:, start_idx:end_idx]\n",
    "\n",
    "                    # Pad the chunk if it is too short\n",
    "                    if chunk.shape[1] < chunk_length:\n",
    "                        pad = torch.zeros((2, chunk_length - chunk.shape[1]))\n",
    "                        # stereo audio so we need to pad 2 channels\n",
    "                        chunk = torch.cat((chunk, pad), dim=1)\n",
    "\n",
    "                    # Save the chunk and a copy of the label file\n",
    "                    new_file_name = f\"{file_name.replace('.wav', '')}_{i}.wav\"\n",
    "                    new_file_path = os.path.join(self.new_path, new_file_name)\n",
    "                    torchaudio.save(new_file_path, chunk, sample_rate)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording_01.wav\n",
      "\twaveform shape: torch.Size([1, 754110000])\n",
      "\tChunk length: 44100\n",
      "\tNumber of chunks: 17100\n",
      "/workspace/model2_data/90Deg_EARS_2.wav /workspace/model2_data/90Deg_EARS_1.wav\n",
      "\twaveform shape: torch.Size([2, 754110000])\n",
      "\tChunk length: 44100\n",
      "\tNumber of chunks: 17100\n"
     ]
    }
   ],
   "source": [
    "# origin -> where the 4 hour 45 min files are stored\n",
    "# output -> where to store the 30 second files\n",
    "origin = '/workspace/model2_data'\n",
    "output = '/workspace/extension/1sec_wav_files'\n",
    "myaudio = AudioBreakdown(old_data_path=origin, new_data_path=output, file_lengths=1)\n",
    "myaudio.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform, sample_rate = torchaudio.load('/workspace/extension/10sec_wav_files/90Deg_EARS_2_8.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 441000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "waveform.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
