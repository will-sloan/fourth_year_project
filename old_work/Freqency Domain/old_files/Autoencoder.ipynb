{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the spectrograms previously made, we are going to create a Autoencoder which will create a \n",
    "# prediction mask that can be used to calculate the spatial audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "import sys\n",
    "sys.path.append('/workspace/fourth_year_project/Freqency Domain/')\n",
    "from SpectroDataset import SpectroDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )   \n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            conv_block(552, 128),\n",
    "            nn.MaxPool2d(2,1),  # 276 x 50\n",
    "            conv_block(128, 128),\n",
    "            nn.MaxPool2d(2,1),  # 138 x 25\n",
    "        )\n",
    "\n",
    "        self.bottleneck = conv_block(128, 256)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=1, stride=1),  # 276 x 50\n",
    "            conv_block(128, 128),\n",
    "            nn.ConvTranspose2d(128, 256, kernel_size=1, stride=1),  # 552 x 100\n",
    "            conv_block(256, 256),\n",
    "            nn.ConvTranspose2d(256, 552, kernel_size=1, stride=1),  # 552 x 100\n",
    "            #nn.ConstantPad2d((0, 1, 0, 0), 0),  \n",
    "        )\n",
    "\n",
    "        self.final_conv = nn.Conv2d(552, 552, kernel_size=1)\n",
    "\n",
    "    '''\n",
    "torch.Size([32, 552, 101, 2])\n",
    "In:  torch.Size([32, 552, 101, 2])\n",
    "En:  torch.Size([32, 128, 25, 2])\n",
    "bt:  torch.Size([32, 256, 25, 2])\n",
    "d1:  torch.Size([32, 128, 50, 2])\n",
    "d2:  torch.Size([32, 128, 50, 2])\n",
    "d3:  torch.Size([32, 256, 100, 2])\n",
    "d4:  torch.Size([32, 256, 100, 2])\n",
    "d5:  torch.Size([32, 552, 100, 2])\n",
    "Out:  torch.Size([32, 552, 100, 2])\n",
    "\n",
    "\n",
    "    '''\n",
    "    def forward(self, x):\n",
    "        # Pass the input through the encoder\n",
    "        print(\"In: \", x.shape)\n",
    "        x = self.encoder(x)\n",
    "        print(\"En: \", x.shape)\n",
    "\n",
    "        # Pass the result through the bottleneck\n",
    "        x = self.bottleneck(x)\n",
    "        print(\"bt: \", x.shape)\n",
    "\n",
    "        # Pass the result through the decoder\n",
    "        # Break down decoder into its 7 steps\n",
    "        d1 = self.decoder[0](x)\n",
    "        print(\"d1: \", d1.shape)\n",
    "        d2 = self.decoder[1](d1)\n",
    "        print(\"d2: \", d2.shape)\n",
    "        d3 = self.decoder[2](d2)\n",
    "        print(\"d3: \", d3.shape)\n",
    "        d4 = self.decoder[3](d3)\n",
    "        print(\"d4: \", d4.shape)\n",
    "        d5 = self.decoder[4](d4)\n",
    "        print(\"d5: \", d5.shape)\n",
    "\n",
    "        # d6 = self.decoder[5](d5)\n",
    "        #x = self.decoder(d5)\n",
    "        # print(\"de: \", d6.shape)\n",
    "        \n",
    "\n",
    "\n",
    "        # Pass the result through the final convolution\n",
    "        x = self.final_conv(d5)\n",
    "        print(\"Out: \", x.shape)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def train_loop(self, train_dataset, val_dataset, batch_size, epochs, lr):\n",
    "        dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "        #optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        # Add momentum to the optimizer\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=lr, momentum=0.9)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "        criterion = nn.MSELoss()\n",
    "        #print(\"Starting training loop\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            #print(\"Epoch\", epoch)\n",
    "            for i, (targets, inputs, angle) in enumerate(dataloader):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                # Convert to real\n",
    "                inputs = torch.view_as_real(inputs)\n",
    "                print(inputs.shape)\n",
    "                \n",
    "                outputs = self(inputs)\n",
    "                # Convert back to complex\n",
    "                outputs = torch.view_as_complex(outputs)\n",
    "\n",
    "                # The output from the model is a mask that represents the difference between the input and the target\n",
    "                # We can use the difference to get both left and right channels\n",
    "                print(\"Output shape: \", outputs.shape)\n",
    "                print(\"Target shape: \", targets.shape)\n",
    "                print(\"Input shape: \", inputs.shape)\n",
    "                output_stft = inputs * outputs\n",
    "                # Compare this to the target stft\n",
    "\n",
    "                # We compare the istft to the target\n",
    "                # XD --> output stft\n",
    "                # targets --> stft\n",
    "                loss = criterion(output_stft, targets)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "             # Validation\n",
    "            self.eval()  # Set the model to evaluation mode\n",
    "            with torch.no_grad():  # No need to track gradients in validation\n",
    "                val_loss = 0\n",
    "                for i, (targets, inputs, angle) in enumerate(val_loader):\n",
    "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                    outputs = self(inputs)\n",
    "                    outputs = inputs * outputs\n",
    "                    val_loss += criterion(outputs, targets).item()\n",
    "                val_loss /= len(val_loader)  # Calculate average validation loss\n",
    "\n",
    "            scheduler.step()\n",
    "            if optimizer.param_groups[0]['lr'] < 0.0001:\n",
    "                optimizer.param_groups[0]['lr'] = 0.0001\n",
    "            print(f'Epoch: {epoch}, Training Loss: {loss.item()}, Validation Loss: {val_loss}, LR: {scheduler.get_last_lr()[0]}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset = SpectroDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# with open('/workspace/extension/train_dataset.pkl', 'wb') as f:\n",
    "#     pickle.dump(dataset, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_get_item(self, index):\n",
    "#     temp = self.data_map[index]\n",
    "#     return temp[\"target_spec\"], temp[\"orig_spec\"], temp[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset.__class__.__getitem__ = my_get_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dataset[1][0].shape)\n",
    "# print(dataset[3][1].shape)\n",
    "# print(dataset[5][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset[1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import random_split\n",
    "\n",
    "# # Define the proportions for the split\n",
    "# train_proportion = 0.8 \n",
    "# val_proportion = 0.1\n",
    "# test_proportion = 0.1 \n",
    "\n",
    "# # Calculate the number of samples for train, validation and test\n",
    "# train_size = int(train_proportion * len(dataset))\n",
    "# val_size = int(val_proportion * len(dataset))\n",
    "# test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "# train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "autoencoder.apply(weights_init)\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.train()\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 552, 101, 2])\n",
      "In:  torch.Size([32, 552, 101, 2])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given input size: (128x100x1). Calculated output size: (128x99x0). Output size is too small",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[422], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[410], line 102\u001b[0m, in \u001b[0;36mAutoEncoder.train_loop\u001b[0;34m(self, train_dataset, val_dataset, batch_size, epochs, lr)\u001b[0m\n\u001b[1;32m     99\u001b[0m inputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_real(inputs)\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mprint\u001b[39m(inputs\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 102\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Convert back to complex\u001b[39;00m\n\u001b[1;32m    104\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mview_as_complex(outputs)\n",
      "File \u001b[0;32m/workspace/venv_work/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv_work/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[410], line 49\u001b[0m, in \u001b[0;36mAutoEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;66;03m# Pass the input through the encoder\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIn: \u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 49\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEn: \u001b[39m\u001b[38;5;124m\"\u001b[39m, x\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;66;03m# Pass the result through the bottleneck\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/venv_work/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv_work/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/venv_work/lib/python3.8/site-packages/torch/nn/modules/container.py:215\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    214\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 215\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/workspace/venv_work/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv_work/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/venv_work/lib/python3.8/site-packages/torch/nn/modules/pooling.py:166\u001b[0m, in \u001b[0;36mMaxPool2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor):\n\u001b[0;32m--> 166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m                        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mceil_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mreturn_indices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreturn_indices\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv_work/lib/python3.8/site-packages/torch/_jit_internal.py:488\u001b[0m, in \u001b[0;36mboolean_dispatch.<locals>.fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m if_true(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    487\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mif_false\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv_work/lib/python3.8/site-packages/torch/nn/functional.py:791\u001b[0m, in \u001b[0;36m_max_pool2d\u001b[0;34m(input, kernel_size, stride, padding, dilation, ceil_mode, return_indices)\u001b[0m\n\u001b[1;32m    789\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stride \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    790\u001b[0m     stride \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mannotate(List[\u001b[38;5;28mint\u001b[39m], [])\n\u001b[0;32m--> 791\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mceil_mode\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given input size: (128x100x1). Calculated output size: (128x99x0). Output size is too small"
     ]
    }
   ],
   "source": [
    "autoencoder.train_loop(train_dataset, val_dataset, batch_size=32, epochs=100, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'output_stft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[400], line 17\u001b[0m\n\u001b[1;32m     11\u001b[0m n_fft \u001b[38;5;241m=\u001b[39m window_length_samples\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# This is the stft, so we take the istft\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# Use the same parameters as the stft\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# return_complex since we want phase information\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Don't normalize since that is the amplitude information\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m XD \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mistft(\u001b[43moutput_stft\u001b[49m, n_fft\u001b[38;5;241m=\u001b[39mn_fft, hop_length\u001b[38;5;241m=\u001b[39mhop_length_samples, normalize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, return_complex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# , normalized=True, return_complex=False\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'output_stft' is not defined"
     ]
    }
   ],
   "source": [
    "# NOTE THAT THE MODEL GENERATES STFTs not the actual audio\n",
    "# MAKE SURE THIS IS THE SAME AS ConvertData.ipynb\n",
    "sr = 44100  # Sample rate in Hz (change this to match your audio's sample rate)\n",
    "window_length_ms = 25  # Window length in ms\n",
    "hop_length_ms = 10  # Hop length in ms\n",
    "\n",
    "# Convert window length and hop length from ms to samples\n",
    "window_length_samples = int(sr * window_length_ms / 1000)\n",
    "hop_length_samples = int(sr * hop_length_ms / 1000)\n",
    "\n",
    "n_fft = window_length_samples\n",
    "\n",
    "# This is the stft, so we take the istft\n",
    "# Use the same parameters as the stft\n",
    "# return_complex since we want phase information\n",
    "# Don't normalize since that is the amplitude information\n",
    "XD = torch.istft(output_stft, n_fft=n_fft, hop_length=hop_length_samples, normalize=False, return_complex=True) # , normalized=True, return_complex=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(552, 101)"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5.02988875e-01+0.00000000e+00j, -5.30593574e-01+1.64057776e-01j,\n",
       "        3.47780168e-01-3.93227488e-01j, -8.54631141e-02+3.25779945e-01j,\n",
       "        6.24152794e-02-1.84804529e-01j, -8.60450119e-02+1.62846655e-01j,\n",
       "        8.65100101e-02-1.64212421e-01j, -6.56432435e-02+1.88583001e-01j,\n",
       "        3.80171137e-03-1.80625960e-01j,  2.13879067e-02+1.24031000e-01j,\n",
       "       -2.28486024e-03-9.55331177e-02j, -5.54099970e-04+9.37462971e-02j,\n",
       "       -3.94957606e-03-8.19811001e-02j,  7.14307185e-04+7.21289963e-02j,\n",
       "        1.07573939e-03-6.65651262e-02j, -3.90548399e-03+6.20640144e-02j,\n",
       "        4.82445862e-03-6.31022155e-02j,  2.50251358e-03+6.14278987e-02j,\n",
       "       -5.29625593e-03-4.95583564e-02j, -3.42971180e-03+4.36155759e-02j,\n",
       "        6.41115708e-03-4.89205308e-02j, -2.44011080e-05+4.98691574e-02j,\n",
       "       -4.19482961e-03-4.37827036e-02j,  3.49496654e-03+3.68963890e-02j,\n",
       "        1.00282789e-03-3.28809544e-02j, -4.34094621e-03+3.43883708e-02j,\n",
       "        2.03237310e-03-3.51826176e-02j, -1.54861400e-03+3.08934040e-02j,\n",
       "        5.67719620e-03-3.01161129e-02j, -5.27545204e-03+3.34643647e-02j,\n",
       "        1.54577370e-03-3.22990566e-02j, -1.71698432e-03+2.87627745e-02j,\n",
       "        3.46201868e-03-2.84295008e-02j, -2.61243107e-03+2.91895494e-02j,\n",
       "        6.97953859e-04-2.80140452e-02j,  2.24777235e-04+2.52170898e-02j,\n",
       "        1.42992998e-03-2.22290549e-02j, -4.16223612e-03+2.26424858e-02j,\n",
       "        3.24830879e-03-2.41141878e-02j, -2.15936871e-03+2.23637708e-02j,\n",
       "        3.34422919e-03-2.14160457e-02j, -3.36270523e-03+2.15612352e-02j,\n",
       "        3.19076376e-03-2.07513180e-02j, -3.74672911e-03+1.98225360e-02j,\n",
       "        5.31539042e-03-1.97316948e-02j, -5.74973738e-03+2.20444910e-02j,\n",
       "        2.61882739e-03-2.30715070e-02j, -6.58848090e-04+2.01148558e-02j,\n",
       "        2.27238308e-03-1.80713851e-02j, -3.21206497e-03+1.86943784e-02j,\n",
       "        2.31863605e-03-1.88189857e-02j, -1.75035861e-03+1.74352825e-02j,\n",
       "        2.83447490e-03-1.61376651e-02j, -4.12449008e-03+1.66735630e-02j,\n",
       "        3.74882575e-03-1.76537484e-02j, -2.87840934e-03+1.75403412e-02j,\n",
       "        2.30253534e-03-1.71248335e-02j, -1.70677120e-03+1.61984749e-02j,\n",
       "        2.21087458e-03-1.50745222e-02j, -2.68147560e-03+1.52281765e-02j,\n",
       "        2.15208041e-03-1.47062102e-02j, -2.97814189e-03+1.37827611e-02j,\n",
       "        3.43369995e-03-1.43753290e-02j, -3.07030929e-03+1.37019530e-02j,\n",
       "        4.90488997e-03-1.35596739e-02j, -4.94214101e-03+1.63127501e-02j,\n",
       "        1.92841305e-03-1.69363711e-02j, -1.03310624e-04+1.49124125e-02j,\n",
       "        3.26726615e-04-1.23851607e-02j, -2.47180788e-03+1.15625765e-02j,\n",
       "        2.84078415e-03-1.31532298e-02j, -9.76196025e-04+1.27007430e-02j,\n",
       "        1.26298156e-03-1.01220468e-02j, -3.95524921e-03+9.44738556e-03j,\n",
       "        5.32570574e-03-1.14079146e-02j, -4.42612078e-03+1.28745474e-02j,\n",
       "        3.00652394e-03-1.29223857e-02j, -2.35313899e-03+1.13709401e-02j,\n",
       "        4.15797532e-03-1.06009534e-02j, -4.76754969e-03+1.25895506e-02j,\n",
       "        3.00352974e-03-1.32584572e-02j, -2.00601481e-03+1.24173108e-02j,\n",
       "        1.56217092e-03-1.13461502e-02j, -2.23058159e-03+1.00869229e-02j,\n",
       "        3.50936572e-03-1.03246458e-02j, -3.38839879e-03+1.13207847e-02j,\n",
       "        2.55449233e-03-1.12143485e-02j, -2.59623583e-03+1.05774431e-02j,\n",
       "        2.90631969e-03-1.07199280e-02j, -2.55676103e-03+1.08895572e-02j,\n",
       "        2.29874882e-03-1.07256696e-02j, -1.86678476e-03+1.06626060e-02j,\n",
       "        1.28757372e-03-1.00255432e-02j, -1.25649781e-03+9.05751158e-03j,\n",
       "        1.74352247e-03-8.16183630e-03j, -2.75125727e-03+7.69474590e-03j,\n",
       "        3.81564116e-03-8.06591194e-03j, -4.11208905e-03+9.19620227e-03j,\n",
       "        2.98413867e-03-9.83326416e-03j, -2.06370838e-03+8.48420896e-03j,\n",
       "        3.63253732e-03-7.03912973e-03j, -5.71212452e-03+8.39234702e-03j,\n",
       "        5.21237589e-03-1.07068010e-02j, -3.54359695e-03+1.13204168e-02j,\n",
       "        2.45200936e-03-1.10130133e-02j, -1.69605738e-03+1.06468843e-02j,\n",
       "        7.51293672e-04-1.00764427e-02j, -2.23587602e-04+8.51917733e-03j,\n",
       "        1.28480722e-03-7.36418879e-03j, -1.82175124e-03+7.74245523e-03j,\n",
       "        1.35369680e-03-7.10314373e-03j, -2.62929196e-03+5.91837429e-03j,\n",
       "        4.38738242e-03-7.07806461e-03j, -3.56561947e-03+8.91370978e-03j,\n",
       "        1.98071846e-03-8.28169752e-03j, -2.54805968e-03+7.07447529e-03j,\n",
       "        3.40779708e-03-7.62661081e-03j, -2.86127580e-03+8.39902461e-03j,\n",
       "        1.87577284e-03-7.94761349e-03j, -2.12254794e-03+6.81562535e-03j,\n",
       "        2.93457252e-03-6.90518226e-03j, -2.84890202e-03+6.96819415e-03j,\n",
       "        3.58120096e-03-6.81472104e-03j, -3.81126325e-03+8.03800579e-03j,\n",
       "        2.55584694e-03-8.38419329e-03j, -2.15873355e-03+7.45460251e-03j,\n",
       "        2.80134985e-03-7.26949051e-03j, -2.63661891e-03+8.04826431e-03j,\n",
       "        1.42183388e-03-7.85194151e-03j, -1.13724929e-03+6.42214948e-03j,\n",
       "        2.36023380e-03-5.47086447e-03j, -3.81716760e-03+6.42111246e-03j,\n",
       "        2.92973779e-03-8.23446084e-03j, -8.61606619e-04+7.45448563e-03j,\n",
       "        1.16004259e-03-5.43924561e-03j, -2.68685073e-03+5.03048534e-03j,\n",
       "        3.60129331e-03-5.87950880e-03j, -3.31630977e-03+6.86541572e-03j,\n",
       "        2.69738631e-03-6.98777242e-03j, -2.34975223e-03+7.07032159e-03j,\n",
       "        1.57085177e-03-6.88695908e-03j, -1.18774676e-03+5.92558505e-03j,\n",
       "        1.68233120e-03-5.01678884e-03j, -2.68472079e-03+4.87895031e-03j,\n",
       "        3.13353492e-03-5.73163107e-03j, -2.28424743e-03+6.30271994e-03j,\n",
       "        1.38717785e-03-5.42459451e-03j, -1.86056423e-03+4.11614357e-03j,\n",
       "        3.11881700e-03-3.73335276e-03j, -4.20842832e-03+4.35051462e-03j,\n",
       "        4.22187010e-03-5.54463873e-03j, -3.23119364e-03+5.57662686e-03j,\n",
       "        3.61523870e-03-4.47412208e-03j, -5.22246398e-03+4.98241419e-03j,\n",
       "        5.19852899e-03-6.84251590e-03j, -3.92704736e-03+7.36200111e-03j,\n",
       "        3.54258320e-03-7.28238560e-03j, -2.66058301e-03+7.64210708e-03j,\n",
       "        1.80468452e-03-6.49644248e-03j, -2.81913136e-03+5.95346885e-03j,\n",
       "        2.66781519e-03-6.85074320e-03j, -2.01738998e-03+6.38687843e-03j,\n",
       "        2.30628881e-03-6.42285822e-03j, -1.40135002e-03+6.48184074e-03j,\n",
       "        1.51128450e-03-5.11149690e-03j, -2.91452906e-03+5.62276738e-03j,\n",
       "        1.80179358e-03-7.19442032e-03j,  3.10853153e-04+5.79197984e-03j,\n",
       "        8.53409234e-04-3.24433204e-03j, -3.29159945e-03+4.07814188e-03j,\n",
       "        2.50654179e-03-6.07647235e-03j, -8.73430748e-04+5.31418715e-03j,\n",
       "        1.28662540e-03-3.99587303e-03j, -2.14286032e-03+3.97453783e-03j,\n",
       "        2.18200590e-03-4.39094519e-03j, -1.83987361e-03+4.06106189e-03j,\n",
       "        2.36952468e-03-3.49341030e-03j, -3.01216473e-03+3.69976345e-03j,\n",
       "        3.42897535e-03-4.00980562e-03j, -3.65821412e-03+4.87813633e-03j,\n",
       "        2.78085307e-03-5.50439721e-03j, -2.01085350e-03+4.99119097e-03j,\n",
       "        2.07606261e-03-4.12196014e-03j, -3.29946936e-03+3.90644325e-03j,\n",
       "        3.61646153e-03-5.73223317e-03j, -1.42411306e-03+6.06047548e-03j,\n",
       "        1.28650735e-03-4.22858819e-03j, -2.24861782e-03+4.65342449e-03j,\n",
       "        1.20157166e-03-5.07272407e-03j, -5.59704786e-04+4.12248960e-03j,\n",
       "        3.50709946e-04-3.05140135e-03j, -1.23701664e-03+1.33865164e-03j,\n",
       "        3.69399833e-03-1.39887840e-03j, -4.42684023e-03+3.51256714e-03j,\n",
       "        3.16315750e-03-4.57730331e-03j, -2.05817260e-03+4.04792652e-03j,\n",
       "        2.11233855e-03-2.97378306e-03j, -3.00528156e-03+2.79959035e-03j,\n",
       "        3.04127322e-03-3.35683837e-03j, -2.61095632e-03+2.94802291e-03j,\n",
       "        3.27613181e-03-2.14236439e-03j, -4.63748537e-03+2.38843774e-03j,\n",
       "        5.32700820e-03-3.77763784e-03j, -4.73870570e-03+5.17559377e-03j,\n",
       "        3.45171243e-03-5.73227275e-03j, -2.21203920e-03+5.26514929e-03j,\n",
       "        1.78061728e-03-4.19347361e-03j, -2.10095942e-03+3.34314513e-03j,\n",
       "        2.75232946e-03-2.87313852e-03j, -3.70821613e-03+2.88471440e-03j,\n",
       "        4.52384446e-03-3.97882191e-03j, -3.58391297e-03+5.53956814e-03j,\n",
       "        1.67942536e-03-4.99968231e-03j, -1.72292278e-03+3.40309250e-03j,\n",
       "        2.41146819e-03-3.16396379e-03j, -2.45513674e-03+2.75134039e-03j,\n",
       "        3.64431785e-03-2.18720152e-03j, -4.81547508e-03+3.53455730e-03j,\n",
       "        3.84324300e-03-4.88148862e-03j, -2.81512365e-03+4.47822083e-03j,\n",
       "        2.74201762e-03-3.92808579e-03j, -2.98014772e-03+3.49362497e-03j,\n",
       "        3.75083298e-03-3.51096550e-03j, -4.15031798e-03+4.45545884e-03j,\n",
       "        3.51372664e-03-5.38433436e-03j, -2.49163643e-03+5.49552776e-03j,\n",
       "        1.85163075e-03-5.11217630e-03j, -1.39767746e-03+4.78647742e-03j,\n",
       "        8.19902692e-04-4.12773481e-03j, -9.61453887e-04+2.99203373e-03j,\n",
       "        1.79969543e-03-2.64668535e-03j, -1.99093786e-03+2.79823295e-03j,\n",
       "        2.16173474e-03-2.39675632e-03j, -3.04665975e-03+2.36369041e-03j,\n",
       "        3.44651891e-03-3.46475048e-03j, -2.21834099e-03+4.15571500e-03j,\n",
       "        1.23032811e-03-2.89472425e-03j, -2.18255911e-03+1.55649905e-03j,\n",
       "        3.74059100e-03-1.78069097e-03j, -4.39187000e-03+3.22617940e-03j,\n",
       "        3.39750084e-03-4.51441761e-03j, -1.97673240e-03+4.13766131e-03j,\n",
       "        1.83771667e-03-3.16325179e-03j, -1.99301308e-03+2.88299099e-03j,\n",
       "        1.97193353e-03-2.34545534e-03j, -2.62448471e-03+1.87257642e-03j,\n",
       "        3.26884491e-03-2.11577956e-03j, -3.44522903e-03+2.53541605e-03j,\n",
       "        3.33470851e-03-2.76363688e-03j, -3.25001287e-03+2.72583659e-03j,\n",
       "        3.35937482e-03-2.56219343e-03j, -3.88035853e-03+2.50848848e-03j,\n",
       "        4.49181441e-03-3.25374305e-03j, -4.01742430e-03+4.53022076e-03j,\n",
       "        2.37342413e-03-4.68874024e-03j, -1.65374496e-03+3.05602443e-03j,\n",
       "        3.12130293e-03-2.04956997e-03j, -4.29946138e-03+3.34021379e-03j,\n",
       "        3.29123274e-03-4.69737966e-03j, -1.92930165e-03+4.10724944e-03j,\n",
       "        2.22126278e-03-3.09224776e-03j, -2.75643449e-03+3.44790518e-03j,\n",
       "        2.15577986e-03-3.78280692e-03j, -1.69278553e-03+3.20261926e-03j,\n",
       "        1.83404016e-03-2.67409091e-03j, -2.06866465e-03+2.26527220e-03j,\n",
       "        2.79537286e-03-2.00595940e-03j, -3.41604161e-03+2.78165145e-03j,\n",
       "        2.76798359e-03-3.55273159e-03j, -1.91762322e-03+3.26128816e-03j,\n",
       "        1.54385867e-03-2.36969814e-03j, -2.28209142e-03+1.19636185e-03j,\n",
       "        3.98615142e-03-1.45924441e-03j, -4.42988798e-03+3.08787869e-03j,\n",
       "        3.53304949e-03-4.16547759e-03j, -2.26054736e-03+4.37204400e-03j,\n",
       "        1.12376164e-03-3.50908213e-03j, -1.23854983e-03+2.13537086e-03j,\n",
       "        2.09950353e-03-1.74012175e-03j, -2.38410849e-03+1.88497885e-03j,\n",
       "        2.47902004e-03-1.62005902e-03j, -3.21091036e-03+1.30782626e-03j,\n",
       "        4.14236588e-03-2.10264837e-03j, -3.60688032e-03+3.32537340e-03j,\n",
       "        2.60575046e-03-3.14509030e-03j, -2.45526200e-03+2.71878182e-03j,\n",
       "        2.20259326e-03-2.33163522e-03j, -2.59485957e-03+1.51583750e-03j,\n",
       "        3.65424762e-03-1.58902095e-03j, -4.07203985e-03+2.46460713e-03j,\n",
       "        3.66292358e-03-3.20767402e-03j, -2.95263343e-03+3.17915529e-03j,\n",
       "        2.97418237e-03-2.69416859e-03j, -3.37043265e-03+3.00897844e-03j,\n",
       "        2.80276197e-03-3.56132956e-03j, -2.05993652e-03+3.00791394e-03j,\n",
       "        2.42669228e-03-2.26966641e-03j, -3.00128409e-03+2.49968609e-03j,\n",
       "        2.79268599e-03-2.95831915e-03j, -2.31636339e-03+2.74687144e-03j,\n",
       "        2.50205048e-03-2.23050779e-03j, -2.94809835e-03+2.40809773e-03j,\n",
       "        2.70820386e-03-2.65796436e-03j, -2.68721394e-03+2.26223306e-03j,\n",
       "        3.32979392e-03-2.33561033e-03j, -3.46579566e-03+3.18381167e-03j,\n",
       "        2.75634252e-03-3.80172208e-03j, -1.73749134e-03+3.74631234e-03j,\n",
       "        9.65871732e-04-2.79900781e-03j, -1.41939265e-03+1.71367335e-03j,\n",
       "        1.97843532e-03-1.76678761e-03j, -1.82637316e-03+1.38135883e-03j,\n",
       "        2.86512147e-03-8.06658471e-04j, -3.66602931e-03+1.94535858e-03j,\n",
       "        2.67929048e-03-2.52721785e-03j, -2.51422613e-03+1.59835024e-03j,\n",
       "        3.45585169e-03-1.65317103e-03j, -3.49645969e-03+2.41741934e-03j,\n",
       "        3.21192620e-03-2.65621976e-03j, -2.95337313e-03+2.95983930e-03j,\n",
       "        2.26855883e-03-2.94311182e-03j, -1.94689608e-03+2.22998741e-03j,\n",
       "        2.47123768e-03-1.70882430e-03j, -2.97667249e-03+2.07747822e-03j,\n",
       "        2.63965363e-03-2.48524616e-03j, -2.24947999e-03+2.19932711e-03j,\n",
       "        2.30907416e-03-1.75939116e-03j, -2.69330177e-03+1.51065201e-03j,\n",
       "        3.02150100e-03-1.62809470e-03j, -3.23137874e-03+1.60804915e-03j,\n",
       "        3.83646763e-03-1.89106748e-03j, -3.87571193e-03+2.85063265e-03j,\n",
       "        3.09020979e-03-3.34426831e-03j, -2.47336319e-03+3.07277311e-03j,\n",
       "        2.36560008e-03-2.84419069e-03j, -1.99025916e-03+2.73278565e-03j,\n",
       "        1.93315255e-03-1.95674575e-03j, -2.79682362e-03+1.85553427e-03j,\n",
       "        2.83178617e-03-2.64787604e-03j, -2.20660400e-03+2.72556557e-03j,\n",
       "        1.95519789e-03-2.45790277e-03j, -1.71406101e-03+2.13715481e-03j,\n",
       "        1.85887574e-03-1.52487389e-03j, -2.45914957e-03+1.40005175e-03j,\n",
       "        2.73068901e-03-1.68015098e-03j, -2.79237004e-03+1.94761669e-03j,\n",
       "        2.59163533e-03-2.15153093e-03j, -2.50417390e-03+2.05327873e-03j,\n",
       "        2.46632728e-03-2.27823900e-03j, -1.91637001e-03+2.16728169e-03j,\n",
       "        1.92341174e-03-1.53525581e-03j, -2.27633934e-03+1.31459220e-03j,\n",
       "        2.62994901e-03-1.21263484e-03j, -3.01068113e-03+1.43100973e-03j,\n",
       "        3.15711554e-03-1.72191812e-03j, -3.19853472e-03+2.25415034e-03j,\n",
       "        2.45180051e-03-2.57394719e-03j, -2.09874171e-03+1.80399371e-03j,\n",
       "        2.82913027e-03-1.60064641e-03j, -2.91030388e-03+2.31332052e-03j,\n",
       "        2.27883598e-03-2.39288528e-03j, -2.24038702e-03+2.01611524e-03j,\n",
       "        2.29850924e-03-2.26473506e-03j, -1.60482526e-03+2.22663907e-03j,\n",
       "        1.40243536e-03-1.32242171e-03j, -2.00484600e-03+8.01243819e-04j,\n",
       "        2.54891743e-03-7.93940097e-04j, -2.94637517e-03+1.00384420e-03j,\n",
       "        3.08389636e-03-1.26334280e-03j, -3.25096562e-03+1.36314705e-03j,\n",
       "        3.60784307e-03-1.70604989e-03j, -3.60375247e-03+2.54398072e-03j,\n",
       "        2.71740928e-03-3.08553292e-03j, -1.98208238e-03+2.65708030e-03j,\n",
       "        1.81621430e-03-2.28751148e-03j, -1.59787224e-03+1.80858735e-03j,\n",
       "        2.03472353e-03-1.23964273e-03j, -2.60933721e-03+1.50589726e-03j,\n",
       "        2.43934314e-03-1.93973712e-03j, -2.14844826e-03+1.76845712e-03j,\n",
       "        2.34735734e-03-1.63391361e-03j, -2.32581142e-03+1.78698672e-03j,\n",
       "        2.40034424e-03-1.67589879e-03j, -2.57181562e-03+2.12534750e-03j,\n",
       "        1.90046115e-03-2.41355179e-03j, -1.54739327e-03+1.98431290e-03j,\n",
       "        1.37574249e-03-1.83882914e-03j, -1.12561579e-03+1.17446622e-03j,\n",
       "        1.91833673e-03-7.81530747e-04j, -1.97865488e-03+1.57779339e-03j,\n",
       "        1.01112411e-03-1.23988325e-03j, -1.20765204e-03+9.27274014e-05j,\n",
       "        2.13052449e-03+4.33212088e-04j, -3.36764264e-03-2.01633680e-04j,\n",
       "        3.86582408e-03-1.17639790e-03j, -2.90934509e-03+1.98407634e-03j,\n",
       "        2.27943179e-03-1.56609935e-03j, -2.45940872e-03+1.32013811e-03j,\n",
       "        2.44606473e-03-1.65462436e-03j, -1.80011929e-03+1.66232744e-03j,\n",
       "        1.58656028e-03-9.08949005e-04j, -2.05607759e-03+5.77255152e-04j,\n",
       "        2.20454996e-03-5.49590972e-04j, -2.52722949e-03+2.92634912e-04j,\n",
       "        3.07156262e-03-4.19701159e-04j, -3.54031776e-03+8.38525360e-04j,\n",
       "        3.62660387e-03-1.91534311e-03j, -2.31034169e-03+2.52919365e-03j,\n",
       "        1.55041274e-03-1.44522951e-03j, -2.15571583e-03+1.04233646e-03j,\n",
       "        1.97864929e-03-1.27516256e-03j, -1.82685594e-03+7.55949470e-04j,\n",
       "        2.20653089e-03-4.96492605e-04j, -2.53093801e-03+4.25268372e-04j,\n",
       "        2.97427014e-03-6.57454948e-04j, -2.91477330e-03+1.14631606e-03j,\n",
       "        2.64432631e-03-1.19554834e-03j, -2.61201290e-03+1.16488722e-03j,\n",
       "        2.55142804e-03-1.22052187e-03j, -2.41100765e-03+1.17119425e-03j,\n",
       "        2.51642126e-03-9.27273009e-04j, -2.96675880e-03+1.20445003e-03j,\n",
       "        2.57852743e-03-1.91723183e-03j, -1.79942616e-03+1.65088219e-03j,\n",
       "        1.83003466e-03-1.19094725e-03j, -1.77761412e-03+1.17484329e-03j,\n",
       "        1.58427982e-03-8.44916794e-04j, -1.81862223e-03+4.77845286e-04j,\n",
       "        2.06731493e-03-5.85926231e-04j, -1.74756872e-03+5.46281517e-04j,\n",
       "        1.94854534e-03+2.43542963e-04j, -3.09360120e-03-8.86673515e-05j,\n",
       "        3.08550638e-03-1.11290603e-03j, -2.03790329e-03+1.36679038e-03j,\n",
       "        1.29468669e-03-6.50437258e-04j, -1.38254522e-03-6.56514196e-04j,\n",
       "        2.85393582e-03+1.44318445e-03j, -4.34423983e-03-5.13331499e-04j,\n",
       "        4.37876955e-03-1.05369836e-03j, -3.38945305e-03+1.82543078e-03j,\n",
       "        2.51284102e-03-1.64147571e-03j, -2.12987070e-03+1.15376245e-03j,\n",
       "        2.15515192e-03-5.89469273e-04j, -2.65488331e-03+3.49496200e-04j,\n",
       "        2.98096496e-03-6.95189869e-04j, -2.84725847e-03+1.04687468e-03j,\n",
       "        2.50421534e-03-1.15415186e-03j, -2.29481608e-03+8.73741810e-04j,\n",
       "        2.54486781e-03-8.71040393e-04j, -2.15889211e-03+1.26205222e-03j,\n",
       "        1.51746289e-03-7.23947771e-04j, -1.71147147e-03+4.13587040e-05j,\n",
       "        2.00031977e-03+3.43562395e-04j, -2.68507283e-03-6.72345283e-04j,\n",
       "        3.39706591e-03+1.23283855e-04j, -3.07670375e-03+5.76561841e-04j,\n",
       "        2.47921469e-03-2.50045880e-04j, -2.92520318e-03-4.66873811e-04j,\n",
       "        3.85166681e-03+1.13530819e-04j, -3.80314770e-03+7.34595873e-04j,\n",
       "        3.37820896e-03-8.56503495e-04j, -3.40088364e-03+7.99635309e-04j,\n",
       "        3.51434364e-03-1.00386632e-03j, -3.47434008e-03+1.49102008e-03j,\n",
       "        2.71335989e-03-1.93994853e-03j, -1.85585907e-03+1.22424180e-03j,\n",
       "        2.35932879e-03-3.45003966e-04j, -2.95667350e-03+6.92982518e-04j,\n",
       "        2.69510807e-03-9.66355205e-04j, -2.67947721e-03+8.28327960e-04j,\n",
       "        2.66880752e-03-1.05343969e-03j, -2.24007270e-03+9.88966436e-04j,\n",
       "        2.25550425e-03-5.38148277e-04j, -2.48675328e-03+5.78724081e-04j,\n",
       "        2.19172100e-03-5.32543811e-04j, -2.28552497e-03-1.53799367e-04j,\n",
       "        3.20625957e-03+3.29095608e-04j, -3.72799416e-03+4.66158905e-04j,\n",
       "        3.29270912e-03-1.06943457e-03j, -2.94117164e-03+8.65217356e-04j,\n",
       "        3.26762558e-03-7.72261352e-04j, -3.48327961e-03+1.38182088e-03j,\n",
       "        2.86097708e-03-2.08614441e-03j, -1.76095462e-03+1.90586213e-03j,\n",
       "        1.33412925e-03-9.27093904e-04j, -1.72795111e-03+1.80942108e-04j,\n",
       "        2.34554801e-03+3.94434392e-05j, -2.83503858e-03+2.11837774e-04j,\n",
       "        2.87961331e-03-5.55862614e-04j, -2.94965971e-03+6.42283470e-04j,\n",
       "        3.09604523e-03-1.18057313e-03j, -2.24567088e-03+1.69084116e-03j,\n",
       "        1.49914436e-03-7.92307197e-04j, -2.24630791e-03+9.42690967e-05j,\n",
       "        2.73580104e-03-6.01213833e-04j, -2.57277698e-03+9.47145571e-04j,\n",
       "        2.32900586e-03-1.26812316e-03j, -1.57751725e-03+1.32040703e-03j,\n",
       "        1.01414917e-03-5.26742544e-04j, -1.41525979e-03-4.16339899e-04j,\n",
       "        2.30482058e-03+4.58245922e-04j, -2.45530787e-03+7.54824505e-05j,\n",
       "        2.21145083e-03-3.78937330e-05j, -2.43090140e-03-1.38293617e-04j,\n",
       "        2.64430977e-03-1.25597246e-04j, -2.36431486e-03+3.74524185e-04j,\n",
       "        2.07298039e-03-4.42835044e-05j, -2.39298609e-03-2.50106852e-04j,\n",
       "        2.50287307e-03+4.90198363e-05j, -2.40950263e-03-3.50890565e-04j,\n",
       "        3.15471692e-03+4.68533806e-04j, -3.37454560e-03+4.97570785e-04j,\n",
       "        2.47445703e-03-7.44550314e-04j, -2.33288785e-03+4.64805489e-05j,\n",
       "        2.88905529e-03-4.84084521e-05j, -2.83879694e-03+6.04121306e-04j,\n",
       "        2.20943452e-03-6.34300290e-04j, -2.07071356e-03-1.26174709e-05j,\n",
       "        2.61399848e-03+1.59921125e-04j, -2.67299847e-03+2.04978365e-04j,\n",
       "        2.48923502e-03-2.36755557e-04j, -2.28984212e-03+2.34499283e-04j,\n",
       "        2.07857834e-03+2.56814994e-04j, -2.76878267e-03-6.79367338e-04j,\n",
       "        3.30873416e-03+1.86971320e-05j, -2.84541305e-03+5.08211786e-04j,\n",
       "        2.39799195e-03-2.61890644e-04j, -2.48982571e-03-1.23111124e-04j,\n",
       "        2.85125244e-03+1.34312693e-04j, -2.95218057e-03+2.13607593e-04j,\n",
       "        2.64122779e-03-4.05490806e-04j, -2.37420155e-03+1.81953292e-04j,\n",
       "        2.44256645e-03+1.08258973e-04j, -2.67773727e-03-2.40374240e-04j,\n",
       "        2.97573651e-03+1.20295379e-04j, -2.96459394e-03+2.16340195e-04j,\n",
       "        2.74034915e-03-2.35747357e-04j, -2.79289251e-03+1.92621766e-04j,\n",
       "        2.71713454e-03-3.76285723e-04j, -2.41901889e-03+3.14499135e-04j,\n",
       "        2.37532868e-03+3.32046620e-05j, -2.70927232e-03-1.80965799e-04j,\n",
       "        2.90769292e-03-8.80204607e-05j, -2.76440033e-03+2.85749120e-04j,\n",
       "        2.61026109e-03-3.21600790e-04j, -2.41168449e-03+2.45445292e-04j,\n",
       "        2.41714856e-03+1.83360899e-05j, -2.65360926e-03-2.56103340e-05j,\n",
       "        2.62704212e-03-1.70851214e-04j, -2.44408497e-03+1.27677922e-04j,\n",
       "        2.46863649e-03+2.72769466e-05j, -2.55503017e-03+0.00000000e+00j],\n",
       "      dtype=complex64)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][0][:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.5029889 +0.j, -0.4718467 +0.j, -0.6029801 +0.j,  1.176311  +0.j,\n",
       "        0.648138  +0.j, -0.9083143 +0.j,  0.37553746+0.j,  1.668564  +0.j,\n",
       "       -1.2395344 +0.j, -0.63539296+0.j,  0.10222008+0.j, -0.5448244 +0.j,\n",
       "       -1.7610011 +0.j, -0.8694553 +0.j,  0.963181  +0.j, -0.5163584 +0.j,\n",
       "       -1.0425301 +0.j, -0.67282873+0.j,  0.17496312+0.j,  1.1337073 +0.j,\n",
       "        1.526577  +0.j,  1.9941056 +0.j,  0.71489406+0.j, -0.5192214 +0.j,\n",
       "        1.2931379 +0.j,  0.63454354+0.j, -1.012174  +0.j,  0.5408937 +0.j,\n",
       "        0.03543916+0.j, -0.43480355+0.j,  1.174363  +0.j,  1.1227303 +0.j,\n",
       "       -1.7879429 +0.j, -2.5298352 +0.j,  0.06283827+0.j, -0.16407955+0.j,\n",
       "       -0.05243171+0.j,  0.17424308+0.j,  1.2525527 +0.j,  0.47287044+0.j,\n",
       "       -0.77015984+0.j,  0.8128915 +0.j,  0.6842846 +0.j, -2.1751873 +0.j,\n",
       "       -2.0081465 +0.j, -1.1924818 +0.j, -1.2335767 +0.j, -0.05667074+0.j,\n",
       "       -1.0939306 +0.j, -1.7757728 +0.j, -0.46993595+0.j,  1.8803167 +0.j,\n",
       "        1.3843821 +0.j, -0.44618666+0.j,  1.2283773 +0.j,  0.52231634+0.j,\n",
       "       -0.06107272+0.j,  2.0834916 +0.j,  3.2112079 +0.j,  0.22910051+0.j,\n",
       "       -1.4313886 +0.j,  0.08036777+0.j,  0.25284442+0.j, -0.8653072 +0.j,\n",
       "       -1.1881064 +0.j, -1.1737859 +0.j, -2.808501  +0.j, -3.061449  +0.j,\n",
       "        1.2394538 +0.j,  1.79145   +0.j, -0.73304844+0.j,  0.9773077 +0.j,\n",
       "        1.3207633 +0.j, -0.06876481+0.j,  0.64574206+0.j,  2.0329363 +0.j,\n",
       "        1.0508327 +0.j,  0.744652  +0.j,  1.6519643 +0.j,  0.1180345 +0.j,\n",
       "       -1.4335266 +0.j, -1.4513887 +0.j,  0.43867964+0.j, -0.02591379+0.j,\n",
       "       -1.7715231 +0.j, -1.3345925 +0.j, -0.4003453 +0.j, -0.6747627 +0.j,\n",
       "        0.7249261 +0.j,  0.3454887 +0.j, -1.8167276 +0.j, -1.6639549 +0.j,\n",
       "        2.8435962 +0.j,  3.1023283 +0.j,  1.9018158 +0.j,  0.19819376+0.j,\n",
       "       -1.099589  +0.j, -0.37463725+0.j,  0.70418036+0.j,  1.4350853 +0.j,\n",
       "       -0.14267808+0.j], dtype=complex64)"
      ]
     },
     "execution_count": 409,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1][0][0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
