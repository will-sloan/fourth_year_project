{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = '''\n",
    "Epoch: 0/100, Batch: 0/143, Loss: 21.257972717285156\n",
    "Epoch: 0/100, Batch: 1/143, Loss: 35.611637115478516\n",
    "Current step: 1.0\n",
    "Epoch: 0/100, Batch: 2/143, Loss: 21.706836700439453\n",
    "Epoch: 0/100, Batch: 3/143, Loss: 21.800052642822266\n",
    "Current step: 2.0\n",
    "Epoch: 0/100, Batch: 4/143, Loss: 36.35921859741211\n",
    "Epoch: 0/100, Batch: 5/143, Loss: 21.442773818969727\n",
    "Current step: 3.0\n",
    "Epoch: 0/100, Batch: 6/143, Loss: 26.695199966430664\n",
    "Epoch: 0/100, Batch: 7/143, Loss: 36.1571159362793\n",
    "Current step: 4.0\n",
    "Epoch: 0/100, Batch: 8/143, Loss: 22.545360565185547\n",
    "Epoch: 0/100, Batch: 9/143, Loss: 34.185081481933594\n",
    "Current step: 5.0\n",
    "Epoch: 0/100, Batch: 10/143, Loss: 37.76951217651367\n",
    "Epoch: 0/100, Batch: 11/143, Loss: 34.78163146972656\n",
    "Current step: 6.0\n",
    "Epoch: 0/100, Batch: 12/143, Loss: 15.614236831665039\n",
    "Epoch: 0/100, Batch: 13/143, Loss: 15.888457298278809\n",
    "Current step: 7.0\n",
    "Epoch: 0/100, Batch: 14/143, Loss: 7.014136791229248\n",
    "Epoch: 0/100, Batch: 15/143, Loss: 6.990067481994629\n",
    "Current step: 8.0\n",
    "Epoch: 0/100, Batch: 16/143, Loss: 4.730969429016113\n",
    "Epoch: 0/100, Batch: 17/143, Loss: 9.78073787689209\n",
    "Current step: 9.0\n",
    "Epoch: 0/100, Batch: 18/143, Loss: 4.546058177947998\n",
    "Epoch: 0/100, Batch: 19/143, Loss: 6.152279853820801\n",
    "Current step: 10.0\n",
    "Epoch: 0/100, Batch: 20/143, Loss: 5.354976654052734\n",
    "Epoch: 0/100, Batch: 21/143, Loss: 5.126471996307373\n",
    "Current step: 11.0\n",
    "Epoch: 0/100, Batch: 22/143, Loss: 4.0301361083984375\n",
    "Epoch: 0/100, Batch: 23/143, Loss: 3.9492533206939697\n",
    "Current step: 12.0\n",
    "Epoch: 0/100, Batch: 24/143, Loss: 3.309458017349243\n",
    "Epoch: 0/100, Batch: 25/143, Loss: 2.785646438598633\n",
    "Current step: 13.0\n",
    "Epoch: 0/100, Batch: 26/143, Loss: 2.513470411300659\n",
    "Epoch: 0/100, Batch: 27/143, Loss: 2.5093436241149902\n",
    "Current step: 14.0\n",
    "Epoch: 0/100, Batch: 28/143, Loss: 1.9444966316223145\n",
    "Epoch: 0/100, Batch: 29/143, Loss: 1.935141682624817\n",
    "Current step: 15.0\n",
    "Epoch: 0/100, Batch: 30/143, Loss: 1.4531035423278809\n",
    "Epoch: 0/100, Batch: 31/143, Loss: 1.4509034156799316\n",
    "Current step: 16.0\n",
    "Epoch: 0/100, Batch: 32/143, Loss: 0.9654436707496643\n",
    "Epoch: 0/100, Batch: 33/143, Loss: 0.9714025855064392\n",
    "Current step: 17.0\n",
    "Epoch: 0/100, Batch: 34/143, Loss: 0.6935701966285706\n",
    "Epoch: 0/100, Batch: 35/143, Loss: 0.7120859622955322\n",
    "Current step: 18.0\n",
    "Epoch: 0/100, Batch: 36/143, Loss: 0.5893391966819763\n",
    "Epoch: 0/100, Batch: 37/143, Loss: 0.5918563604354858\n",
    "Current step: 19.0\n",
    "Epoch: 0/100, Batch: 38/143, Loss: 0.9336786270141602\n",
    "Epoch: 0/100, Batch: 39/143, Loss: 1.062097430229187\n",
    "Current step: 20.0\n",
    "Epoch: 0/100, Batch: 40/143, Loss: 0.4394150972366333\n",
    "Epoch: 0/100, Batch: 41/143, Loss: 0.6223888397216797\n",
    "Current step: 21.0\n",
    "Epoch: 0/100, Batch: 42/143, Loss: 0.633198618888855\n",
    "Epoch: 0/100, Batch: 43/143, Loss: 0.6343699097633362\n",
    "Current step: 22.0\n",
    "Epoch: 0/100, Batch: 44/143, Loss: 0.5027183294296265\n",
    "Epoch: 0/100, Batch: 45/143, Loss: 0.7199493646621704\n",
    "Current step: 23.0\n",
    "Epoch: 0/100, Batch: 46/143, Loss: 0.5286459922790527\n",
    "Epoch: 0/100, Batch: 47/143, Loss: 0.41377270221710205\n",
    "Current step: 24.0\n",
    "Epoch: 0/100, Batch: 48/143, Loss: 1.0095540285110474\n",
    "Epoch: 0/100, Batch: 49/143, Loss: 1.0279070138931274\n",
    "Current step: 25.0\n",
    "Epoch: 0/100, Batch: 50/143, Loss: 0.9976438283920288\n",
    "Epoch: 0/100, Batch: 51/143, Loss: 0.5665835738182068\n",
    "Current step: 26.0\n",
    "Epoch: 0/100, Batch: 52/143, Loss: 0.38909712433815\n",
    "Epoch: 0/100, Batch: 53/143, Loss: 0.6671620607376099\n",
    "Current step: 27.0\n",
    "Epoch: 0/100, Batch: 54/143, Loss: 0.2885938882827759\n",
    "Epoch: 0/100, Batch: 55/143, Loss: 0.28524765372276306\n",
    "Current step: 28.0\n",
    "Epoch: 0/100, Batch: 56/143, Loss: 0.4310549199581146\n",
    "Epoch: 0/100, Batch: 57/143, Loss: 0.46405676007270813\n",
    "Current step: 29.0\n",
    "Epoch: 0/100, Batch: 58/143, Loss: 0.7243091464042664\n",
    "Epoch: 0/100, Batch: 59/143, Loss: 0.7213947176933289\n",
    "Current step: 30.0\n",
    "Epoch: 0/100, Batch: 60/143, Loss: 0.6439153552055359\n",
    "Epoch: 0/100, Batch: 61/143, Loss: 0.6546884775161743\n",
    "Current step: 31.0\n",
    "Epoch: 0/100, Batch: 62/143, Loss: 0.3801010251045227\n",
    "Epoch: 0/100, Batch: 63/143, Loss: 0.385773241519928\n",
    "Current step: 32.0\n",
    "Epoch: 0/100, Batch: 64/143, Loss: 0.1976897418498993\n",
    "Epoch: 0/100, Batch: 65/143, Loss: 0.19853456318378448\n",
    "Current step: 33.0\n",
    "Epoch: 0/100, Batch: 66/143, Loss: 0.5563176274299622\n",
    "Epoch: 0/100, Batch: 67/143, Loss: 0.55499267578125\n",
    "Current step: 34.0\n",
    "Epoch: 0/100, Batch: 68/143, Loss: 0.5042729377746582\n",
    "Epoch: 0/100, Batch: 69/143, Loss: 0.8149397969245911\n",
    "Current step: 35.0\n",
    "Epoch: 0/100, Batch: 70/143, Loss: 0.569019079208374\n",
    "Epoch: 0/100, Batch: 71/143, Loss: 0.5810320377349854\n",
    "Current step: 36.0\n",
    "Epoch: 0/100, Batch: 72/143, Loss: 0.4780985414981842\n",
    "Epoch: 0/100, Batch: 73/143, Loss: 0.4093693494796753\n",
    "Current step: 37.0\n",
    "Epoch: 0/100, Batch: 74/143, Loss: 0.1969561129808426\n",
    "Epoch: 0/100, Batch: 75/143, Loss: 0.1988312155008316\n",
    "Current step: 38.0\n",
    "Epoch: 0/100, Batch: 76/143, Loss: 0.2170933037996292\n",
    "Epoch: 0/100, Batch: 77/143, Loss: 0.22183291614055634\n",
    "Current step: 39.0\n",
    "Epoch: 0/100, Batch: 78/143, Loss: 0.3711387515068054\n",
    "Epoch: 0/100, Batch: 79/143, Loss: 0.2266392856836319\n",
    "Current step: 40.0\n",
    "Epoch: 0/100, Batch: 80/143, Loss: 0.32817038893699646\n",
    "Epoch: 0/100, Batch: 81/143, Loss: 0.19171226024627686\n",
    "Current step: 41.0\n",
    "Epoch: 0/100, Batch: 82/143, Loss: 0.2534823715686798\n",
    "Epoch: 0/100, Batch: 83/143, Loss: 0.12996521592140198\n",
    "Current step: 42.0\n",
    "Epoch: 0/100, Batch: 84/143, Loss: 0.17335882782936096\n",
    "Epoch: 0/100, Batch: 85/143, Loss: 0.1742432415485382\n",
    "Current step: 43.0\n",
    "Epoch: 0/100, Batch: 86/143, Loss: 0.15814080834388733\n",
    "Epoch: 0/100, Batch: 87/143, Loss: 0.16180528700351715\n",
    "Current step: 44.0\n",
    "Epoch: 0/100, Batch: 88/143, Loss: 0.9176130890846252\n",
    "Epoch: 0/100, Batch: 89/143, Loss: 0.17997729778289795\n",
    "Current step: 45.0\n",
    "Epoch: 0/100, Batch: 90/143, Loss: 0.13261324167251587\n",
    "Epoch: 0/100, Batch: 91/143, Loss: 0.13271257281303406\n",
    "Current step: 46.0\n",
    "Epoch: 0/100, Batch: 92/143, Loss: 1.0310670137405396\n",
    "Epoch: 0/100, Batch: 93/143, Loss: 1.0340449810028076\n",
    "Current step: 47.0\n",
    "Epoch: 0/100, Batch: 94/143, Loss: 0.6920337677001953\n",
    "Epoch: 0/100, Batch: 95/143, Loss: 0.14232885837554932\n",
    "Current step: 48.0\n",
    "Epoch: 0/100, Batch: 96/143, Loss: 0.6125408411026001\n",
    "Epoch: 0/100, Batch: 97/143, Loss: 0.22343547642230988\n",
    "Current step: 49.0\n",
    "Epoch: 0/100, Batch: 98/143, Loss: 0.16352201998233795\n",
    "Epoch: 0/100, Batch: 99/143, Loss: 0.1615392118692398\n",
    "Current step: 50.0\n",
    "Epoch: 0/100, Batch: 100/143, Loss: 0.0907825157046318\n",
    "Epoch: 0/100, Batch: 101/143, Loss: 0.09019549936056137\n",
    "Current step: 51.0\n",
    "Epoch: 0/100, Batch: 102/143, Loss: 1.2277759313583374\n",
    "Epoch: 0/100, Batch: 103/143, Loss: 1.3325902223587036\n",
    "Current step: 52.0\n",
    "Epoch: 0/100, Batch: 104/143, Loss: 0.1479998081922531\n",
    "Epoch: 0/100, Batch: 105/143, Loss: 1.230489730834961\n",
    "Current step: 53.0\n",
    "Epoch: 0/100, Batch: 106/143, Loss: 0.16343048214912415\n",
    "Epoch: 0/100, Batch: 107/143, Loss: 0.1634712666273117\n",
    "Current step: 54.0\n",
    "Epoch: 0/100, Batch: 108/143, Loss: 0.11775608360767365\n",
    "Epoch: 0/100, Batch: 109/143, Loss: 0.12036265432834625\n",
    "Current step: 55.0\n",
    "Epoch: 0/100, Batch: 110/143, Loss: 0.2502058744430542\n",
    "Epoch: 0/100, Batch: 111/143, Loss: 0.09177916496992111\n",
    "Current step: 56.0\n",
    "Epoch: 0/100, Batch: 112/143, Loss: 0.11300322413444519\n",
    "Epoch: 0/100, Batch: 113/143, Loss: 0.09785839915275574\n",
    "Current step: 57.0\n",
    "Epoch: 0/100, Batch: 114/143, Loss: 0.08441813290119171\n",
    "Epoch: 0/100, Batch: 115/143, Loss: 0.07720745354890823\n",
    "Current step: 58.0\n",
    "Epoch: 0/100, Batch: 116/143, Loss: 0.12344536930322647\n",
    "Epoch: 0/100, Batch: 117/143, Loss: 0.07322027534246445\n",
    "Current step: 59.0\n",
    "Epoch: 0/100, Batch: 118/143, Loss: 0.12459629774093628\n",
    "Epoch: 0/100, Batch: 119/143, Loss: 0.12281522899866104\n",
    "Current step: 60.0\n",
    "Epoch: 0/100, Batch: 120/143, Loss: 0.0727171078324318\n",
    "Epoch: 0/100, Batch: 121/143, Loss: 0.07531094551086426\n",
    "Current step: 61.0\n",
    "Epoch: 0/100, Batch: 122/143, Loss: 0.06298938393592834\n",
    "Epoch: 0/100, Batch: 123/143, Loss: 0.06315366923809052\n",
    "Current step: 62.0\n",
    "Epoch: 0/100, Batch: 124/143, Loss: 0.07600709050893784\n",
    "Epoch: 0/100, Batch: 125/143, Loss: 0.07749678194522858\n",
    "Current step: 63.0\n",
    "Epoch: 0/100, Batch: 126/143, Loss: 0.05019904300570488\n",
    "Epoch: 0/100, Batch: 127/143, Loss: 0.052612997591495514\n",
    "Current step: 64.0\n",
    "Epoch: 0/100, Batch: 128/143, Loss: 0.03703340142965317\n",
    "Epoch: 0/100, Batch: 129/143, Loss: 0.037097908556461334\n",
    "Current step: 65.0\n",
    "Epoch: 0/100, Batch: 130/143, Loss: 0.05018744617700577\n",
    "Epoch: 0/100, Batch: 131/143, Loss: 0.05097801238298416\n",
    "Current step: 66.0\n",
    "Epoch: 0/100, Batch: 132/143, Loss: 0.06837425380945206\n",
    "Epoch: 0/100, Batch: 133/143, Loss: 0.06700004637241364\n",
    "Current step: 67.0\n",
    "Epoch: 0/100, Batch: 134/143, Loss: 0.2344367951154709\n",
    "Epoch: 0/100, Batch: 135/143, Loss: 0.04591657966375351\n",
    "Current step: 68.0\n",
    "Epoch: 0/100, Batch: 136/143, Loss: 0.026860946789383888\n",
    "Epoch: 0/100, Batch: 137/143, Loss: 0.027016915380954742\n",
    "Current step: 69.0\n",
    "Epoch: 0/100, Batch: 138/143, Loss: 0.029522137716412544\n",
    "Epoch: 0/100, Batch: 139/143, Loss: 0.1678307056427002\n",
    "Current step: 70.0\n",
    "Epoch: 0/100, Batch: 140/143, Loss: 0.06167437508702278\n",
    "Epoch: 0/100, Batch: 141/143, Loss: 0.09691309928894043\n",
    "Current step: 71.0\n",
    "Epoch: 0/100, Batch: 142/143, Loss: 0.03408179432153702\n",
    "Epoch: 1/100, Batch: 0/143, Loss: 0.03357149660587311\n",
    "Epoch: 1/100, Batch: 1/143, Loss: 0.03458099067211151\n",
    "Current step: 72.5\n",
    "Epoch: 1/100, Batch: 2/143, Loss: 0.08758803457021713\n",
    "Epoch: 1/100, Batch: 3/143, Loss: 0.3685360252857208\n",
    "Current step: 73.5\n",
    "Epoch: 1/100, Batch: 4/143, Loss: 0.19161199033260345\n",
    "Epoch: 1/100, Batch: 5/143, Loss: 0.48835039138793945\n",
    "Current step: 74.5\n",
    "Epoch: 1/100, Batch: 6/143, Loss: 0.22026963531970978\n",
    "Epoch: 1/100, Batch: 7/143, Loss: 0.3945137560367584\n",
    "Current step: 75.5\n",
    "Epoch: 1/100, Batch: 8/143, Loss: 0.24274082481861115\n",
    "Epoch: 1/100, Batch: 9/143, Loss: 0.19001471996307373\n",
    "Current step: 76.5\n",
    "Epoch: 1/100, Batch: 10/143, Loss: 0.11227892339229584\n",
    "Epoch: 1/100, Batch: 11/143, Loss: 0.1014869287610054\n",
    "Current step: 77.5\n",
    "Epoch: 1/100, Batch: 12/143, Loss: 0.07955038547515869\n",
    "Epoch: 1/100, Batch: 13/143, Loss: 0.04700420796871185\n",
    "Current step: 78.5\n",
    "Epoch: 1/100, Batch: 14/143, Loss: 0.08785226941108704\n",
    "Epoch: 1/100, Batch: 15/143, Loss: 0.07370555400848389\n",
    "Current step: 79.5\n",
    "Epoch: 1/100, Batch: 16/143, Loss: 0.10921623557806015\n",
    "Epoch: 1/100, Batch: 17/143, Loss: 0.10794811695814133\n",
    "Current step: 80.5\n",
    "Epoch: 1/100, Batch: 18/143, Loss: 0.06467406451702118\n",
    "Epoch: 1/100, Batch: 19/143, Loss: 0.0852159634232521\n",
    "Current step: 81.5\n",
    "Epoch: 1/100, Batch: 20/143, Loss: 0.04676610603928566\n",
    "Epoch: 1/100, Batch: 21/143, Loss: 0.04717804864048958\n",
    "Current step: 82.5\n",
    "Epoch: 1/100, Batch: 22/143, Loss: 0.05068983510136604\n",
    "Epoch: 1/100, Batch: 23/143, Loss: 0.05237460881471634\n",
    "Current step: 83.5\n",
    "Epoch: 1/100, Batch: 24/143, Loss: 0.07350849360227585\n",
    "Epoch: 1/100, Batch: 25/143, Loss: 0.07426567375659943\n",
    "Current step: 84.5\n",
    "Epoch: 1/100, Batch: 26/143, Loss: 0.07237850874662399\n",
    "Epoch: 1/100, Batch: 27/143, Loss: 0.07334005832672119\n",
    "Current step: 85.5\n",
    "Epoch: 1/100, Batch: 28/143, Loss: 0.03719643875956535\n",
    "Epoch: 1/100, Batch: 29/143, Loss: 0.03652923181653023\n",
    "Current step: 86.5\n",
    "Epoch: 1/100, Batch: 30/143, Loss: 0.02186608500778675\n",
    "Epoch: 1/100, Batch: 31/143, Loss: 0.022082822397351265\n",
    "Current step: 87.5\n",
    "Epoch: 1/100, Batch: 32/143, Loss: 0.07630233466625214\n",
    "Epoch: 1/100, Batch: 33/143, Loss: 0.0774058848619461\n",
    "Current step: 88.5\n",
    "Epoch: 1/100, Batch: 34/143, Loss: 0.02706124633550644\n",
    "Epoch: 1/100, Batch: 35/143, Loss: 0.06494566053152084\n",
    "Current step: 89.5\n",
    "Epoch: 1/100, Batch: 36/143, Loss: 0.020964184775948524\n",
    "Epoch: 1/100, Batch: 37/143, Loss: 0.02098061330616474\n",
    "Current step: 90.5\n",
    "Epoch: 1/100, Batch: 38/143, Loss: 0.02473311498761177\n",
    "Epoch: 1/100, Batch: 39/143, Loss: 0.02497311308979988\n",
    "Current step: 91.5\n",
    "Epoch: 1/100, Batch: 40/143, Loss: 0.02853982150554657\n",
    "Epoch: 1/100, Batch: 41/143, Loss: 0.028320368379354477\n",
    "Current step: 92.5\n",
    "Epoch: 1/100, Batch: 42/143, Loss: 0.01664087362587452\n",
    "Epoch: 1/100, Batch: 43/143, Loss: 0.016641277819871902\n",
    "Current step: 93.5\n",
    "Epoch: 1/100, Batch: 44/143, Loss: 0.026904882863163948\n",
    "Epoch: 1/100, Batch: 45/143, Loss: 0.02161499857902527\n",
    "Current step: 94.5\n",
    "Epoch: 1/100, Batch: 46/143, Loss: 0.02878093719482422\n",
    "Epoch: 1/100, Batch: 47/143, Loss: 0.02474602498114109\n",
    "Current step: 95.5\n",
    "Epoch: 1/100, Batch: 48/143, Loss: 0.04269026964902878\n",
    "Epoch: 1/100, Batch: 49/143, Loss: 0.017097584903240204\n",
    "Current step: 96.5\n",
    "Epoch: 1/100, Batch: 50/143, Loss: 0.01626334711909294\n",
    "Epoch: 1/100, Batch: 51/143, Loss: 0.014466900378465652\n",
    "Current step: 97.5\n",
    "Epoch: 1/100, Batch: 52/143, Loss: 0.0216099563986063\n",
    "Epoch: 1/100, Batch: 53/143, Loss: 0.02132297120988369\n",
    "Current step: 98.5\n",
    "Epoch: 1/100, Batch: 54/143, Loss: 0.013569523580372334\n",
    "Epoch: 1/100, Batch: 55/143, Loss: 0.01322400663048029\n",
    "Current step: 99.5\n",
    "Epoch: 1/100, Batch: 56/143, Loss: 0.014393605291843414\n",
    "Epoch: 1/100, Batch: 57/143, Loss: 0.01690666750073433\n",
    "Current step: 100.5\n",
    "Epoch: 1/100, Batch: 58/143, Loss: 0.06615379452705383\n",
    "Epoch: 1/100, Batch: 59/143, Loss: 0.022433597594499588\n",
    "Current step: 101.5\n",
    "Epoch: 1/100, Batch: 60/143, Loss: 0.0944768413901329\n",
    "Epoch: 1/100, Batch: 61/143, Loss: 0.012854453176259995\n",
    "Current step: 102.5\n",
    "Epoch: 1/100, Batch: 62/143, Loss: 0.016041945666074753\n",
    "Epoch: 1/100, Batch: 63/143, Loss: 0.015488820150494576\n",
    "Current step: 103.5\n",
    "Epoch: 1/100, Batch: 64/143, Loss: 0.2143527865409851\n",
    "Epoch: 1/100, Batch: 65/143, Loss: 0.023270484060049057\n",
    "Current step: 104.5\n",
    "Epoch: 1/100, Batch: 66/143, Loss: 0.014075072482228279\n",
    "Epoch: 1/100, Batch: 67/143, Loss: 0.18408918380737305\n",
    "Current step: 105.5\n",
    "Epoch: 1/100, Batch: 68/143, Loss: 0.09750941395759583\n",
    "Epoch: 1/100, Batch: 69/143, Loss: 0.010594976134598255\n",
    "Current step: 106.5\n",
    "Epoch: 1/100, Batch: 70/143, Loss: 0.012189068831503391\n",
    "Epoch: 1/100, Batch: 71/143, Loss: 0.011903436854481697\n",
    "Current step: 107.5\n",
    "Epoch: 1/100, Batch: 72/143, Loss: 0.008046071976423264\n",
    "Epoch: 1/100, Batch: 73/143, Loss: 0.008069121278822422\n",
    "Current step: 108.5\n",
    "Epoch: 1/100, Batch: 74/143, Loss: 0.007270321249961853\n",
    "Epoch: 1/100, Batch: 75/143, Loss: 0.00830691959708929\n",
    "Current step: 109.5\n",
    "Epoch: 1/100, Batch: 76/143, Loss: 0.00916079431772232\n",
    "Epoch: 1/100, Batch: 77/143, Loss: 0.050296150147914886\n",
    "Current step: 110.5\n",
    "Epoch: 1/100, Batch: 78/143, Loss: 0.03178151696920395\n",
    "Epoch: 1/100, Batch: 79/143, Loss: 0.030478617176413536\n",
    "Current step: 111.5\n",
    "Epoch: 1/100, Batch: 80/143, Loss: 0.038990091532468796\n",
    "Epoch: 1/100, Batch: 81/143, Loss: 0.03951501473784447\n",
    "Current step: 112.5\n",
    "Epoch: 1/100, Batch: 82/143, Loss: 0.019129516556859016\n",
    "Epoch: 1/100, Batch: 83/143, Loss: 0.027510512620210648\n",
    "Current step: 113.5\n",
    "Epoch: 1/100, Batch: 84/143, Loss: 0.011278129182755947\n",
    "Epoch: 1/100, Batch: 85/143, Loss: 0.01123388484120369\n",
    "Current step: 114.5\n",
    "Epoch: 1/100, Batch: 86/143, Loss: 0.013391321524977684\n",
    "Epoch: 1/100, Batch: 87/143, Loss: 0.013626521453261375\n",
    "Current step: 115.5\n",
    "Epoch: 1/100, Batch: 88/143, Loss: 0.012151900678873062\n",
    "Epoch: 1/100, Batch: 89/143, Loss: 0.012271551415324211\n",
    "Current step: 116.5\n",
    "Epoch: 1/100, Batch: 90/143, Loss: 0.02100655995309353\n",
    "Epoch: 1/100, Batch: 91/143, Loss: 0.018691066652536392\n",
    "Current step: 117.5\n",
    "Epoch: 1/100, Batch: 92/143, Loss: 0.013012073934078217\n",
    "Epoch: 1/100, Batch: 93/143, Loss: 0.013115303590893745\n",
    "Current step: 118.5\n",
    "Epoch: 1/100, Batch: 94/143, Loss: 0.009005982428789139\n",
    "Epoch: 1/100, Batch: 95/143, Loss: 0.008451083675026894\n",
    "Current step: 119.5\n",
    "Epoch: 1/100, Batch: 96/143, Loss: 0.070442333817482\n",
    "Epoch: 1/100, Batch: 97/143, Loss: 0.07043026387691498\n",
    "Current step: 120.5\n",
    "Epoch: 1/100, Batch: 98/143, Loss: 0.08085717260837555\n",
    "Epoch: 1/100, Batch: 99/143, Loss: 0.012524951249361038\n",
    "Current step: 121.5\n",
    "Epoch: 1/100, Batch: 100/143, Loss: 0.011130976490676403\n",
    "Epoch: 1/100, Batch: 101/143, Loss: 0.0697527602314949\n",
    "Current step: 122.5\n",
    "Epoch: 1/100, Batch: 102/143, Loss: 0.031217899173498154\n",
    "Epoch: 1/100, Batch: 103/143, Loss: 0.031198587268590927\n",
    "Current step: 123.5\n",
    "Epoch: 1/100, Batch: 104/143, Loss: 0.03979529067873955\n",
    "Epoch: 1/100, Batch: 105/143, Loss: 0.038790784776210785\n",
    "Current step: 124.5\n",
    "Epoch: 1/100, Batch: 106/143, Loss: 0.024179402738809586\n",
    "Epoch: 1/100, Batch: 107/143, Loss: 0.02434765174984932\n",
    "Current step: 125.5\n",
    "Epoch: 1/100, Batch: 108/143, Loss: 0.01194292213767767\n",
    "Epoch: 1/100, Batch: 109/143, Loss: 0.01170993410050869\n",
    "Current step: 126.5\n",
    "Epoch: 1/100, Batch: 110/143, Loss: 0.014981523156166077\n",
    "Epoch: 1/100, Batch: 111/143, Loss: 0.014758077450096607\n",
    "Current step: 127.5\n",
    "Epoch: 1/100, Batch: 112/143, Loss: 0.017261946573853493\n",
    "Epoch: 1/100, Batch: 113/143, Loss: 0.045515742152929306\n",
    "Current step: 128.5\n",
    "Epoch: 1/100, Batch: 114/143, Loss: 0.03521403670310974\n",
    "Epoch: 1/100, Batch: 115/143, Loss: 0.03551749885082245\n",
    "Current step: 129.5\n",
    "Epoch: 1/100, Batch: 116/143, Loss: 0.027383005246520042\n",
    "Epoch: 1/100, Batch: 117/143, Loss: 0.0222025066614151\n",
    "Current step: 130.5\n",
    "Epoch: 1/100, Batch: 118/143, Loss: 0.03263671323657036\n",
    "Epoch: 1/100, Batch: 119/143, Loss: 0.017682135105133057\n",
    "Current step: 131.5\n",
    "Epoch: 1/100, Batch: 120/143, Loss: 0.034423455595970154\n",
    "Epoch: 1/100, Batch: 121/143, Loss: 0.007392726372927427\n",
    "Current step: 132.5\n",
    "Epoch: 1/100, Batch: 122/143, Loss: 0.015397338196635246\n",
    "Epoch: 1/100, Batch: 123/143, Loss: 0.016465961933135986\n",
    "Current step: 133.5\n",
    "Epoch: 1/100, Batch: 124/143, Loss: 0.022393709048628807\n",
    "Epoch: 1/100, Batch: 125/143, Loss: 0.021955672651529312\n",
    "Current step: 134.5\n",
    "Epoch: 1/100, Batch: 126/143, Loss: 0.09205761551856995\n",
    "Epoch: 1/100, Batch: 127/143, Loss: 0.01437272597104311\n",
    "Current step: 135.5\n",
    "Epoch: 1/100, Batch: 128/143, Loss: 0.1639489382505417\n",
    "Epoch: 1/100, Batch: 129/143, Loss: 0.01552500855177641\n",
    "Current step: 136.5\n",
    "Epoch: 1/100, Batch: 130/143, Loss: 0.01866246573626995\n",
    "Epoch: 1/100, Batch: 131/143, Loss: 0.018801873549818993\n",
    "Current step: 137.5\n",
    "Epoch: 1/100, Batch: 132/143, Loss: 0.010818189941346645\n",
    "Epoch: 1/100, Batch: 133/143, Loss: 0.18581484258174896\n",
    "Current step: 138.5\n",
    "Epoch: 1/100, Batch: 134/143, Loss: 0.01116001233458519\n",
    "Epoch: 1/100, Batch: 135/143, Loss: 0.008402423933148384\n",
    "Current step: 139.5\n",
    "Epoch: 1/100, Batch: 136/143, Loss: 0.013577291741967201\n",
    "Epoch: 1/100, Batch: 137/143, Loss: 0.012023134157061577\n",
    "Current step: 140.5\n",
    "Epoch: 1/100, Batch: 138/143, Loss: 0.006617147009819746\n",
    "Epoch: 1/100, Batch: 139/143, Loss: 0.00623888848349452\n",
    "Current step: 141.5\n",
    "Epoch: 1/100, Batch: 140/143, Loss: 0.011483018286526203\n",
    "Epoch: 1/100, Batch: 141/143, Loss: 0.011410682462155819\n",
    "Current step: 142.5\n",
    "Epoch: 1/100, Batch: 142/143, Loss: 0.015256664715707302\n",
    "Epoch: 2/100, Batch: 0/143, Loss: 0.01546813640743494\n",
    "Epoch: 2/100, Batch: 1/143, Loss: 0.01567099615931511\n",
    "Current step: 144.0\n",
    "Epoch: 2/100, Batch: 2/143, Loss: 0.011619784869253635\n",
    "Epoch: 2/100, Batch: 3/143, Loss: 0.15193501114845276\n",
    "Current step: 145.0\n",
    "Epoch: 2/100, Batch: 4/143, Loss: 0.020648697391152382\n",
    "Epoch: 2/100, Batch: 5/143, Loss: 0.020512660965323448\n",
    "Current step: 146.0\n",
    "Epoch: 2/100, Batch: 6/143, Loss: 0.02468539960682392\n",
    "Epoch: 2/100, Batch: 7/143, Loss: 0.02511146478354931\n",
    "Current step: 147.0\n",
    "Epoch: 2/100, Batch: 8/143, Loss: 0.01505105197429657\n",
    "Epoch: 2/100, Batch: 9/143, Loss: 0.04432864487171173\n",
    "Current step: 148.0\n",
    "Epoch: 2/100, Batch: 10/143, Loss: 0.022143471986055374\n",
    "Epoch: 2/100, Batch: 11/143, Loss: 0.016644056886434555\n",
    "Current step: 149.0\n",
    "Epoch: 2/100, Batch: 12/143, Loss: 0.048035360872745514\n",
    "Epoch: 2/100, Batch: 13/143, Loss: 0.05035490542650223\n",
    "Current step: 150.0\n",
    "Epoch: 2/100, Batch: 14/143, Loss: 0.05787845700979233\n",
    "Epoch: 2/100, Batch: 15/143, Loss: 0.032466307282447815\n",
    "Current step: 151.0\n",
    "Epoch: 2/100, Batch: 16/143, Loss: 0.05274214595556259\n",
    "Epoch: 2/100, Batch: 17/143, Loss: 0.04987368732690811\n",
    "Current step: 152.0\n",
    "Epoch: 2/100, Batch: 18/143, Loss: 0.026345841586589813\n",
    "Epoch: 2/100, Batch: 19/143, Loss: 0.03022262081503868\n",
    "Current step: 153.0\n",
    "Epoch: 2/100, Batch: 20/143, Loss: 0.011371508240699768\n",
    "Epoch: 2/100, Batch: 21/143, Loss: 0.011090988293290138\n",
    "Current step: 154.0\n",
    "Epoch: 2/100, Batch: 22/143, Loss: 0.014550169929862022\n",
    "Epoch: 2/100, Batch: 23/143, Loss: 0.014726785942912102\n",
    "Current step: 155.0\n",
    "Epoch: 2/100, Batch: 24/143, Loss: 0.02617361955344677\n",
    "Epoch: 2/100, Batch: 25/143, Loss: 0.052998218685388565\n",
    "Current step: 156.0\n",
    "Epoch: 2/100, Batch: 26/143, Loss: 0.04680684953927994\n",
    "Epoch: 2/100, Batch: 27/143, Loss: 0.03573012351989746\n",
    "Current step: 157.0\n",
    "Epoch: 2/100, Batch: 28/143, Loss: 0.07278542965650558\n",
    "Epoch: 2/100, Batch: 29/143, Loss: 0.07389175146818161\n",
    "Current step: 158.0\n",
    "Epoch: 2/100, Batch: 30/143, Loss: 0.08264242112636566\n",
    "Epoch: 2/100, Batch: 31/143, Loss: 0.0827721431851387\n",
    "Current step: 159.0\n",
    "Epoch: 2/100, Batch: 32/143, Loss: 0.0657443031668663\n",
    "Epoch: 2/100, Batch: 33/143, Loss: 0.06700355559587479\n",
    "Current step: 160.0\n",
    "Epoch: 2/100, Batch: 34/143, Loss: 0.040464796125888824\n",
    "Epoch: 2/100, Batch: 35/143, Loss: 0.04033457115292549\n",
    "Current step: 161.0\n",
    "Epoch: 2/100, Batch: 36/143, Loss: 0.029187653213739395\n",
    "Epoch: 2/100, Batch: 37/143, Loss: 0.029434209689497948\n",
    "Current step: 162.0\n",
    "Epoch: 2/100, Batch: 38/143, Loss: 0.03809850290417671\n",
    "Epoch: 2/100, Batch: 39/143, Loss: 0.02519446611404419\n",
    "Current step: 163.0\n",
    "Epoch: 2/100, Batch: 40/143, Loss: 0.018247824162244797\n",
    "Epoch: 2/100, Batch: 41/143, Loss: 0.018620464950799942\n",
    "Current step: 164.0\n",
    "Epoch: 2/100, Batch: 42/143, Loss: 0.01801251247525215\n",
    "Epoch: 2/100, Batch: 43/143, Loss: 0.01764751225709915\n",
    "Current step: 165.0\n",
    "Epoch: 2/100, Batch: 44/143, Loss: 0.022235415875911713\n",
    "Epoch: 2/100, Batch: 45/143, Loss: 0.02198525331914425\n",
    "Current step: 166.0\n",
    "Epoch: 2/100, Batch: 46/143, Loss: 0.01896742917597294\n",
    "Epoch: 2/100, Batch: 47/143, Loss: 0.018489008769392967\n",
    "Current step: 167.0\n",
    "Epoch: 2/100, Batch: 48/143, Loss: 0.017819566652178764\n",
    "Epoch: 2/100, Batch: 49/143, Loss: 0.11377307772636414\n",
    "Current step: 168.0\n",
    "Epoch: 2/100, Batch: 50/143, Loss: 0.06333781033754349\n",
    "Epoch: 2/100, Batch: 51/143, Loss: 0.06245237588882446\n",
    "Current step: 169.0\n",
    "Epoch: 2/100, Batch: 52/143, Loss: 0.12510979175567627\n",
    "Epoch: 2/100, Batch: 53/143, Loss: 0.043221209198236465\n",
    "Current step: 170.0\n",
    "Epoch: 2/100, Batch: 54/143, Loss: 0.04609609395265579\n",
    "Epoch: 2/100, Batch: 55/143, Loss: 0.04733387008309364\n",
    "Current step: 171.0\n",
    "Epoch: 2/100, Batch: 56/143, Loss: 0.25218456983566284\n",
    "Epoch: 2/100, Batch: 57/143, Loss: 0.25140392780303955\n",
    "Current step: 172.0\n",
    "Epoch: 2/100, Batch: 58/143, Loss: 0.03324427828192711\n",
    "Epoch: 2/100, Batch: 59/143, Loss: 0.23209413886070251\n",
    "Current step: 173.0\n",
    "Epoch: 2/100, Batch: 60/143, Loss: 0.03508302941918373\n",
    "Epoch: 2/100, Batch: 61/143, Loss: 0.17302167415618896\n",
    "Current step: 174.0\n",
    "Epoch: 2/100, Batch: 62/143, Loss: 0.11468546837568283\n",
    "Epoch: 2/100, Batch: 63/143, Loss: 0.1151183471083641\n",
    "Current step: 175.0\n",
    "Epoch: 2/100, Batch: 64/143, Loss: 0.08908302336931229\n",
    "Epoch: 2/100, Batch: 65/143, Loss: 0.08771981298923492\n",
    "Current step: 176.0\n",
    "Epoch: 2/100, Batch: 66/143, Loss: 0.20667652785778046\n",
    "Epoch: 2/100, Batch: 67/143, Loss: 0.08510564267635345\n",
    "Current step: 177.0\n",
    "Epoch: 2/100, Batch: 68/143, Loss: 0.07678468525409698\n",
    "Epoch: 2/100, Batch: 69/143, Loss: 0.254131942987442\n",
    "Current step: 178.0\n",
    "Epoch: 2/100, Batch: 70/143, Loss: 0.05833353102207184\n",
    "Epoch: 2/100, Batch: 71/143, Loss: 0.05849809572100639\n",
    "Current step: 179.0\n",
    "Epoch: 2/100, Batch: 72/143, Loss: 0.032103195786476135\n",
    "Epoch: 2/100, Batch: 73/143, Loss: 0.1382482498884201\n",
    "Current step: 180.0\n",
    "Epoch: 2/100, Batch: 74/143, Loss: 0.029651477932929993\n",
    "Epoch: 2/100, Batch: 75/143, Loss: 0.029511984437704086\n",
    "Current step: 181.0\n",
    "Epoch: 2/100, Batch: 76/143, Loss: 0.03543251380324364\n",
    "Epoch: 2/100, Batch: 77/143, Loss: 0.03704074025154114\n",
    "Current step: 182.0\n",
    "Epoch: 2/100, Batch: 78/143, Loss: 0.039787471294403076\n",
    "Epoch: 2/100, Batch: 79/143, Loss: 0.04007183015346527\n",
    "Current step: 183.0\n",
    "Epoch: 2/100, Batch: 80/143, Loss: 0.01775532402098179\n",
    "Epoch: 2/100, Batch: 81/143, Loss: 0.01776334084570408\n",
    "Current step: 184.0\n",
    "Epoch: 2/100, Batch: 82/143, Loss: 0.01171919796615839\n",
    "Epoch: 2/100, Batch: 83/143, Loss: 0.00761681143194437\n",
    "Current step: 185.0\n",
    "Epoch: 2/100, Batch: 84/143, Loss: 0.02541307359933853\n",
    "Epoch: 2/100, Batch: 85/143, Loss: 0.025943798944354057\n",
    "Current step: 186.0\n",
    "Epoch: 2/100, Batch: 86/143, Loss: 0.04169383645057678\n",
    "Epoch: 2/100, Batch: 87/143, Loss: 0.04106002300977707\n",
    "Current step: 187.0\n",
    "Epoch: 2/100, Batch: 88/143, Loss: 0.04754774644970894\n",
    "Epoch: 2/100, Batch: 89/143, Loss: 0.036084190011024475\n",
    "Current step: 188.0\n",
    "Epoch: 2/100, Batch: 90/143, Loss: 0.019222406670451164\n",
    "Epoch: 2/100, Batch: 91/143, Loss: 0.018971528857946396\n",
    "Current step: 189.0\n",
    "Epoch: 2/100, Batch: 92/143, Loss: 0.016067037358880043\n",
    "Epoch: 2/100, Batch: 93/143, Loss: 0.016013309359550476\n",
    "Current step: 190.0\n",
    "Epoch: 2/100, Batch: 94/143, Loss: 0.02322457730770111\n",
    "Epoch: 2/100, Batch: 95/143, Loss: 0.0499517060816288\n",
    "Current step: 191.0\n",
    "Epoch: 2/100, Batch: 96/143, Loss: 0.022662127390503883\n",
    "Epoch: 2/100, Batch: 97/143, Loss: 0.022636787965893745\n",
    "Current step: 192.0\n",
    "Epoch: 2/100, Batch: 98/143, Loss: 0.01629822701215744\n",
    "Epoch: 2/100, Batch: 99/143, Loss: 0.016594473272562027\n",
    "Current step: 193.0\n",
    "Epoch: 2/100, Batch: 100/143, Loss: 0.015599459409713745\n",
    "Epoch: 2/100, Batch: 101/143, Loss: 0.015891874209046364\n",
    "Current step: 194.0\n",
    "Epoch: 2/100, Batch: 102/143, Loss: 0.028226584196090698\n",
    "Epoch: 2/100, Batch: 103/143, Loss: 0.016199704259634018\n",
    "Current step: 195.0\n",
    "Epoch: 2/100, Batch: 104/143, Loss: 0.009937616996467113\n",
    "Epoch: 2/100, Batch: 105/143, Loss: 0.010426267981529236\n",
    "Current step: 196.0\n",
    "Epoch: 2/100, Batch: 106/143, Loss: 0.003615020075812936\n",
    "Epoch: 2/100, Batch: 107/143, Loss: 0.00383196328766644\n",
    "Current step: 197.0\n",
    "Epoch: 2/100, Batch: 108/143, Loss: 0.02567458525300026\n",
    "Epoch: 2/100, Batch: 109/143, Loss: 0.005374181549996138\n",
    "Current step: 198.0\n",
    "Epoch: 2/100, Batch: 110/143, Loss: 0.004519775044173002\n",
    "Epoch: 2/100, Batch: 111/143, Loss: 0.004495341330766678\n",
    "Current step: 199.0\n",
    "Epoch: 2/100, Batch: 112/143, Loss: 0.037659574300050735\n",
    "Epoch: 2/100, Batch: 113/143, Loss: 0.00411183713003993\n",
    "Current step: 200.0\n",
    "Epoch: 2/100, Batch: 114/143, Loss: 0.0038626811001449823\n",
    "Epoch: 2/100, Batch: 115/143, Loss: 0.002912241267040372\n",
    "Current step: 201.0\n",
    "Epoch: 2/100, Batch: 116/143, Loss: 0.026360495015978813\n",
    "Epoch: 2/100, Batch: 117/143, Loss: 0.028999123722314835\n",
    "Current step: 202.0\n",
    "Epoch: 2/100, Batch: 118/143, Loss: 0.008455871604382992\n",
    "Epoch: 2/100, Batch: 119/143, Loss: 0.013492288067936897\n",
    "Current step: 203.0\n",
    "Epoch: 2/100, Batch: 120/143, Loss: 0.030440006405115128\n",
    "Epoch: 2/100, Batch: 121/143, Loss: 0.030899150297045708\n",
    "Current step: 204.0\n",
    "Epoch: 2/100, Batch: 122/143, Loss: 0.03965609148144722\n",
    "Epoch: 2/100, Batch: 123/143, Loss: 0.04058664292097092\n",
    "Current step: 205.0\n",
    "Epoch: 2/100, Batch: 124/143, Loss: 0.029902685433626175\n",
    "Epoch: 2/100, Batch: 125/143, Loss: 0.02936745434999466\n",
    "Current step: 206.0\n",
    "Epoch: 2/100, Batch: 126/143, Loss: 0.010850399732589722\n",
    "Epoch: 2/100, Batch: 127/143, Loss: 0.01241637859493494\n",
    "Current step: 207.0\n",
    "Epoch: 2/100, Batch: 128/143, Loss: 0.014500584453344345\n",
    "Epoch: 2/100, Batch: 129/143, Loss: 0.007795984391123056\n",
    "Current step: 208.0\n",
    "Epoch: 2/100, Batch: 130/143, Loss: 0.012742972932755947\n",
    "Epoch: 2/100, Batch: 131/143, Loss: 0.04608401283621788\n",
    "Current step: 209.0\n",
    "Epoch: 2/100, Batch: 132/143, Loss: 0.06510034948587418\n",
    "Epoch: 2/100, Batch: 133/143, Loss: 0.017004195600748062\n",
    "Current step: 210.0\n",
    "Epoch: 2/100, Batch: 134/143, Loss: 0.010530101135373116\n",
    "Epoch: 2/100, Batch: 135/143, Loss: 0.06060018762946129\n",
    "Current step: 211.0\n",
    "Epoch: 2/100, Batch: 136/143, Loss: 0.014734901487827301\n",
    "Epoch: 2/100, Batch: 137/143, Loss: 0.03363659232854843\n",
    "Current step: 212.0\n",
    "Epoch: 2/100, Batch: 138/143, Loss: 0.05636400729417801\n",
    "Epoch: 2/100, Batch: 139/143, Loss: 0.008864584378898144\n",
    "Current step: 213.0\n",
    "Epoch: 2/100, Batch: 140/143, Loss: 0.020027397200465202\n",
    "Epoch: 2/100, Batch: 141/143, Loss: 0.16097401082515717\n",
    "Current step: 214.0\n",
    "Epoch: 2/100, Batch: 142/143, Loss: 0.050103042274713516\n",
    "Epoch: 3/100, Batch: 0/143, Loss: 0.23122499883174896\n",
    "Epoch: 3/100, Batch: 1/143, Loss: 0.23078124225139618\n",
    "Current step: 215.5\n",
    "Epoch: 3/100, Batch: 2/143, Loss: 0.06537950038909912\n",
    "Epoch: 3/100, Batch: 3/143, Loss: 0.2313029021024704\n",
    "Current step: 216.5\n",
    "Epoch: 3/100, Batch: 4/143, Loss: 0.16740624606609344\n",
    "Epoch: 3/100, Batch: 5/143, Loss: 0.1701185405254364\n",
    "Current step: 217.5\n",
    "Epoch: 3/100, Batch: 6/143, Loss: 0.08322270959615707\n",
    "Epoch: 3/100, Batch: 7/143, Loss: 0.08326995372772217\n",
    "Current step: 218.5\n",
    "Epoch: 3/100, Batch: 8/143, Loss: 0.021458910778164864\n",
    "Epoch: 3/100, Batch: 9/143, Loss: 0.021072089672088623\n",
    "Current step: 219.5\n",
    "Epoch: 3/100, Batch: 10/143, Loss: 0.031057190150022507\n",
    "Epoch: 3/100, Batch: 11/143, Loss: 0.007784092333167791\n",
    "Current step: 220.5\n",
    "Epoch: 3/100, Batch: 12/143, Loss: 0.01740100048482418\n",
    "Epoch: 3/100, Batch: 13/143, Loss: 0.017536194995045662\n",
    "Current step: 221.5\n",
    "Epoch: 3/100, Batch: 14/143, Loss: 0.01598299853503704\n",
    "Epoch: 3/100, Batch: 15/143, Loss: 0.01575547829270363\n",
    "Current step: 222.5\n",
    "Epoch: 3/100, Batch: 16/143, Loss: 0.006140552926808596\n",
    "Epoch: 3/100, Batch: 17/143, Loss: 0.16202682256698608\n",
    "Current step: 223.5\n",
    "Epoch: 3/100, Batch: 18/143, Loss: 0.12876538932323456\n",
    "Epoch: 3/100, Batch: 19/143, Loss: 0.007836995646357536\n",
    "Current step: 224.5\n",
    "Epoch: 3/100, Batch: 20/143, Loss: 0.01227464247494936\n",
    "Epoch: 3/100, Batch: 21/143, Loss: 0.13134562969207764\n",
    "Current step: 225.5\n",
    "Epoch: 3/100, Batch: 22/143, Loss: 0.03033209964632988\n",
    "Epoch: 3/100, Batch: 23/143, Loss: 0.03038250282406807\n",
    "Current step: 226.5\n",
    "Epoch: 3/100, Batch: 24/143, Loss: 0.031647682189941406\n",
    "Epoch: 3/100, Batch: 25/143, Loss: 0.031930338591337204\n",
    "Current step: 227.5\n",
    "Epoch: 3/100, Batch: 26/143, Loss: 0.014755950309336185\n",
    "Epoch: 3/100, Batch: 27/143, Loss: 0.016352513805031776\n",
    "Current step: 228.5\n",
    "Epoch: 3/100, Batch: 28/143, Loss: 0.003470510244369507\n",
    "Epoch: 3/100, Batch: 29/143, Loss: 0.003717471146956086\n",
    "Current step: 229.5\n",
    "Epoch: 3/100, Batch: 30/143, Loss: 0.013586544431746006\n",
    "Epoch: 3/100, Batch: 31/143, Loss: 0.013937147334218025\n",
    "Current step: 230.5\n",
    "Epoch: 3/100, Batch: 32/143, Loss: 0.023445896804332733\n",
    "Epoch: 3/100, Batch: 33/143, Loss: 0.025013141334056854\n",
    "Current step: 231.5\n",
    "Epoch: 3/100, Batch: 34/143, Loss: 0.2558448910713196\n",
    "Epoch: 3/100, Batch: 35/143, Loss: 0.2554037570953369\n",
    "Current step: 232.5\n",
    "Epoch: 3/100, Batch: 36/143, Loss: 0.18431149423122406\n",
    "Epoch: 3/100, Batch: 37/143, Loss: 0.008327914401888847\n",
    "Current step: 233.5\n",
    "Epoch: 3/100, Batch: 38/143, Loss: 0.007252122741192579\n",
    "Epoch: 3/100, Batch: 39/143, Loss: 0.007273681927472353\n",
    "Current step: 234.5\n",
    "Epoch: 3/100, Batch: 40/143, Loss: 0.01206188090145588\n",
    "Epoch: 3/100, Batch: 41/143, Loss: 0.01219973061233759\n",
    "Current step: 235.5\n",
    "Epoch: 3/100, Batch: 42/143, Loss: 0.008791147731244564\n",
    "Epoch: 3/100, Batch: 43/143, Loss: 0.008615829050540924\n",
    "Current step: 236.5\n",
    "Epoch: 3/100, Batch: 44/143, Loss: 0.07864174991846085\n",
    "Epoch: 3/100, Batch: 45/143, Loss: 0.08242763578891754\n",
    "Current step: 237.5\n",
    "Epoch: 3/100, Batch: 46/143, Loss: 0.0686449408531189\n",
    "Epoch: 3/100, Batch: 47/143, Loss: 0.003385033691301942\n",
    "Current step: 238.5\n",
    "Epoch: 3/100, Batch: 48/143, Loss: 0.0024003349244594574\n",
    "Epoch: 3/100, Batch: 49/143, Loss: 0.046870362013578415\n",
    "Current step: 239.5\n",
    "Epoch: 3/100, Batch: 50/143, Loss: 0.005191761534661055\n",
    "Epoch: 3/100, Batch: 51/143, Loss: 0.005077866837382317\n",
    "Current step: 240.5\n",
    "Epoch: 3/100, Batch: 52/143, Loss: 0.0047955382615327835\n",
    "Epoch: 3/100, Batch: 53/143, Loss: 0.004977577831596136\n",
    "Current step: 241.5\n",
    "Epoch: 3/100, Batch: 54/143, Loss: 0.0028562680818140507\n",
    "Epoch: 3/100, Batch: 55/143, Loss: 0.0029026565607637167\n",
    "Current step: 242.5\n",
    "Epoch: 3/100, Batch: 56/143, Loss: 0.009756013751029968\n",
    "Epoch: 3/100, Batch: 57/143, Loss: 0.0029855596367269754\n",
    "Current step: 243.5\n",
    "Epoch: 3/100, Batch: 58/143, Loss: 0.0029334865976125\n",
    "Epoch: 3/100, Batch: 59/143, Loss: 0.0025976812466979027\n",
    "Current step: 244.5\n",
    "Epoch: 3/100, Batch: 60/143, Loss: 0.02442110888659954\n",
    "Epoch: 3/100, Batch: 61/143, Loss: 0.02234751731157303\n",
    "Current step: 245.5\n",
    "Epoch: 3/100, Batch: 62/143, Loss: 0.014880234375596046\n",
    "Epoch: 3/100, Batch: 63/143, Loss: 0.0021773227490484715\n",
    "Current step: 246.5\n",
    "Epoch: 3/100, Batch: 64/143, Loss: 0.002562294714152813\n",
    "Epoch: 3/100, Batch: 65/143, Loss: 0.010890702717006207\n",
    "Current step: 247.5\n",
    "Epoch: 3/100, Batch: 66/143, Loss: 0.006848615128546953\n",
    "Epoch: 3/100, Batch: 67/143, Loss: 0.008758224546909332\n",
    "Current step: 248.5\n",
    "Epoch: 3/100, Batch: 68/143, Loss: 0.008206339552998543\n",
    "Epoch: 3/100, Batch: 69/143, Loss: 0.007298423442989588\n",
    "Current step: 249.5\n",
    "Epoch: 3/100, Batch: 70/143, Loss: 0.0028813404496759176\n",
    "Epoch: 3/100, Batch: 71/143, Loss: 0.002991040237247944\n",
    "Current step: 250.5\n",
    "Epoch: 3/100, Batch: 72/143, Loss: 0.008458662778139114\n",
    "Epoch: 3/100, Batch: 73/143, Loss: 0.007091892883181572\n",
    "Current step: 251.5\n",
    "Epoch: 3/100, Batch: 74/143, Loss: 0.006302579306066036\n",
    "Epoch: 3/100, Batch: 75/143, Loss: 0.006340832449495792\n",
    "Current step: 252.5\n",
    "Epoch: 3/100, Batch: 76/143, Loss: 0.00535585405305028\n",
    "Epoch: 3/100, Batch: 77/143, Loss: 0.01517410110682249\n",
    "Current step: 253.5\n",
    "Epoch: 3/100, Batch: 78/143, Loss: 0.02120339684188366\n",
    "Epoch: 3/100, Batch: 79/143, Loss: 0.005097636021673679\n",
    "Current step: 254.5\n",
    "Epoch: 3/100, Batch: 80/143, Loss: 0.006469516549259424\n",
    "Epoch: 3/100, Batch: 81/143, Loss: 0.006532158702611923\n",
    "Current step: 255.5\n",
    "Epoch: 3/100, Batch: 82/143, Loss: 0.12636330723762512\n",
    "Epoch: 3/100, Batch: 83/143, Loss: 0.013884383253753185\n",
    "Current step: 256.5\n",
    "Epoch: 3/100, Batch: 84/143, Loss: 0.011752325110137463\n",
    "Epoch: 3/100, Batch: 85/143, Loss: 0.1422772854566574\n",
    "Current step: 257.5\n",
    "Epoch: 3/100, Batch: 86/143, Loss: 0.1151079311966896\n",
    "Epoch: 3/100, Batch: 87/143, Loss: 0.004374949261546135\n",
    "Current step: 258.5\n",
    "Epoch: 3/100, Batch: 88/143, Loss: 0.0681147500872612\n",
    "Epoch: 3/100, Batch: 89/143, Loss: 0.006088390480726957\n",
    "Current step: 259.5\n",
    "Epoch: 3/100, Batch: 90/143, Loss: 0.011535817757248878\n",
    "Epoch: 3/100, Batch: 91/143, Loss: 0.011520829051733017\n",
    "Current step: 260.5\n",
    "Epoch: 3/100, Batch: 92/143, Loss: 0.008028022013604641\n",
    "Epoch: 3/100, Batch: 93/143, Loss: 0.007998429238796234\n",
    "Current step: 261.5\n",
    "Epoch: 3/100, Batch: 94/143, Loss: 0.0991453304886818\n",
    "Epoch: 3/100, Batch: 95/143, Loss: 0.0998324379324913\n",
    "Current step: 262.5\n",
    "Epoch: 3/100, Batch: 96/143, Loss: 0.0031635623890906572\n",
    "Epoch: 3/100, Batch: 97/143, Loss: 0.003013713750988245\n",
    "Current step: 263.5\n",
    "Epoch: 3/100, Batch: 98/143, Loss: 0.07598607242107391\n",
    "Epoch: 3/100, Batch: 99/143, Loss: 0.001690630684606731\n",
    "Current step: 264.5\n",
    "Epoch: 3/100, Batch: 100/143, Loss: 0.06686414033174515\n",
    "Epoch: 3/100, Batch: 101/143, Loss: 0.0024487485643476248\n",
    "Current step: 265.5\n",
    "Epoch: 3/100, Batch: 102/143, Loss: 0.002124095568433404\n",
    "Epoch: 3/100, Batch: 103/143, Loss: 0.070224829018116\n",
    "Current step: 266.5\n",
    "Epoch: 3/100, Batch: 104/143, Loss: 0.002017262624576688\n",
    "Epoch: 3/100, Batch: 105/143, Loss: 0.002047722926363349\n",
    "Current step: 267.5\n",
    "Epoch: 3/100, Batch: 106/143, Loss: 0.0018810323672369123\n",
    "Epoch: 3/100, Batch: 107/143, Loss: 0.001787900342606008\n",
    "Current step: 268.5\n",
    "Epoch: 3/100, Batch: 108/143, Loss: 0.0019362318562343717\n",
    "Epoch: 3/100, Batch: 109/143, Loss: 0.0018292504828423262\n",
    "Current step: 269.5\n",
    "Epoch: 3/100, Batch: 110/143, Loss: 0.001206559012643993\n",
    "Epoch: 3/100, Batch: 111/143, Loss: 0.0015049492940306664\n",
    "Current step: 270.5\n",
    "Epoch: 3/100, Batch: 112/143, Loss: 0.0124438451603055\n",
    "Epoch: 3/100, Batch: 113/143, Loss: 0.001875436631962657\n",
    "Current step: 271.5\n",
    "Epoch: 3/100, Batch: 114/143, Loss: 0.011493532918393612\n",
    "Epoch: 3/100, Batch: 115/143, Loss: 0.0017100860131904483\n",
    "Current step: 272.5\n",
    "Epoch: 3/100, Batch: 116/143, Loss: 0.0014969288604333997\n",
    "Epoch: 3/100, Batch: 117/143, Loss: 0.0014772422146052122\n",
    "Current step: 273.5\n",
    "Epoch: 3/100, Batch: 118/143, Loss: 0.0016336098778992891\n",
    "Epoch: 3/100, Batch: 119/143, Loss: 0.006030155811458826\n",
    "Current step: 274.5\n",
    "Epoch: 3/100, Batch: 120/143, Loss: 0.00567777082324028\n",
    "Epoch: 3/100, Batch: 121/143, Loss: 0.007768593728542328\n",
    "Current step: 275.5\n",
    "Epoch: 3/100, Batch: 122/143, Loss: 0.006029317621141672\n",
    "Epoch: 3/100, Batch: 123/143, Loss: 0.006050444673746824\n",
    "Current step: 276.5\n",
    "Epoch: 3/100, Batch: 124/143, Loss: 0.004636112600564957\n",
    "Epoch: 3/100, Batch: 125/143, Loss: 0.0045351749286055565\n",
    "Current step: 277.5\n",
    "Epoch: 3/100, Batch: 126/143, Loss: 0.011498834006488323\n",
    "Epoch: 3/100, Batch: 127/143, Loss: 0.009721516631543636\n",
    "Current step: 278.5\n",
    "Epoch: 3/100, Batch: 128/143, Loss: 0.0144805321469903\n",
    "Epoch: 3/100, Batch: 129/143, Loss: 0.01287088543176651\n",
    "Current step: 279.5\n",
    "Epoch: 3/100, Batch: 130/143, Loss: 0.007048160303384066\n",
    "Epoch: 3/100, Batch: 131/143, Loss: 0.0077791097573935986\n",
    "Current step: 280.5\n",
    "Epoch: 3/100, Batch: 132/143, Loss: 0.006167608313262463\n",
    "Epoch: 3/100, Batch: 133/143, Loss: 0.002696751616895199\n",
    "Current step: 281.5\n",
    "Epoch: 3/100, Batch: 134/143, Loss: 0.026746323332190514\n",
    "Epoch: 3/100, Batch: 135/143, Loss: 0.007263958919793367\n",
    "Current step: 282.5\n",
    "Epoch: 3/100, Batch: 136/143, Loss: 0.009707001969218254\n",
    "Epoch: 3/100, Batch: 137/143, Loss: 0.009705640375614166\n",
    "Current step: 283.5\n",
    "Epoch: 3/100, Batch: 138/143, Loss: 0.005520437378436327\n",
    "Epoch: 3/100, Batch: 139/143, Loss: 0.004781853407621384\n",
    "Current step: 284.5\n",
    "Epoch: 3/100, Batch: 140/143, Loss: 0.005169048439711332\n",
    "Epoch: 3/100, Batch: 141/143, Loss: 0.005243184510618448\n",
    "Current step: 285.5\n",
    "Epoch: 3/100, Batch: 142/143, Loss: 0.007549544330686331\n",
    "Epoch: 4/100, Batch: 0/143, Loss: 0.006317972671240568\n",
    "Epoch: 4/100, Batch: 1/143, Loss: 0.007468859199434519\n",
    "Current step: 287.0\n",
    "Epoch: 4/100, Batch: 2/143, Loss: 0.0019365816842764616\n",
    "Epoch: 4/100, Batch: 3/143, Loss: 0.002370271133258939\n",
    "Current step: 288.0\n",
    "Epoch: 4/100, Batch: 4/143, Loss: 0.0046275099739432335\n",
    "Epoch: 4/100, Batch: 5/143, Loss: 0.004562712740153074\n",
    "Current step: 289.0\n",
    "Epoch: 4/100, Batch: 6/143, Loss: 0.007540329825133085\n",
    "Epoch: 4/100, Batch: 7/143, Loss: 0.007506645750254393\n",
    "Current step: 290.0\n",
    "Epoch: 4/100, Batch: 8/143, Loss: 0.003717133542522788\n",
    "Epoch: 4/100, Batch: 9/143, Loss: 0.08722461760044098\n",
    "Current step: 291.0\n",
    "Epoch: 4/100, Batch: 10/143, Loss: 0.0038540009409189224\n",
    "Epoch: 4/100, Batch: 11/143, Loss: 0.00388796697370708\n",
    "Current step: 292.0\n",
    "Epoch: 4/100, Batch: 12/143, Loss: 0.004586368799209595\n",
    "Epoch: 4/100, Batch: 13/143, Loss: 0.003600153373554349\n",
    "Current step: 293.0\n",
    "Epoch: 4/100, Batch: 14/143, Loss: 0.038592319935560226\n",
    "Epoch: 4/100, Batch: 15/143, Loss: 0.001876523718237877\n",
    "Current step: 294.0\n",
    "Epoch: 4/100, Batch: 16/143, Loss: 0.005439660977572203\n",
    "Epoch: 4/100, Batch: 17/143, Loss: 0.06201746314764023\n",
    "Current step: 295.0\n",
    "Epoch: 4/100, Batch: 18/143, Loss: 0.008215110749006271\n",
    "Epoch: 4/100, Batch: 19/143, Loss: 0.05569647625088692\n",
    "Current step: 296.0\n",
    "Epoch: 4/100, Batch: 20/143, Loss: 0.0060526481829583645\n",
    "Epoch: 4/100, Batch: 21/143, Loss: 0.006095093209296465\n",
    "Current step: 297.0\n",
    "Epoch: 4/100, Batch: 22/143, Loss: 0.0030701872892677784\n",
    "Epoch: 4/100, Batch: 23/143, Loss: 0.0032867002300918102\n",
    "Current step: 298.0\n",
    "Epoch: 4/100, Batch: 24/143, Loss: 0.0032506228890269995\n",
    "Epoch: 4/100, Batch: 25/143, Loss: 0.003955226857215166\n",
    "Current step: 299.0\n",
    "Epoch: 4/100, Batch: 26/143, Loss: 0.004239211790263653\n",
    "Epoch: 4/100, Batch: 27/143, Loss: 0.004034361336380243\n",
    "Current step: 300.0\n",
    "Epoch: 4/100, Batch: 28/143, Loss: 0.0038480705115944147\n",
    "Epoch: 4/100, Batch: 29/143, Loss: 0.003928936552256346\n",
    "Current step: 301.0\n",
    "Epoch: 4/100, Batch: 30/143, Loss: 0.004047208931297064\n",
    "Epoch: 4/100, Batch: 31/143, Loss: 0.00407461216673255\n",
    "Current step: 302.0\n",
    "Epoch: 4/100, Batch: 32/143, Loss: 0.0025527349207550287\n",
    "Epoch: 4/100, Batch: 33/143, Loss: 0.0025274858344346285\n",
    "Current step: 303.0\n",
    "Epoch: 4/100, Batch: 34/143, Loss: 0.0036278716288506985\n",
    "Epoch: 4/100, Batch: 35/143, Loss: 0.003550071269273758\n",
    "Current step: 304.0\n",
    "Epoch: 4/100, Batch: 36/143, Loss: 0.015562881715595722\n",
    "Epoch: 4/100, Batch: 37/143, Loss: 0.015536148101091385\n",
    "Current step: 305.0\n",
    "Epoch: 4/100, Batch: 38/143, Loss: 0.003612681059166789\n",
    "Epoch: 4/100, Batch: 39/143, Loss: 0.0036757993511855602\n",
    "Current step: 306.0\n",
    "Epoch: 4/100, Batch: 40/143, Loss: 0.0037353530060499907\n",
    "Epoch: 4/100, Batch: 41/143, Loss: 0.0036795397754758596\n",
    "Current step: 307.0\n",
    "Epoch: 4/100, Batch: 42/143, Loss: 0.002135781105607748\n",
    "Epoch: 4/100, Batch: 43/143, Loss: 0.0019157089991495013\n",
    "Current step: 308.0\n",
    "Epoch: 4/100, Batch: 44/143, Loss: 0.0028972153086215258\n",
    "Epoch: 4/100, Batch: 45/143, Loss: 0.0030061216093599796\n",
    "Current step: 309.0\n",
    "Epoch: 4/100, Batch: 46/143, Loss: 0.002989577129483223\n",
    "Epoch: 4/100, Batch: 47/143, Loss: 0.003043942619115114\n",
    "Current step: 310.0\n",
    "Epoch: 4/100, Batch: 48/143, Loss: 0.007655316032469273\n",
    "Epoch: 4/100, Batch: 49/143, Loss: 0.002857884857803583\n",
    "Current step: 311.0\n",
    "Epoch: 4/100, Batch: 50/143, Loss: 0.0021301975939422846\n",
    "Epoch: 4/100, Batch: 51/143, Loss: 0.006946637760847807\n",
    "Current step: 312.0\n",
    "Epoch: 4/100, Batch: 52/143, Loss: 0.002551920711994171\n",
    "Epoch: 4/100, Batch: 53/143, Loss: 0.0035781702026724815\n",
    "Current step: 313.0\n",
    "Epoch: 4/100, Batch: 54/143, Loss: 0.004161588381975889\n",
    "Epoch: 4/100, Batch: 55/143, Loss: 0.004423967562615871\n",
    "Current step: 314.0\n",
    "Epoch: 4/100, Batch: 56/143, Loss: 0.005568940658122301\n",
    "Epoch: 4/100, Batch: 57/143, Loss: 0.005230466835200787\n",
    "Current step: 315.0\n",
    "Epoch: 4/100, Batch: 58/143, Loss: 0.004164856858551502\n",
    "Epoch: 4/100, Batch: 59/143, Loss: 0.004202459938824177\n",
    "Current step: 316.0\n",
    "Epoch: 4/100, Batch: 60/143, Loss: 0.0030335988849401474\n",
    "Epoch: 4/100, Batch: 61/143, Loss: 0.00579071044921875\n",
    "Current step: 317.0\n",
    "Epoch: 4/100, Batch: 62/143, Loss: 0.007375696208328009\n",
    "Epoch: 4/100, Batch: 63/143, Loss: 0.007367389742285013\n",
    "Current step: 318.0\n",
    "Epoch: 4/100, Batch: 64/143, Loss: 0.008052642457187176\n",
    "Epoch: 4/100, Batch: 65/143, Loss: 0.008257732726633549\n",
    "Current step: 319.0\n",
    "Epoch: 4/100, Batch: 66/143, Loss: 0.003936550579965115\n",
    "Epoch: 4/100, Batch: 67/143, Loss: 0.005198055412620306\n",
    "Current step: 320.0\n",
    "Epoch: 4/100, Batch: 68/143, Loss: 0.006852603051811457\n",
    "Epoch: 4/100, Batch: 69/143, Loss: 0.00710100494325161\n",
    "Current step: 321.0\n",
    "Epoch: 4/100, Batch: 70/143, Loss: 0.0123000992462039\n",
    "Epoch: 4/100, Batch: 71/143, Loss: 0.00899343192577362\n",
    "Current step: 322.0\n",
    "Epoch: 4/100, Batch: 72/143, Loss: 0.005757920444011688\n",
    "Epoch: 4/100, Batch: 73/143, Loss: 0.0056353225372731686\n",
    "Current step: 323.0\n",
    "Epoch: 4/100, Batch: 74/143, Loss: 0.004531228914856911\n",
    "Epoch: 4/100, Batch: 75/143, Loss: 0.0044886451214551926\n",
    "Current step: 324.0\n",
    "Epoch: 4/100, Batch: 76/143, Loss: 0.004803777206689119\n",
    "Epoch: 4/100, Batch: 77/143, Loss: 0.006591878365725279\n",
    "Current step: 325.0\n",
    "Epoch: 4/100, Batch: 78/143, Loss: 0.003864848054945469\n",
    "Epoch: 4/100, Batch: 79/143, Loss: 0.0038423414807766676\n",
    "Current step: 326.0\n",
    "Epoch: 4/100, Batch: 80/143, Loss: 0.008162799291312695\n",
    "Epoch: 4/100, Batch: 81/143, Loss: 0.004331936128437519\n",
    "Current step: 327.0\n",
    "Epoch: 4/100, Batch: 82/143, Loss: 0.003863690886646509\n",
    "Epoch: 4/100, Batch: 83/143, Loss: 0.0038041884545236826\n",
    "Current step: 328.0\n",
    "Epoch: 4/100, Batch: 84/143, Loss: 0.0018113788682967424\n",
    "Epoch: 4/100, Batch: 85/143, Loss: 0.0017660274170339108\n",
    "Current step: 329.0\n",
    "Epoch: 4/100, Batch: 86/143, Loss: 0.0034445864148437977\n",
    "Epoch: 4/100, Batch: 87/143, Loss: 0.003346837591379881\n",
    "Current step: 330.0\n",
    "Epoch: 4/100, Batch: 88/143, Loss: 0.009616628289222717\n",
    "Epoch: 4/100, Batch: 89/143, Loss: 0.0033330146688967943\n",
    "Current step: 331.0\n",
    "Epoch: 4/100, Batch: 90/143, Loss: 0.01946713961660862\n",
    "Epoch: 4/100, Batch: 91/143, Loss: 0.0026963094715029\n",
    "Current step: 332.0\n",
    "Epoch: 4/100, Batch: 92/143, Loss: 0.002502182964235544\n",
    "Epoch: 4/100, Batch: 93/143, Loss: 0.02193225733935833\n",
    "Current step: 333.0\n",
    "Epoch: 4/100, Batch: 94/143, Loss: 0.0025441159959882498\n",
    "Epoch: 4/100, Batch: 95/143, Loss: 0.012144804932177067\n",
    "Current step: 334.0\n",
    "Epoch: 4/100, Batch: 96/143, Loss: 0.005791857838630676\n",
    "Epoch: 4/100, Batch: 97/143, Loss: 0.005822756327688694\n",
    "Current step: 335.0\n",
    "Epoch: 4/100, Batch: 98/143, Loss: 0.019547706469893456\n",
    "Epoch: 4/100, Batch: 99/143, Loss: 0.018445780500769615\n",
    "Current step: 336.0\n",
    "Epoch: 4/100, Batch: 100/143, Loss: 0.017952777445316315\n",
    "Epoch: 4/100, Batch: 101/143, Loss: 0.01006366964429617\n",
    "Current step: 337.0\n",
    "Epoch: 4/100, Batch: 102/143, Loss: 0.005956313107162714\n",
    "Epoch: 4/100, Batch: 103/143, Loss: 0.010271781124174595\n",
    "Current step: 338.0\n",
    "Epoch: 4/100, Batch: 104/143, Loss: 0.005327780265361071\n",
    "Epoch: 4/100, Batch: 105/143, Loss: 0.0054945386946201324\n",
    "Current step: 339.0\n",
    "Epoch: 4/100, Batch: 106/143, Loss: 0.016928771510720253\n",
    "Epoch: 4/100, Batch: 107/143, Loss: 0.017128290608525276\n",
    "Current step: 340.0\n",
    "Epoch: 4/100, Batch: 108/143, Loss: 0.013851235620677471\n",
    "Epoch: 4/100, Batch: 109/143, Loss: 0.014365767128765583\n",
    "Current step: 341.0\n",
    "Epoch: 4/100, Batch: 110/143, Loss: 0.006718757562339306\n",
    "Epoch: 4/100, Batch: 111/143, Loss: 0.00619107810780406\n",
    "Current step: 342.0\n",
    "Epoch: 4/100, Batch: 112/143, Loss: 0.009063438512384892\n",
    "Epoch: 4/100, Batch: 113/143, Loss: 0.009077640250325203\n",
    "Current step: 343.0\n",
    "Epoch: 4/100, Batch: 114/143, Loss: 0.00962008722126484\n",
    "Epoch: 4/100, Batch: 115/143, Loss: 0.00969025120139122\n",
    "Current step: 344.0\n",
    "Epoch: 4/100, Batch: 116/143, Loss: 0.0329148955643177\n",
    "Epoch: 4/100, Batch: 117/143, Loss: 0.006767637096345425\n",
    "Current step: 345.0\n",
    "Epoch: 4/100, Batch: 118/143, Loss: 0.0022930996492505074\n",
    "Epoch: 4/100, Batch: 119/143, Loss: 0.0023686408530920744\n",
    "Current step: 346.0\n",
    "Epoch: 4/100, Batch: 120/143, Loss: 0.0049533359706401825\n",
    "Epoch: 4/100, Batch: 121/143, Loss: 0.004984492436051369\n",
    "Current step: 347.0\n",
    "Epoch: 4/100, Batch: 122/143, Loss: 0.009040623903274536\n",
    "Epoch: 4/100, Batch: 123/143, Loss: 0.009213556535542011\n",
    "Current step: 348.0\n",
    "Epoch: 4/100, Batch: 124/143, Loss: 0.007619758602231741\n",
    "Epoch: 4/100, Batch: 125/143, Loss: 0.007536831311881542\n",
    "Current step: 349.0\n",
    "Epoch: 4/100, Batch: 126/143, Loss: 0.004494613502174616\n",
    "Epoch: 4/100, Batch: 127/143, Loss: 0.07397955656051636\n",
    "Current step: 350.0\n",
    "Epoch: 4/100, Batch: 128/143, Loss: 0.07600666582584381\n",
    "Epoch: 4/100, Batch: 129/143, Loss: 0.004118874669075012\n",
    "Current step: 351.0\n",
    "Epoch: 4/100, Batch: 130/143, Loss: 0.05974126234650612\n",
    "Epoch: 4/100, Batch: 131/143, Loss: 0.002046011621132493\n",
    "Current step: 352.0\n",
    "Epoch: 4/100, Batch: 132/143, Loss: 0.0026728238444775343\n",
    "Epoch: 4/100, Batch: 133/143, Loss: 0.0025744186714291573\n",
    "Current step: 353.0\n",
    "Epoch: 4/100, Batch: 134/143, Loss: 0.0024112879764288664\n",
    "Epoch: 4/100, Batch: 135/143, Loss: 0.06050273776054382\n",
    "Current step: 354.0\n",
    "Epoch: 4/100, Batch: 136/143, Loss: 0.04212048649787903\n",
    "Epoch: 4/100, Batch: 137/143, Loss: 0.0037278467789292336\n",
    "Current step: 355.0\n",
    "Epoch: 4/100, Batch: 138/143, Loss: 0.04307638108730316\n",
    "Epoch: 4/100, Batch: 139/143, Loss: 0.002640696242451668\n",
    "Current step: 356.0\n",
    "Epoch: 4/100, Batch: 140/143, Loss: 0.002223874209448695\n",
    "Epoch: 4/100, Batch: 141/143, Loss: 0.002123486716300249\n",
    "Current step: 357.0\n",
    "Epoch: 4/100, Batch: 142/143, Loss: 0.001983806723728776\n",
    "Epoch: 5/100, Batch: 0/143, Loss: 0.032098155468702316\n",
    "Epoch: 5/100, Batch: 1/143, Loss: 0.0020172768272459507\n",
    "Current step: 358.5\n",
    "Epoch: 5/100, Batch: 2/143, Loss: 0.002184937009587884\n",
    "Epoch: 5/100, Batch: 3/143, Loss: 0.0021435113158077\n",
    "Current step: 359.5\n",
    "Epoch: 5/100, Batch: 4/143, Loss: 0.024584995582699776\n",
    "Epoch: 5/100, Batch: 5/143, Loss: 0.0019616074860095978\n",
    "Current step: 360.5\n",
    "Epoch: 5/100, Batch: 6/143, Loss: 0.0020663493778556585\n",
    "Epoch: 5/100, Batch: 7/143, Loss: 0.0021411855705082417\n",
    "Current step: 361.5\n",
    "Epoch: 5/100, Batch: 8/143, Loss: 0.0016634248895570636\n",
    "Epoch: 5/100, Batch: 9/143, Loss: 0.017448095604777336\n",
    "Current step: 362.5\n",
    "Epoch: 5/100, Batch: 10/143, Loss: 0.005262717138975859\n",
    "Epoch: 5/100, Batch: 11/143, Loss: 0.0057999384589493275\n",
    "Current step: 363.5\n",
    "Epoch: 5/100, Batch: 12/143, Loss: 0.022702187299728394\n",
    "Epoch: 5/100, Batch: 13/143, Loss: 0.009417682886123657\n",
    "Current step: 364.5\n",
    "Epoch: 5/100, Batch: 14/143, Loss: 0.01844657212495804\n",
    "Epoch: 5/100, Batch: 15/143, Loss: 0.033532336354255676\n",
    "Current step: 365.5\n",
    "Epoch: 5/100, Batch: 16/143, Loss: 0.029880721122026443\n",
    "Epoch: 5/100, Batch: 17/143, Loss: 0.029849277809262276\n",
    "Current step: 366.5\n",
    "Epoch: 5/100, Batch: 18/143, Loss: 0.011681153438985348\n",
    "Epoch: 5/100, Batch: 19/143, Loss: 0.013907212764024734\n",
    "Current step: 367.5\n",
    "Epoch: 5/100, Batch: 20/143, Loss: 0.00443410687148571\n",
    "Epoch: 5/100, Batch: 21/143, Loss: 0.004758861381560564\n",
    "Current step: 368.5\n",
    "Epoch: 5/100, Batch: 22/143, Loss: 0.00937800295650959\n",
    "Epoch: 5/100, Batch: 23/143, Loss: 0.00920249242335558\n",
    "Current step: 369.5\n",
    "Epoch: 5/100, Batch: 24/143, Loss: 0.014466451480984688\n",
    "Epoch: 5/100, Batch: 25/143, Loss: 0.007137228734791279\n",
    "Current step: 370.5\n",
    "Epoch: 5/100, Batch: 26/143, Loss: 0.011510958895087242\n",
    "Epoch: 5/100, Batch: 27/143, Loss: 0.004760803189128637\n",
    "Current step: 371.5\n",
    "Epoch: 5/100, Batch: 28/143, Loss: 0.006321208085864782\n",
    "Epoch: 5/100, Batch: 29/143, Loss: 0.006234288215637207\n",
    "Current step: 372.5\n",
    "Epoch: 5/100, Batch: 30/143, Loss: 0.025972643867135048\n",
    "Epoch: 5/100, Batch: 31/143, Loss: 0.0032517958898097277\n",
    "Current step: 373.5\n",
    "Epoch: 5/100, Batch: 32/143, Loss: 0.04447142779827118\n",
    "Epoch: 5/100, Batch: 33/143, Loss: 0.004556822590529919\n",
    "Current step: 374.5\n",
    "Epoch: 5/100, Batch: 34/143, Loss: 0.0032576152589172125\n",
    "Epoch: 5/100, Batch: 35/143, Loss: 0.003312563756480813\n",
    "Current step: 375.5\n",
    "Epoch: 5/100, Batch: 36/143, Loss: 0.04267234727740288\n",
    "Epoch: 5/100, Batch: 37/143, Loss: 0.0440659373998642\n",
    "Current step: 376.5\n",
    "Epoch: 5/100, Batch: 38/143, Loss: 0.015656836330890656\n",
    "Epoch: 5/100, Batch: 39/143, Loss: 0.01570630818605423\n",
    "Current step: 377.5\n",
    "Epoch: 5/100, Batch: 40/143, Loss: 0.024415628984570503\n",
    "Epoch: 5/100, Batch: 41/143, Loss: 0.02453593909740448\n",
    "Current step: 378.5\n",
    "Epoch: 5/100, Batch: 42/143, Loss: 0.02032211236655712\n",
    "Epoch: 5/100, Batch: 43/143, Loss: 0.02050497755408287\n",
    "Current step: 379.5\n",
    "Epoch: 5/100, Batch: 44/143, Loss: 0.008185204118490219\n",
    "Epoch: 5/100, Batch: 45/143, Loss: 0.008282352238893509\n",
    "Current step: 380.5\n",
    "Epoch: 5/100, Batch: 46/143, Loss: 0.06516049057245255\n",
    "Epoch: 5/100, Batch: 47/143, Loss: 0.06442166864871979\n",
    "Current step: 381.5\n",
    "Epoch: 5/100, Batch: 48/143, Loss: 0.007819714955985546\n",
    "Epoch: 5/100, Batch: 49/143, Loss: 0.007877505384385586\n",
    "Current step: 382.5\n",
    "Epoch: 5/100, Batch: 50/143, Loss: 0.007920796051621437\n",
    "Epoch: 5/100, Batch: 51/143, Loss: 0.008054242469370365\n",
    "Current step: 383.5\n",
    "Epoch: 5/100, Batch: 52/143, Loss: 0.0032942425459623337\n",
    "Epoch: 5/100, Batch: 53/143, Loss: 0.04452434927225113\n",
    "Current step: 384.5\n",
    "Epoch: 5/100, Batch: 54/143, Loss: 0.003850062843412161\n",
    "Epoch: 5/100, Batch: 55/143, Loss: 0.003532680217176676\n",
    "Current step: 385.5\n",
    "Epoch: 5/100, Batch: 56/143, Loss: 0.007906393148005009\n",
    "Epoch: 5/100, Batch: 57/143, Loss: 0.007863285951316357\n",
    "Current step: 386.5\n",
    "Epoch: 5/100, Batch: 58/143, Loss: 0.00567478034645319\n",
    "Epoch: 5/100, Batch: 59/143, Loss: 0.0158227551728487\n",
    "Current step: 387.5\n",
    "Epoch: 5/100, Batch: 60/143, Loss: 0.01835823990404606\n",
    "Epoch: 5/100, Batch: 61/143, Loss: 0.01076324563473463\n",
    "Current step: 388.5\n",
    "Epoch: 5/100, Batch: 62/143, Loss: 0.013200121931731701\n",
    "Epoch: 5/100, Batch: 63/143, Loss: 0.013247624970972538\n",
    "Current step: 389.5\n",
    "Epoch: 5/100, Batch: 64/143, Loss: 0.0037195971235632896\n",
    "Epoch: 5/100, Batch: 65/143, Loss: 0.005736137740314007\n",
    "Current step: 390.5\n",
    "Epoch: 5/100, Batch: 66/143, Loss: 0.004312248434871435\n",
    "Epoch: 5/100, Batch: 67/143, Loss: 0.007816042751073837\n",
    "Current step: 391.5\n",
    "Epoch: 5/100, Batch: 68/143, Loss: 0.007315936032682657\n",
    "Epoch: 5/100, Batch: 69/143, Loss: 0.007363430690020323\n",
    "Current step: 392.5\n",
    "Epoch: 5/100, Batch: 70/143, Loss: 0.013505259528756142\n",
    "Epoch: 5/100, Batch: 71/143, Loss: 0.004825148265808821\n",
    "Current step: 393.5\n",
    "Epoch: 5/100, Batch: 72/143, Loss: 0.007383414544165134\n",
    "Epoch: 5/100, Batch: 73/143, Loss: 0.007758795283734798\n",
    "Current step: 394.5\n",
    "Epoch: 5/100, Batch: 74/143, Loss: 0.01822936348617077\n",
    "Epoch: 5/100, Batch: 75/143, Loss: 0.002061521401628852\n",
    "Current step: 395.5\n",
    "Epoch: 5/100, Batch: 76/143, Loss: 0.006231145933270454\n",
    "Epoch: 5/100, Batch: 77/143, Loss: 0.00656184321269393\n",
    "Current step: 396.5\n",
    "Epoch: 5/100, Batch: 78/143, Loss: 0.010777480900287628\n",
    "Epoch: 5/100, Batch: 79/143, Loss: 0.010677648708224297\n",
    "Current step: 397.5\n",
    "Epoch: 5/100, Batch: 80/143, Loss: 0.007034836336970329\n",
    "Epoch: 5/100, Batch: 81/143, Loss: 0.007461502216756344\n",
    "Current step: 398.5\n",
    "Epoch: 5/100, Batch: 82/143, Loss: 0.0021928087808191776\n",
    "Epoch: 5/100, Batch: 83/143, Loss: 0.06753864139318466\n",
    "Current step: 399.5\n",
    "Epoch: 5/100, Batch: 84/143, Loss: 0.007896902039647102\n",
    "Epoch: 5/100, Batch: 85/143, Loss: 0.007804075721651316\n",
    "Current step: 400.5\n",
    "Epoch: 5/100, Batch: 86/143, Loss: 0.015013244934380054\n",
    "Epoch: 5/100, Batch: 87/143, Loss: 0.02452833391726017\n",
    "Current step: 401.5\n",
    "Epoch: 5/100, Batch: 88/143, Loss: 0.008108681999146938\n",
    "Epoch: 5/100, Batch: 89/143, Loss: 0.03503047302365303\n",
    "Current step: 402.5\n",
    "Epoch: 5/100, Batch: 90/143, Loss: 0.04221725091338158\n",
    "Epoch: 5/100, Batch: 91/143, Loss: 0.04210386052727699\n",
    "Current step: 403.5\n",
    "Epoch: 5/100, Batch: 92/143, Loss: 0.033071305602788925\n",
    "Epoch: 5/100, Batch: 93/143, Loss: 0.004755689296871424\n",
    "Current step: 404.5\n",
    "Epoch: 5/100, Batch: 94/143, Loss: 0.03587670996785164\n",
    "Epoch: 5/100, Batch: 95/143, Loss: 0.03550071641802788\n",
    "Current step: 405.5\n",
    "Epoch: 5/100, Batch: 96/143, Loss: 0.02490946650505066\n",
    "Epoch: 5/100, Batch: 97/143, Loss: 0.02487168088555336\n",
    "Current step: 406.5\n",
    "Epoch: 5/100, Batch: 98/143, Loss: 0.008899048902094364\n",
    "Epoch: 5/100, Batch: 99/143, Loss: 0.008828763850033283\n",
    "Current step: 407.5\n",
    "Epoch: 5/100, Batch: 100/143, Loss: 0.0025679999962449074\n",
    "Epoch: 5/100, Batch: 101/143, Loss: 0.01356801763176918\n",
    "Current step: 408.5\n",
    "Epoch: 5/100, Batch: 102/143, Loss: 0.009327424690127373\n",
    "Epoch: 5/100, Batch: 103/143, Loss: 0.017375942319631577\n",
    "Current step: 409.5\n",
    "Epoch: 5/100, Batch: 104/143, Loss: 0.010426338762044907\n",
    "Epoch: 5/100, Batch: 105/143, Loss: 0.010442633181810379\n",
    "Current step: 410.5\n",
    "Epoch: 5/100, Batch: 106/143, Loss: 0.003112747799605131\n",
    "Epoch: 5/100, Batch: 107/143, Loss: 0.009950279258191586\n",
    "Current step: 411.5\n",
    "Epoch: 5/100, Batch: 108/143, Loss: 0.012835994362831116\n",
    "Epoch: 5/100, Batch: 109/143, Loss: 0.01267019473016262\n",
    "Current step: 412.5\n",
    "Epoch: 5/100, Batch: 110/143, Loss: 0.0018989511299878359\n",
    "Epoch: 5/100, Batch: 111/143, Loss: 0.0019456204026937485\n",
    "Current step: 413.5\n",
    "Epoch: 5/100, Batch: 112/143, Loss: 0.04246486350893974\n",
    "Epoch: 5/100, Batch: 113/143, Loss: 0.0021298329811543226\n",
    "Current step: 414.5\n",
    "Epoch: 5/100, Batch: 114/143, Loss: 0.04827234894037247\n",
    "Epoch: 5/100, Batch: 115/143, Loss: 0.001569364801980555\n",
    "Current step: 415.5\n",
    "Epoch: 5/100, Batch: 116/143, Loss: 0.0020495972130447626\n",
    "Epoch: 5/100, Batch: 117/143, Loss: 0.0018333876505494118\n",
    "Current step: 416.5\n",
    "Epoch: 5/100, Batch: 118/143, Loss: 0.05535266548395157\n",
    "Epoch: 5/100, Batch: 119/143, Loss: 0.0015640562633052468\n",
    "Current step: 417.5\n",
    "Epoch: 5/100, Batch: 120/143, Loss: 0.0017887238645926118\n",
    "Epoch: 5/100, Batch: 121/143, Loss: 0.0017736197914928198\n",
    "Current step: 418.5\n",
    "Epoch: 5/100, Batch: 122/143, Loss: 0.08033062517642975\n",
    "Epoch: 5/100, Batch: 123/143, Loss: 0.001354065490886569\n",
    "Current step: 419.5\n",
    "Epoch: 5/100, Batch: 124/143, Loss: 0.07370805740356445\n",
    "Epoch: 5/100, Batch: 125/143, Loss: 0.0015649668639525771\n",
    "Current step: 420.5\n",
    "Epoch: 5/100, Batch: 126/143, Loss: 0.0013320177095010877\n",
    "Epoch: 5/100, Batch: 127/143, Loss: 0.0012338971719145775\n",
    "Current step: 421.5\n",
    "Epoch: 5/100, Batch: 128/143, Loss: 0.0014015320921316743\n",
    "Epoch: 5/100, Batch: 129/143, Loss: 0.10526824742555618\n",
    "Current step: 422.5\n",
    "Epoch: 5/100, Batch: 130/143, Loss: 0.001282456680200994\n",
    "Epoch: 5/100, Batch: 131/143, Loss: 0.0012906083138659596\n",
    "Current step: 423.5\n",
    "Epoch: 5/100, Batch: 132/143, Loss: 0.07545232772827148\n",
    "Epoch: 5/100, Batch: 133/143, Loss: 0.0014766197418794036\n",
    "Current step: 424.5\n",
    "Epoch: 5/100, Batch: 134/143, Loss: 0.0752163901925087\n",
    "Epoch: 5/100, Batch: 135/143, Loss: 0.0011167858028784394\n",
    "Current step: 425.5\n",
    "Epoch: 5/100, Batch: 136/143, Loss: 0.0012989880051463842\n",
    "Epoch: 5/100, Batch: 137/143, Loss: 0.001222074730321765\n",
    "Current step: 426.5\n",
    "Epoch: 5/100, Batch: 138/143, Loss: 0.001119692693464458\n",
    "Epoch: 5/100, Batch: 139/143, Loss: 0.0011221868917346\n",
    "Current step: 427.5\n",
    "Epoch: 5/100, Batch: 140/143, Loss: 0.0012404535664245486\n",
    "Epoch: 5/100, Batch: 141/143, Loss: 0.06178601086139679\n",
    "Current step: 428.5\n",
    "Epoch: 5/100, Batch: 142/143, Loss: 0.005720535293221474\n",
    "Epoch: 6/100, Batch: 0/143, Loss: 0.005655545275658369\n",
    "Epoch: 6/100, Batch: 1/143, Loss: 0.005724642425775528\n",
    "Current step: 430.0\n",
    "Epoch: 6/100, Batch: 2/143, Loss: 0.005828073248267174\n",
    "Epoch: 6/100, Batch: 3/143, Loss: 0.005712928716093302\n",
    "Current step: 431.0\n",
    "Epoch: 6/100, Batch: 4/143, Loss: 0.0016300935531035066\n",
    "Epoch: 6/100, Batch: 5/143, Loss: 0.0016110980650410056\n",
    "Current step: 432.0\n",
    "Epoch: 6/100, Batch: 6/143, Loss: 0.0048971641808748245\n",
    "Epoch: 6/100, Batch: 7/143, Loss: 0.004747357685118914\n",
    "Current step: 433.0\n",
    "Epoch: 6/100, Batch: 8/143, Loss: 0.00882450956851244\n",
    "Epoch: 6/100, Batch: 9/143, Loss: 0.055183544754981995\n",
    "Current step: 434.0\n",
    "Epoch: 6/100, Batch: 10/143, Loss: 0.0064795734360814095\n",
    "Epoch: 6/100, Batch: 11/143, Loss: 0.006591551937162876\n",
    "Current step: 435.0\n",
    "Epoch: 6/100, Batch: 12/143, Loss: 0.014320299960672855\n",
    "Epoch: 6/100, Batch: 13/143, Loss: 0.001420786720700562\n",
    "Current step: 436.0\n",
    "Epoch: 6/100, Batch: 14/143, Loss: 0.00432937266305089\n",
    "Epoch: 6/100, Batch: 15/143, Loss: 0.0055919247679412365\n",
    "Current step: 437.0\n",
    "Epoch: 6/100, Batch: 16/143, Loss: 0.005900657270103693\n",
    "Epoch: 6/100, Batch: 17/143, Loss: 0.005891402717679739\n",
    "Current step: 438.0\n",
    "Epoch: 6/100, Batch: 18/143, Loss: 0.0074313790537416935\n",
    "Epoch: 6/100, Batch: 19/143, Loss: 0.007406673394143581\n",
    "Current step: 439.0\n",
    "Epoch: 6/100, Batch: 20/143, Loss: 0.003089958569034934\n",
    "Epoch: 6/100, Batch: 21/143, Loss: 0.002245844341814518\n",
    "Current step: 440.0\n",
    "Epoch: 6/100, Batch: 22/143, Loss: 0.005454848986119032\n",
    "Epoch: 6/100, Batch: 23/143, Loss: 0.005516084376722574\n",
    "Current step: 441.0\n",
    "Epoch: 6/100, Batch: 24/143, Loss: 0.010869596153497696\n",
    "Epoch: 6/100, Batch: 25/143, Loss: 0.010879412293434143\n",
    "Current step: 442.0\n",
    "Epoch: 6/100, Batch: 26/143, Loss: 0.008910073898732662\n",
    "Epoch: 6/100, Batch: 27/143, Loss: 0.008859017863869667\n",
    "Current step: 443.0\n",
    "Epoch: 6/100, Batch: 28/143, Loss: 0.0030895243398845196\n",
    "Epoch: 6/100, Batch: 29/143, Loss: 0.0030737651977688074\n",
    "Current step: 444.0\n",
    "Epoch: 6/100, Batch: 30/143, Loss: 0.004207031801342964\n",
    "Epoch: 6/100, Batch: 31/143, Loss: 0.004149776417762041\n",
    "Current step: 445.0\n",
    "Epoch: 6/100, Batch: 32/143, Loss: 0.009280341677367687\n",
    "Epoch: 6/100, Batch: 33/143, Loss: 0.009360849857330322\n",
    "Current step: 446.0\n",
    "Epoch: 6/100, Batch: 34/143, Loss: 0.009090413339436054\n",
    "Epoch: 6/100, Batch: 35/143, Loss: 0.008746005594730377\n",
    "Current step: 447.0\n",
    "Epoch: 6/100, Batch: 36/143, Loss: 0.004288062918931246\n",
    "Epoch: 6/100, Batch: 37/143, Loss: 0.0038233017548918724\n",
    "Current step: 448.0\n",
    "Epoch: 6/100, Batch: 38/143, Loss: 0.002358904806897044\n",
    "Epoch: 6/100, Batch: 39/143, Loss: 0.0023864922113716602\n",
    "Current step: 449.0\n",
    "Epoch: 6/100, Batch: 40/143, Loss: 0.005137335974723101\n",
    "Epoch: 6/100, Batch: 41/143, Loss: 0.0014187722699716687\n",
    "Current step: 450.0\n",
    "Epoch: 6/100, Batch: 42/143, Loss: 0.003032334614545107\n",
    "Epoch: 6/100, Batch: 43/143, Loss: 0.00979604572057724\n",
    "Current step: 451.0\n",
    "Epoch: 6/100, Batch: 44/143, Loss: 0.0020794235169887543\n",
    "Epoch: 6/100, Batch: 45/143, Loss: 0.0021380921825766563\n",
    "Current step: 452.0\n",
    "Epoch: 6/100, Batch: 46/143, Loss: 0.0011750961421057582\n",
    "Epoch: 6/100, Batch: 47/143, Loss: 0.0012053691316395998\n",
    "Current step: 453.0\n",
    "Epoch: 6/100, Batch: 48/143, Loss: 0.004351264331489801\n",
    "Epoch: 6/100, Batch: 49/143, Loss: 0.004032551310956478\n",
    "Current step: 454.0\n",
    "Epoch: 6/100, Batch: 50/143, Loss: 0.005936828441917896\n",
    "Epoch: 6/100, Batch: 51/143, Loss: 0.006080905441194773\n",
    "Current step: 455.0\n",
    "Epoch: 6/100, Batch: 52/143, Loss: 0.006121163722127676\n",
    "Epoch: 6/100, Batch: 53/143, Loss: 0.0061597516760230064\n",
    "Current step: 456.0\n",
    "Epoch: 6/100, Batch: 54/143, Loss: 0.0035331568215042353\n",
    "Epoch: 6/100, Batch: 55/143, Loss: 0.002478815382346511\n",
    "Current step: 457.0\n",
    "Epoch: 6/100, Batch: 56/143, Loss: 0.0022825319319963455\n",
    "Epoch: 6/100, Batch: 57/143, Loss: 0.0023156425449997187\n",
    "Current step: 458.0\n",
    "Epoch: 6/100, Batch: 58/143, Loss: 0.004364087712019682\n",
    "Epoch: 6/100, Batch: 59/143, Loss: 0.007093721069395542\n",
    "Current step: 459.0\n",
    "Epoch: 6/100, Batch: 60/143, Loss: 0.0054311067797243595\n",
    "Epoch: 6/100, Batch: 61/143, Loss: 0.0054436130449175835\n",
    "Current step: 460.0\n",
    "Epoch: 6/100, Batch: 62/143, Loss: 0.004358859732747078\n",
    "Epoch: 6/100, Batch: 63/143, Loss: 0.004338589496910572\n",
    "Current step: 461.0\n",
    "Epoch: 6/100, Batch: 64/143, Loss: 0.002207971177995205\n",
    "Epoch: 6/100, Batch: 65/143, Loss: 0.0041190446354448795\n",
    "Current step: 462.0\n",
    "Epoch: 6/100, Batch: 66/143, Loss: 0.001377515378408134\n",
    "Epoch: 6/100, Batch: 67/143, Loss: 0.0036782408133149147\n",
    "Current step: 463.0\n",
    "Epoch: 6/100, Batch: 68/143, Loss: 0.0037099614273756742\n",
    "Epoch: 6/100, Batch: 69/143, Loss: 0.0036855528596788645\n",
    "Current step: 464.0\n",
    "Epoch: 6/100, Batch: 70/143, Loss: 0.003790164366364479\n",
    "Epoch: 6/100, Batch: 71/143, Loss: 0.0036635117139667273\n",
    "Current step: 465.0\n",
    "Epoch: 6/100, Batch: 72/143, Loss: 0.0014272084226831794\n",
    "Epoch: 6/100, Batch: 73/143, Loss: 0.0028519921470433474\n",
    "Current step: 466.0\n",
    "Epoch: 6/100, Batch: 74/143, Loss: 0.00322134792804718\n",
    "Epoch: 6/100, Batch: 75/143, Loss: 0.0039177509024739265\n",
    "Current step: 467.0\n",
    "Epoch: 6/100, Batch: 76/143, Loss: 0.006457457784563303\n",
    "Epoch: 6/100, Batch: 77/143, Loss: 0.005898904986679554\n",
    "Current step: 468.0\n",
    "Epoch: 6/100, Batch: 78/143, Loss: 0.004606829956173897\n",
    "Epoch: 6/100, Batch: 79/143, Loss: 0.0041336072608828545\n",
    "Current step: 469.0\n",
    "Epoch: 6/100, Batch: 80/143, Loss: 0.0026057944633066654\n",
    "Epoch: 6/100, Batch: 81/143, Loss: 0.0025539568159729242\n",
    "Current step: 470.0\n",
    "Epoch: 6/100, Batch: 82/143, Loss: 0.0028108826372772455\n",
    "Epoch: 6/100, Batch: 83/143, Loss: 0.0013680679257959127\n",
    "Current step: 471.0\n",
    "Epoch: 6/100, Batch: 84/143, Loss: 0.0015305276028811932\n",
    "Epoch: 6/100, Batch: 85/143, Loss: 0.004588600248098373\n",
    "Current step: 472.0\n",
    "Epoch: 6/100, Batch: 86/143, Loss: 0.0031354553066194057\n",
    "Epoch: 6/100, Batch: 87/143, Loss: 0.0013227647868916392\n",
    "Current step: 473.0\n",
    "Epoch: 6/100, Batch: 88/143, Loss: 0.0014480268582701683\n",
    "Epoch: 6/100, Batch: 89/143, Loss: 0.0013931902358308434\n",
    "Current step: 474.0\n",
    "Epoch: 6/100, Batch: 90/143, Loss: 0.0010716532124206424\n",
    "Epoch: 6/100, Batch: 91/143, Loss: 0.0010826860088855028\n",
    "Current step: 475.0\n",
    "Epoch: 6/100, Batch: 92/143, Loss: 0.0014213152462616563\n",
    "Epoch: 6/100, Batch: 93/143, Loss: 0.0014392276061698794\n",
    "Current step: 476.0\n",
    "Epoch: 6/100, Batch: 94/143, Loss: 0.0013720400165766478\n",
    "Epoch: 6/100, Batch: 95/143, Loss: 0.0013730847276747227\n",
    "Current step: 477.0\n",
    "Epoch: 6/100, Batch: 96/143, Loss: 0.0010527480626478791\n",
    "Epoch: 6/100, Batch: 97/143, Loss: 0.0010783522156998515\n",
    "Current step: 478.0\n",
    "Epoch: 6/100, Batch: 98/143, Loss: 0.001096747349947691\n",
    "Epoch: 6/100, Batch: 99/143, Loss: 0.0009372607455588877\n",
    "Current step: 479.0\n",
    "Epoch: 6/100, Batch: 100/143, Loss: 0.0011995288077741861\n",
    "Epoch: 6/100, Batch: 101/143, Loss: 0.0012184911174699664\n",
    "Current step: 480.0\n",
    "Epoch: 6/100, Batch: 102/143, Loss: 0.004283019341528416\n",
    "Epoch: 6/100, Batch: 103/143, Loss: 0.004384188447147608\n",
    "Current step: 481.0\n",
    "Epoch: 6/100, Batch: 104/143, Loss: 0.0020460381638258696\n",
    "Epoch: 6/100, Batch: 105/143, Loss: 0.0020905695855617523\n",
    "Current step: 482.0\n",
    "Epoch: 6/100, Batch: 106/143, Loss: 0.0019096998730674386\n",
    "Epoch: 6/100, Batch: 107/143, Loss: 0.0019485179800540209\n",
    "Current step: 483.0\n",
    "Epoch: 6/100, Batch: 108/143, Loss: 0.0022519524209201336\n",
    "Epoch: 6/100, Batch: 109/143, Loss: 0.0022589326836168766\n",
    "Current step: 484.0\n",
    "Epoch: 6/100, Batch: 110/143, Loss: 0.0012346642324700952\n",
    "Epoch: 6/100, Batch: 111/143, Loss: 0.0017845750553533435\n",
    "Current step: 485.0\n",
    "Epoch: 6/100, Batch: 112/143, Loss: 0.0025304791051894426\n",
    "Epoch: 6/100, Batch: 113/143, Loss: 0.0015493209939450026\n",
    "Current step: 486.0\n",
    "Epoch: 6/100, Batch: 114/143, Loss: 0.0032543912529945374\n",
    "Epoch: 6/100, Batch: 115/143, Loss: 0.0017545341979712248\n",
    "Current step: 487.0\n",
    "Epoch: 6/100, Batch: 116/143, Loss: 0.002743850462138653\n",
    "Epoch: 6/100, Batch: 117/143, Loss: 0.0012481810990720987\n",
    "Current step: 488.0\n",
    "Epoch: 6/100, Batch: 118/143, Loss: 0.0011971784988418221\n",
    "Epoch: 6/100, Batch: 119/143, Loss: 0.0037349676713347435\n",
    "Current step: 489.0\n",
    "Epoch: 6/100, Batch: 120/143, Loss: 0.0024053212255239487\n",
    "Epoch: 6/100, Batch: 121/143, Loss: 0.003868824103847146\n",
    "Current step: 490.0\n",
    "Epoch: 6/100, Batch: 122/143, Loss: 0.003032044041901827\n",
    "Epoch: 6/100, Batch: 123/143, Loss: 0.0029978512320667505\n",
    "Current step: 491.0\n",
    "Epoch: 6/100, Batch: 124/143, Loss: 0.001367053366266191\n",
    "Epoch: 6/100, Batch: 125/143, Loss: 0.001336188637651503\n",
    "Current step: 492.0\n",
    "Epoch: 6/100, Batch: 126/143, Loss: 0.004315661266446114\n",
    "Epoch: 6/100, Batch: 127/143, Loss: 0.00429446529597044\n",
    "Current step: 493.0\n",
    "Epoch: 6/100, Batch: 128/143, Loss: 0.0012584119103848934\n",
    "Epoch: 6/100, Batch: 129/143, Loss: 0.0015073524555191398\n",
    "Current step: 494.0\n",
    "Epoch: 6/100, Batch: 130/143, Loss: 0.004612640477716923\n",
    "Epoch: 6/100, Batch: 131/143, Loss: 0.001988212810829282\n",
    "Current step: 495.0\n",
    "Epoch: 6/100, Batch: 132/143, Loss: 0.002625158056616783\n",
    "Epoch: 6/100, Batch: 133/143, Loss: 0.0026254551485180855\n",
    "Current step: 496.0\n",
    "Epoch: 6/100, Batch: 134/143, Loss: 0.0010143864201381803\n",
    "Epoch: 6/100, Batch: 135/143, Loss: 0.0009560044854879379\n",
    "Current step: 497.0\n",
    "Epoch: 6/100, Batch: 136/143, Loss: 0.0021966788917779922\n",
    "Epoch: 6/100, Batch: 137/143, Loss: 0.00244101881980896\n",
    "Current step: 498.0\n",
    "Epoch: 6/100, Batch: 138/143, Loss: 0.001968346768990159\n",
    "Epoch: 6/100, Batch: 139/143, Loss: 0.006041299551725388\n",
    "Current step: 499.0\n",
    "Epoch: 6/100, Batch: 140/143, Loss: 0.004816961474716663\n",
    "Epoch: 6/100, Batch: 141/143, Loss: 0.004874069709330797\n",
    "Current step: 500.0\n",
    "Epoch: 6/100, Batch: 142/143, Loss: 0.003377130487933755\n",
    "Epoch: 7/100, Batch: 0/143, Loss: 0.003357711248099804\n",
    "Epoch: 7/100, Batch: 1/143, Loss: 0.003352385712787509\n",
    "Current step: 501.5\n",
    "Epoch: 7/100, Batch: 2/143, Loss: 0.0009684410179033875\n",
    "Epoch: 7/100, Batch: 3/143, Loss: 0.0009758924716152251\n",
    "Current step: 502.5\n",
    "Epoch: 7/100, Batch: 4/143, Loss: 0.01389008853584528\n",
    "Epoch: 7/100, Batch: 5/143, Loss: 0.002773306565359235\n",
    "Current step: 503.5\n",
    "Epoch: 7/100, Batch: 6/143, Loss: 0.00241655670106411\n",
    "Epoch: 7/100, Batch: 7/143, Loss: 0.011852370575070381\n",
    "Current step: 504.5\n",
    "Epoch: 7/100, Batch: 8/143, Loss: 0.0011019206140190363\n",
    "Epoch: 7/100, Batch: 9/143, Loss: 0.0011914534261450171\n",
    "Current step: 505.5\n",
    "Epoch: 7/100, Batch: 10/143, Loss: 0.001988315489143133\n",
    "Epoch: 7/100, Batch: 11/143, Loss: 0.0021832974161952734\n",
    "Current step: 506.5\n",
    "Epoch: 7/100, Batch: 12/143, Loss: 0.0012549313250929117\n",
    "Epoch: 7/100, Batch: 13/143, Loss: 0.0013083775993436575\n",
    "Current step: 507.5\n",
    "Epoch: 7/100, Batch: 14/143, Loss: 0.0017578130355104804\n",
    "Epoch: 7/100, Batch: 15/143, Loss: 0.0016480740159749985\n",
    "Current step: 508.5\n",
    "Epoch: 7/100, Batch: 16/143, Loss: 0.001552318804897368\n",
    "Epoch: 7/100, Batch: 17/143, Loss: 0.001498220837675035\n",
    "Current step: 509.5\n",
    "Epoch: 7/100, Batch: 18/143, Loss: 0.001964263617992401\n",
    "Epoch: 7/100, Batch: 19/143, Loss: 0.001677252585068345\n",
    "Current step: 510.5\n",
    "Epoch: 7/100, Batch: 20/143, Loss: 0.0014301855117082596\n",
    "Epoch: 7/100, Batch: 21/143, Loss: 0.0019566728733479977\n",
    "Current step: 511.5\n",
    "Epoch: 7/100, Batch: 22/143, Loss: 0.0023634925018996\n",
    "Epoch: 7/100, Batch: 23/143, Loss: 0.0022791766095906496\n",
    "Current step: 512.5\n",
    "Epoch: 7/100, Batch: 24/143, Loss: 0.001315033994615078\n",
    "Epoch: 7/100, Batch: 25/143, Loss: 0.0012447293847799301\n",
    "Current step: 513.5\n",
    "Epoch: 7/100, Batch: 26/143, Loss: 0.0015289741568267345\n",
    "Epoch: 7/100, Batch: 27/143, Loss: 0.0008167208870872855\n",
    "Current step: 514.5\n",
    "Epoch: 7/100, Batch: 28/143, Loss: 0.0014104073634371161\n",
    "Epoch: 7/100, Batch: 29/143, Loss: 0.0011331234127283096\n",
    "Current step: 515.5\n",
    "Epoch: 7/100, Batch: 30/143, Loss: 0.0008554933010600507\n",
    "Epoch: 7/100, Batch: 31/143, Loss: 0.0008794011664576828\n",
    "Current step: 516.5\n",
    "Epoch: 7/100, Batch: 32/143, Loss: 0.0010537086054682732\n",
    "Epoch: 7/100, Batch: 33/143, Loss: 0.0010906629031524062\n",
    "Current step: 517.5\n",
    "Epoch: 7/100, Batch: 34/143, Loss: 0.0007433079299516976\n",
    "Epoch: 7/100, Batch: 35/143, Loss: 0.000860718369949609\n",
    "Current step: 518.5\n",
    "Epoch: 7/100, Batch: 36/143, Loss: 0.0010174884228035808\n",
    "Epoch: 7/100, Batch: 37/143, Loss: 0.0031528400722891092\n",
    "Current step: 519.5\n",
    "Epoch: 7/100, Batch: 38/143, Loss: 0.00579620897769928\n",
    "Epoch: 7/100, Batch: 39/143, Loss: 0.005724008660763502\n",
    "Current step: 520.5\n",
    "Epoch: 7/100, Batch: 40/143, Loss: 0.006342466454952955\n",
    "Epoch: 7/100, Batch: 41/143, Loss: 0.002440997399389744\n",
    "Current step: 521.5\n",
    "Epoch: 7/100, Batch: 42/143, Loss: 0.0009671942098066211\n",
    "Epoch: 7/100, Batch: 43/143, Loss: 0.002686741529032588\n",
    "Current step: 522.5\n",
    "Epoch: 7/100, Batch: 44/143, Loss: 0.002297047059983015\n",
    "Epoch: 7/100, Batch: 45/143, Loss: 0.002197328954935074\n",
    "Current step: 523.5\n",
    "Epoch: 7/100, Batch: 46/143, Loss: 0.004047466907650232\n",
    "Epoch: 7/100, Batch: 47/143, Loss: 0.012366801500320435\n",
    "Current step: 524.5\n",
    "Epoch: 7/100, Batch: 48/143, Loss: 0.0028204189147800207\n",
    "Epoch: 7/100, Batch: 49/143, Loss: 0.002822727430611849\n",
    "Current step: 525.5\n",
    "Epoch: 7/100, Batch: 50/143, Loss: 0.0012131351977586746\n",
    "Epoch: 7/100, Batch: 51/143, Loss: 0.0022740978747606277\n",
    "Current step: 526.5\n",
    "Epoch: 7/100, Batch: 52/143, Loss: 0.006323358044028282\n",
    "Epoch: 7/100, Batch: 53/143, Loss: 0.009841341525316238\n",
    "Current step: 527.5\n",
    "Epoch: 7/100, Batch: 54/143, Loss: 0.0169837586581707\n",
    "Epoch: 7/100, Batch: 55/143, Loss: 0.01693013310432434\n",
    "Current step: 528.5\n",
    "Epoch: 7/100, Batch: 56/143, Loss: 0.014272134751081467\n",
    "Epoch: 7/100, Batch: 57/143, Loss: 0.018275244161486626\n",
    "Current step: 529.5\n",
    "Epoch: 7/100, Batch: 58/143, Loss: 0.006427561864256859\n",
    "Epoch: 7/100, Batch: 59/143, Loss: 0.011363592930138111\n",
    "Current step: 530.5\n",
    "Epoch: 7/100, Batch: 60/143, Loss: 0.0015378990210592747\n",
    "Epoch: 7/100, Batch: 61/143, Loss: 0.003237144323065877\n",
    "Current step: 531.5\n",
    "Epoch: 7/100, Batch: 62/143, Loss: 0.007605801336467266\n",
    "Epoch: 7/100, Batch: 63/143, Loss: 0.007575801573693752\n",
    "Current step: 532.5\n",
    "Epoch: 7/100, Batch: 64/143, Loss: 0.016384048387408257\n",
    "Epoch: 7/100, Batch: 65/143, Loss: 0.01401812769472599\n",
    "Current step: 533.5\n",
    "Epoch: 7/100, Batch: 66/143, Loss: 0.02004525065422058\n",
    "Epoch: 7/100, Batch: 67/143, Loss: 0.019906410947442055\n",
    "Current step: 534.5\n",
    "Epoch: 7/100, Batch: 68/143, Loss: 0.006702268961817026\n",
    "Epoch: 7/100, Batch: 69/143, Loss: 0.006691636983305216\n",
    "Current step: 535.5\n",
    "Epoch: 7/100, Batch: 70/143, Loss: 0.003274592338129878\n",
    "Epoch: 7/100, Batch: 71/143, Loss: 0.006739103235304356\n",
    "Current step: 536.5\n",
    "Epoch: 7/100, Batch: 72/143, Loss: 0.012304863892495632\n",
    "Epoch: 7/100, Batch: 73/143, Loss: 0.012222875840961933\n",
    "Current step: 537.5\n",
    "Epoch: 7/100, Batch: 74/143, Loss: 0.012047694064676762\n",
    "Epoch: 7/100, Batch: 75/143, Loss: 0.012040620669722557\n",
    "Current step: 538.5\n",
    "Epoch: 7/100, Batch: 76/143, Loss: 0.025381557643413544\n",
    "Epoch: 7/100, Batch: 77/143, Loss: 0.025335531681776047\n",
    "Current step: 539.5\n",
    "Epoch: 7/100, Batch: 78/143, Loss: 0.01894829422235489\n",
    "Epoch: 7/100, Batch: 79/143, Loss: 0.019067587330937386\n",
    "Current step: 540.5\n",
    "Epoch: 7/100, Batch: 80/143, Loss: 0.007607146166265011\n",
    "Epoch: 7/100, Batch: 81/143, Loss: 0.00781058706343174\n",
    "Current step: 541.5\n",
    "Epoch: 7/100, Batch: 82/143, Loss: 0.005641114432364702\n",
    "Epoch: 7/100, Batch: 83/143, Loss: 0.005051067564636469\n",
    "Current step: 542.5\n",
    "Epoch: 7/100, Batch: 84/143, Loss: 0.003068694844841957\n",
    "Epoch: 7/100, Batch: 85/143, Loss: 0.00304091302677989\n",
    "Current step: 543.5\n",
    "Epoch: 7/100, Batch: 86/143, Loss: 0.004110909067094326\n",
    "Epoch: 7/100, Batch: 87/143, Loss: 0.004112128634005785\n",
    "Current step: 544.5\n",
    "Epoch: 7/100, Batch: 88/143, Loss: 0.009820999577641487\n",
    "Epoch: 7/100, Batch: 89/143, Loss: 0.005376079585403204\n",
    "Current step: 545.5\n",
    "Epoch: 7/100, Batch: 90/143, Loss: 0.008475781418383121\n",
    "Epoch: 7/100, Batch: 91/143, Loss: 0.004671233240514994\n",
    "Current step: 546.5\n",
    "Epoch: 7/100, Batch: 92/143, Loss: 0.002684521023184061\n",
    "Epoch: 7/100, Batch: 93/143, Loss: 0.0027309665456414223\n",
    "Current step: 547.5\n",
    "Epoch: 7/100, Batch: 94/143, Loss: 0.006902375724166632\n",
    "Epoch: 7/100, Batch: 95/143, Loss: 0.006845508236438036\n",
    "Current step: 548.5\n",
    "Epoch: 7/100, Batch: 96/143, Loss: 0.004969314206391573\n",
    "Epoch: 7/100, Batch: 97/143, Loss: 0.0049284896813333035\n",
    "Current step: 549.5\n",
    "Epoch: 7/100, Batch: 98/143, Loss: 0.0045564076863229275\n",
    "Epoch: 7/100, Batch: 99/143, Loss: 0.004102274309843779\n",
    "Current step: 550.5\n",
    "Epoch: 7/100, Batch: 100/143, Loss: 0.0029566786251962185\n",
    "Epoch: 7/100, Batch: 101/143, Loss: 0.00242514256387949\n",
    "Current step: 551.5\n",
    "Epoch: 7/100, Batch: 102/143, Loss: 0.0026308968663215637\n",
    "Epoch: 7/100, Batch: 103/143, Loss: 0.002604828914627433\n",
    "Current step: 552.5\n",
    "Epoch: 7/100, Batch: 104/143, Loss: 0.0019611597526818514\n",
    "Epoch: 7/100, Batch: 105/143, Loss: 0.001917205867357552\n",
    "Current step: 553.5\n",
    "Epoch: 7/100, Batch: 106/143, Loss: 0.0019099352648481727\n",
    "Epoch: 7/100, Batch: 107/143, Loss: 0.001858980511315167\n",
    "Current step: 554.5\n",
    "Epoch: 7/100, Batch: 108/143, Loss: 0.0014610389480367303\n",
    "Epoch: 7/100, Batch: 109/143, Loss: 0.004656071774661541\n",
    "Current step: 555.5\n",
    "Epoch: 7/100, Batch: 110/143, Loss: 0.0012484658509492874\n",
    "Epoch: 7/100, Batch: 111/143, Loss: 0.002915658988058567\n",
    "Current step: 556.5\n",
    "Epoch: 7/100, Batch: 112/143, Loss: 0.002115597715601325\n",
    "Epoch: 7/100, Batch: 113/143, Loss: 0.001654198276810348\n",
    "Current step: 557.5\n",
    "Epoch: 7/100, Batch: 114/143, Loss: 0.002152950270101428\n",
    "Epoch: 7/100, Batch: 115/143, Loss: 0.0018850318156182766\n",
    "Current step: 558.5\n",
    "Epoch: 7/100, Batch: 116/143, Loss: 0.0019160989904776216\n",
    "Epoch: 7/100, Batch: 117/143, Loss: 0.0018957487773150206\n",
    "Current step: 559.5\n",
    "Epoch: 7/100, Batch: 118/143, Loss: 0.0011084103025496006\n",
    "Epoch: 7/100, Batch: 119/143, Loss: 0.0010606830473989248\n",
    "Current step: 560.5\n",
    "Epoch: 7/100, Batch: 120/143, Loss: 0.0013635605573654175\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular expression to match the loss value\n",
    "loss_regex = re.compile(r'Loss: (\\d+\\.\\d+)')\n",
    "\n",
    "# Extract the loss values\n",
    "loss_values = [float(match.group(1)) for match in loss_regex.finditer(output)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1122"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(loss_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss values\n",
    "plt.plot(loss_values)\n",
    "plt.xlabel('Batch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
