{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the spectrograms previously made, we are going to create a Autoencoder which will create a \n",
    "# prediction mask that can be used to calculate the spatial audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "import sys\n",
    "sys.path.append('/workspace/fourth_year_project/Freqency Domain/')\n",
    "from SpectroDataset import SpectroDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, dropout_rate=0.5):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        def conv_block(in_channels, out_channels):\n",
    "            return nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "                nn.ReLU(inplace=True)\n",
    "            )   \n",
    "\n",
    "        self.encoder = nn.Sequential(\n",
    "            conv_block(1, 64),\n",
    "            nn.MaxPool2d(2, 2),  # 276 x 50\n",
    "            conv_block(64, 128),\n",
    "            nn.MaxPool2d(2, 2),  # 138 x 25\n",
    "        )\n",
    "\n",
    "        self.bottleneck = conv_block(128, 256)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2),  # 276 x 50\n",
    "            conv_block(128, 128),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),  # 552 x 101\n",
    "            conv_block(64, 64),\n",
    "        )\n",
    "\n",
    "        self.final_conv = nn.Conv2d(64, 1, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.encoder[0](x)\n",
    "        enc2 = self.encoder[2](self.encoder[1](enc1))\n",
    "        bottleneck = self.bottleneck(self.encoder[3](enc2))\n",
    "        dec1 = self.decoder[1](self.decoder[0](bottleneck))\n",
    "        dec2 = self.decoder[3](self.decoder[2](dec1))\n",
    "        return self.final_conv(dec2)\n",
    "\n",
    "\n",
    "    def train_loop(self, train_dataset, val_dataset, batch_size, epochs, lr):\n",
    "        dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True)\n",
    "        #optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        # Add momentum to the optimizer\n",
    "        optimizer = torch.optim.SGD(self.parameters(), lr=lr, momentum=0.9)\n",
    "        scheduler = lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "        criterion = nn.MSELoss()\n",
    "        #print(\"Starting training loop\")\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            #print(\"Epoch\", epoch)\n",
    "            for i, (left_stft, targets, _, inputs, angle, sr) in enumerate(dataloader):\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                outputs = self(inputs)\n",
    "\n",
    "                # The output from the model is a mask that represents the difference between the input and the target\n",
    "                # We can use the difference to get both left and right channels\n",
    "                output_stft = inputs * outputs\n",
    "                # Compare this to the target stft\n",
    "                \n",
    "\n",
    "                # This is the stft, so we take the istft\n",
    "                XD = torch.istft(x_d, n_fft=1024, hop_length=256, normalized=True, return_complex=False)\n",
    "\n",
    "                # \n",
    "                \n",
    "                \n",
    "\n",
    "\n",
    "                # Calculate the loss\n",
    "                # We are comparing the stft\n",
    "\n",
    "                loss = criterion(outputs, targets)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "             # Validation\n",
    "            self.eval()  # Set the model to evaluation mode\n",
    "            with torch.no_grad():  # No need to track gradients in validation\n",
    "                val_loss = 0\n",
    "                for i, (_, targets, _, inputs, angle, sr) in enumerate(val_loader):\n",
    "                    inputs, targets = inputs.cuda(), targets.cuda()\n",
    "                    outputs = self(inputs)\n",
    "                    val_loss += criterion(outputs, targets).item()\n",
    "                val_loss /= len(val_loader)  # Calculate average validation loss\n",
    "\n",
    "            scheduler.step()\n",
    "            if optimizer.param_groups[0]['lr'] < 0.0001:\n",
    "                optimizer.param_groups[0]['lr'] = 0.0001\n",
    "            print(f'Epoch: {epoch}, Training Loss: {loss.item()}, Validation Loss: {val_loss}, LR: {scheduler.get_last_lr()[0]}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SpectroDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17100"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(552, 101)\n",
      "(552, 101)\n",
      "(552, 101)\n"
     ]
    }
   ],
   "source": [
    "print(dataset[1][0].shape)\n",
    "print(dataset[3][1].shape)\n",
    "print(dataset[5][2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "\n",
    "# Define the proportions for the split\n",
    "train_proportion = 0.8 \n",
    "val_proportion = 0.1\n",
    "test_proportion = 0.1 \n",
    "\n",
    "# Calculate the number of samples for train, validation and test\n",
    "train_size = int(train_proportion * len(dataset))\n",
    "val_size = int(val_proportion * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = AutoEncoder().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv1d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "\n",
    "autoencoder.apply(weights_init)\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autoencoder.train()\n",
    "''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.train_loop(train_dataset, val_dataset, batch_size=32, epochs=100, lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
