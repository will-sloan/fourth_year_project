{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/fourth_year_project/HRTF Models/')\n",
    "\n",
    "from HRIRDataset import HRIRDataset\n",
    "from HRIRTransformerModel import HRIRTransformerModel\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofa_file = '/workspace/fourth_year_project/HRTF Models/sofa_hrtfs/RIEC_hrir_subject_001.sofa'\n",
    "hrir_dataset = HRIRDataset()\n",
    "for i in range(1,30):\n",
    "    hrir_dataset.load(sofa_file.replace('001', str(i).zfill(3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7128"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(hrir_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/venv_work/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "# model = MainModel()\n",
    "model = HRIRTransformerModel()\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "num_epochs = 100\n",
    "\n",
    "# Create the DataLoader\n",
    "#dataloader = DataLoader(hrir_dataset, batch_size=32, shuffle=True)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "\n",
    "# Split the dataset into a training, validation and test set\n",
    "# 0.8, 0.1, 0.1 respectively\n",
    "train_size = int(0.7 * len(hrir_dataset))\n",
    "val_size = int(0.2 * len(hrir_dataset))\n",
    "test_size = len(hrir_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(hrir_dataset, [train_size, val_size, test_size])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load('/workspace/fourth_year_project/HRTF Models/mask_models/model_4.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = '/workspace/fourth_year_project/HRTF Models/mask_models/'\n",
    "# Create it if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mask_values(tensor, mask_value, mask_prob):\n",
    "    \"\"\"\n",
    "    Masks values in a tensor with `mask_value` with probability `mask_prob`.\n",
    "\n",
    "    Args:\n",
    "    tensor (torch.Tensor): The input tensor.\n",
    "    mask_value (float): The value to use for masking.\n",
    "    mask_prob (float): The probability of masking each value in the tensor.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The masked tensor.\n",
    "    torch.Tensor: The original tensor before masking.\n",
    "    \"\"\"\n",
    "    # Create a mask tensor with the same size as the input tensor\n",
    "    # The mask tensor has values of 1 where the input tensor is to be masked\n",
    "    mask = torch.bernoulli(torch.full_like(tensor, mask_prob))\n",
    "\n",
    "    # Create a masked tensor by replacing values where the mask is 1 with `mask_value`\n",
    "    masked_tensor = tensor * (1 - mask) + mask * mask_value\n",
    "\n",
    "    return masked_tensor, tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the mask function\n",
    "tgt = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9, 10]).float()\n",
    "tgt, true_values = mask_values(tgt, -2, 0.2)\n",
    "print(tgt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# learning_rate = 0.01\n",
    "# Define the optimizer and loss function\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_function = nn.MSELoss(reduction='none')\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "percent_masked = 0.1\n",
    "factor = 0.003\n",
    "# myshape = (32, 2, 512)\n",
    "# Create a weight tensor that has higher values for the early part of the impulse response\n",
    "# weights = torch.ones_like(myshape)\n",
    "# weights[:, :200] *= 5  # Increase the weight for the first 200 samples\n",
    "# # # move to cuda\n",
    "# weights = weights.to(device)\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "# Loop over each epoch\n",
    "\n",
    "best_val_loss = 100000\n",
    "\n",
    "for epoch in range(1, num_epochs):\n",
    "    # Initialize the epoch loss\n",
    "    epoch_loss = 0.0\n",
    "    model.train()\n",
    "    # Loop over each batch\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Get the src and tgt sequences from the batch\n",
    "        src, _, angle = batch\n",
    "        \n",
    "        src, true_values = mask_values(src, -2, percent_masked)\n",
    "        mask = (src == -2).float()\n",
    "        # Masked values are weighted 10 times more\n",
    "        weights = mask * 9 + torch.ones_like(src)\n",
    "        weights = weights.to(device)\n",
    "        \n",
    "\n",
    "        # Move data to the same device as the model\n",
    "        src = src.to(device)\n",
    "        angle = angle.to(device)\n",
    "        true_values = true_values.to(device)\n",
    "        # print(src.shape, tgt.shape, angle.shape)\n",
    "        # convert to floats\n",
    "        angle = angle.float()\n",
    "        src = src.float()\n",
    "        true_values = true_values.float()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the model\n",
    "        output = model(src, angle, true_values)\n",
    "        \n",
    "        # remove the last feature dimension from output\n",
    "        # [batch_size, d_model, seq_length] --> [batch_size, d_model-1, seq_length]\n",
    "        output = output[:, :-1, :]\n",
    "        loss = loss_function(output, true_values)\n",
    "        loss = loss * weights\n",
    "        loss = loss.mean()\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the batch loss\n",
    "        epoch_loss += loss.item()\n",
    "    val_loss = 0\n",
    "    scheduler.step()\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            src, _, angle = batch\n",
    "            src = src.to(device)\n",
    "            src, true_values = mask_values(src, -2, percent_masked)\n",
    "            mask = (src == -2).float()\n",
    "            # Masked values are weighted 10 times more\n",
    "            weights = mask * 9 + torch.ones_like(src)\n",
    "            weights = weights.to(device)\n",
    "            angle = angle.to(device)\n",
    "            angle = angle.float()\n",
    "            src = src.float()\n",
    "            true_values = true_values.to(device)\n",
    "            true_values = true_values.float()\n",
    "            output = model(src, angle, true_values)\n",
    "            # remove the last feature dimension from output\n",
    "            output = output[:, :-1, :]\n",
    "            #print(\"Before loss val: \",output.shape, tgt.shape)\n",
    "            loss = loss_function(output, true_values)\n",
    "            loss = loss * weights\n",
    "            loss = loss.mean()\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        percent_masked += 0.001 # Add 1 %\n",
    "    # Print the average loss for this epoch\n",
    "    print(f'Epoch {epoch} | Training Loss: {epoch_loss / len(train_dataset)} | Validation Loss: {val_loss / len(val_dataset)} | Learning Rate: {scheduler.get_last_lr()} | Percentage Masked: {percent_masked} | Elements Masked: {int((percent_masked) * 512)}')\n",
    "    if epoch % 2 == 0:\n",
    "        torch.save(model.state_dict(), f'{target_folder}model_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Fine tune the model on sequence generation\n",
    "seq_model = SeqModel()\n",
    "seq_model.load_state_dict(torch.load('/workspace/fourth_year_project/HRTF Models/mask_models/model_98.pth'))\n",
    "seq_model = seq_model.to(device)\n",
    "seq_model.train()\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(seq_model.parameters())\n",
    "loss_function = nn.MSELoss()\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folder = '/workspace/fourth_year_project/HRTF Models/seq_models/'\n",
    "# Create it if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, num_epochs):\n",
    "    # Initialize the epoch loss\n",
    "    epoch_loss = 0.0\n",
    "    model.train()\n",
    "    # Loop over each batch\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Get the src and tgt sequences from the batch\n",
    "        src, tgt, angle = batch\n",
    "        # Move data to the same device as the model\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        angle = angle.to(device)\n",
    "        # convert to floats\n",
    "        angle = angle.float()\n",
    "        src = src.float()\n",
    "        tgt = tgt.float()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass through the model\n",
    "        output = model(src, angle, tgt)\n",
    "        \n",
    "        # remove the last feature dimension from output\n",
    "        # [batch_size, d_model, seq_length] --> [batch_size, d_model-1, seq_length]\n",
    "        output = output[:, :-1, :]\n",
    "        loss = loss_function(output, tgt)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the batch loss\n",
    "        epoch_loss += loss.item()\n",
    "    val_loss = 0\n",
    "    scheduler.step()\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            src, tgt, angle = batch\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            angle = angle.to(device)\n",
    "            angle = angle.float()\n",
    "            src = src.float()\n",
    "            tgt = tgt.float()\n",
    "            output = model(src, angle, tgt)\n",
    "            # remove the last feature dimension from output\n",
    "            output = output[:, :-1, :]\n",
    "            #print(\"Before loss val: \",output.shape, tgt.shape)\n",
    "            loss = loss_function(output, tgt)\n",
    "            val_loss += loss.item()\n",
    "    # Print the average loss for this epoch\n",
    "    print(f'Epoch {epoch} | Training Loss: {epoch_loss / len(train_dataset)} | Validation Loss: {val_loss / len(val_dataset)} | Learning Rate: {scheduler.get_last_lr()}')\n",
    "    if epoch % 2 == 0:\n",
    "        torch.save(model.state_dict(), f'{target_folder}model_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/venv_work/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "144\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/fourth_year_project/HRTF Models/')\n",
    "\n",
    "from HRIRDataset import HRIRDataset\n",
    "from MainModel import MainModel\n",
    "from AutoregressiveModel import AutoregressiveModel\n",
    "import matplotlib.pyplot as plt\n",
    "from MaskModel import MaskModel\n",
    "from SeqModel import SeqModel\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# Train FullSeqModel\n",
    "from FullSeqModel import FullSeqModel\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "\n",
    "full_seq_model = FullSeqModel()\n",
    "full_seq_model = full_seq_model.to(device)\n",
    "full_seq_model.train()\n",
    "# Define the optimizer and loss function\n",
    "optimizer = optim.Adam(full_seq_model.parameters())\n",
    "loss_function = nn.MSELoss()\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "# Load checkpoint\n",
    "full_seq_model.load_state_dict(torch.load('/workspace/fourth_year_project/HRTF Models/seq_models/model_98.pth'))\n",
    "\n",
    "# Make sure encoder is being trained\n",
    "full_seq_model.enable_grad()\n",
    "\n",
    "target_folder = '/workspace/fourth_year_project/HRTF Models/full_seq_models/'\n",
    "# Create it if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "sofa_file = '/workspace/fourth_year_project/HRTF Models/sofa_hrtfs/RIEC_hrir_subject_001.sofa'\n",
    "hrir_dataset = HRIRDataset()\n",
    "for i in range(1,3):\n",
    "    hrir_dataset.load(sofa_file.replace('001', str(i).zfill(3)))\n",
    "\n",
    "print(len(hrir_dataset))\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "num_epochs = 5\n",
    "\n",
    "\n",
    "# Split the dataset into a training, validation and test set\n",
    "# 0.8, 0.1, 0.1 respectively\n",
    "train_size = int(0.7 * len(hrir_dataset))\n",
    "val_size = int(0.2 * len(hrir_dataset))\n",
    "test_size = len(hrir_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(hrir_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "\n",
    "# model.load_state_dict(torch.load('/workspace/fourth_year_project/HRTF Models/mask_models/model_4.pth'))\n",
    "batch_size = 8\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "\n",
    "\n",
    "model = full_seq_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Batch 0 | Loss: 0.519118070602417\n",
      "Epoch 1 | Batch 1 | Loss: 0.6763975620269775\n",
      "Epoch 1 | Batch 2 | Loss: 0.5756906270980835\n",
      "Epoch 1 | Batch 3 | Loss: 0.5391711592674255\n",
      "Epoch 1 | Batch 4 | Loss: 0.536404013633728\n",
      "Epoch 1 | Batch 5 | Loss: 0.4305543303489685\n",
      "Epoch 1 | Batch 6 | Loss: 0.5170207619667053\n",
      "Epoch 1 | Batch 7 | Loss: 0.5018888115882874\n",
      "Epoch 1 | Batch 8 | Loss: 0.5224542021751404\n",
      "Epoch 1 | Batch 9 | Loss: 0.6725940108299255\n",
      "Epoch 1 | Batch 10 | Loss: 0.4114666283130646\n",
      "Epoch 1 | Batch 11 | Loss: 0.41564810276031494\n",
      "Epoch 1 | Batch 12 | Loss: 0.643868088722229\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_CUDA_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 95\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# Divide angle by 360 to get a value between 0 and 1\u001b[39;00m\n\u001b[1;32m     93\u001b[0m angle \u001b[38;5;241m=\u001b[39m angle \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m360\u001b[39m\n\u001b[0;32m---> 95\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mteacher_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;66;03m# remove the last feature dimension from output\u001b[39;00m\n\u001b[1;32m     97\u001b[0m output \u001b[38;5;241m=\u001b[39m output[:, :\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :]\n",
      "File \u001b[0;32m/workspace/venv_work/lib/python3.8/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/workspace/venv_work/lib/python3.8/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/fourth_year_project/HRTF Models/FullSeqModel.py:75\u001b[0m, in \u001b[0;36mFullSeqModel.forward\u001b[0;34m(self, src, angle, tgt, epoch, teacher_ratio)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tgt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;66;03m# [batch_size, 2, 512] --> [batch_size, 3, 512]\u001b[39;00m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# Do the same for tgt but set it to -1 since that isn't a real angle\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     constant_tgt \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull_like(angle, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 75\u001b[0m     tgt \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtgt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconstant_tgt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m     src \u001b[38;5;241m=\u001b[39m src\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     77\u001b[0m     tgt \u001b[38;5;241m=\u001b[39m tgt\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument tensors in method wrapper_CUDA_cat)"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(1, num_epochs):\n",
    "    # Initialize the epoch loss\n",
    "    epoch_loss = 0.0\n",
    "    model.train()\n",
    "    # Loop over half of the dataset\n",
    "    # indices = torch.randperm(dataset_size)\n",
    "\n",
    "    # Split the dataset into four parts\n",
    "    # half_size = dataset_size // 4\n",
    "    # first_half_indices = indices[:half_size]\n",
    "    # fhd = torch.utils.data.Subset(train_dataset, first_half_indices)\n",
    "    # dl = DataLoader(fhd, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Get the src and tgt sequences from the batch\n",
    "        src, tgt, angle = batch\n",
    "        # Move data to the same device as the model\n",
    "        src = src.to(device)\n",
    "        tgt = tgt.to(device)\n",
    "        angle = angle.to(device)\n",
    "        # convert to floats\n",
    "        angle = angle.float()\n",
    "        src = src.float()\n",
    "        tgt = tgt.float()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        # Forward pass through the model\n",
    "\n",
    "        # Standardize the input\n",
    "        src = (src - src.mean()) / src.std()\n",
    "        tgt = (tgt - tgt.mean()) / tgt.std()\n",
    "        # Divide angle by 360 to get a value between 0 and 1\n",
    "        angle = angle / 360\n",
    "\n",
    "        output = model(src, angle, tgt=tgt, teacher_ratio=0.5)\n",
    "        \n",
    "        # remove the last feature dimension from output\n",
    "        # [batch_size, d_model, seq_length] --> [batch_size, d_model-1, seq_length]\n",
    "        output = output[:, :-1, :]\n",
    "\n",
    "        \n",
    "        loss = loss_function(output, tgt)\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the batch loss\n",
    "        epoch_loss += loss.item()\n",
    "        print(f'Epoch {epoch} | Batch {i} | Loss: {loss.item()}')\n",
    "    val_loss = 0\n",
    "    scheduler.step()\n",
    "    # Validate the model when with and without tgt\n",
    "    # With tgt\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            src, tgt, angle = batch\n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            angle = angle.to(device)\n",
    "            angle = angle.float()\n",
    "            src = src.float()\n",
    "            tgt = tgt.float()\n",
    "\n",
    "            # Standardize the input\n",
    "            src = (src - src.mean()) / src.std()\n",
    "            tgt = (tgt - tgt.mean()) / tgt.std()\n",
    "            # Divide angle by 360 to get a value between 0 and 1\n",
    "            angle = angle / 360\n",
    "\n",
    "            output = model(src, angle, tgt=tgt, teacher_ratio=0.7)\n",
    "            # remove the last feature dimension from output\n",
    "            output = output[:, :-1, :]\n",
    "            #print(\"Before loss val: \",output.shape, tgt.shape)\n",
    "            loss = loss_function(output, tgt)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # without tgt\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            src, tgt, angle = batch\n",
    "            src = src.to(device)\n",
    "            angle = angle.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            tgt = tgt.float()\n",
    "            angle = angle.float()\n",
    "            src = src.float()\n",
    "\n",
    "            # Standardize the input\n",
    "            src = (src - src.mean()) / src.std()\n",
    "            tgt = (tgt - tgt.mean()) / tgt.std()\n",
    "            # Divide angle by 360 to get a value between 0 and 1\n",
    "            angle = angle / 360\n",
    "\n",
    "            output = model(src, angle, tgt=tgt, teacher_ratio=0.1)\n",
    "            # remove the last feature dimension from output\n",
    "            output = output[:, :-1, :]\n",
    "            #print(\"Before loss val: \",output.shape, tgt.shape)\n",
    "            loss = loss_function(output, tgt)\n",
    "            val_loss += loss.item()\n",
    "    # Print the average loss for this epoch\n",
    "    print(f'Epoch {epoch} | Training Loss: {epoch_loss / len(train_dataset)} | Validation (tgt): {val_loss / len(val_dataset)} | Validation (no tgt): {val_loss / len(val_dataset)} | Learning Rate: {scheduler.get_last_lr()}')\n",
    "    if epoch % 2 == 0:\n",
    "        torch.save(model.state_dict(), f'{target_folder}model_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
