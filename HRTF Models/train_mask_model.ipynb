{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspace/venv_work/lib/python3.8/site-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/workspace/fourth_year_project/HRTF Models/')\n",
    "\n",
    "from HRIRDataset import HRIRDataset\n",
    "from MainModel import MainModel\n",
    "from AutoregressiveModel import AutoregressiveModel\n",
    "import matplotlib.pyplot as plt\n",
    "from MaskModel import MaskModel\n",
    "from SeqModel import SeqModel\n",
    "sofa_file = '/workspace/fourth_year_project/HRTF Models/sofa_hrtfs/RIEC_hrir_subject_001.sofa'\n",
    "hrir_dataset = HRIRDataset()\n",
    "for i in range(1,100):\n",
    "    hrir_dataset.load(sofa_file.replace('001', str(i).zfill(3)))\n",
    "len(hrir_dataset)\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "# model = MainModel()\n",
    "model = MaskModel()\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "num_epochs = 100\n",
    "\n",
    "# Create the DataLoader\n",
    "#dataloader = DataLoader(hrir_dataset, batch_size=32, shuffle=True)\n",
    "device = torch.device('cuda')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "\n",
    "# Split the dataset into a training, validation and test set\n",
    "# 0.8, 0.1, 0.1 respectively\n",
    "train_size = int(0.7 * len(hrir_dataset))\n",
    "val_size = int(0.2 * len(hrir_dataset))\n",
    "test_size = len(hrir_dataset) - train_size - val_size\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(hrir_dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# model.load_state_dict(torch.load('/workspace/fourth_year_project/HRTF Models/mask_models/model_4.pth'))\n",
    "batch_size = 32\n",
    "\n",
    "dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True, num_workers=6)\n",
    "target_folder = '/workspace/fourth_year_project/HRTF Models/mask_models/'\n",
    "# Create it if it doesn't exist\n",
    "import os\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "def mask_values(tensor, mask_value, mask_prob):\n",
    "    \"\"\"\n",
    "    Masks values in a tensor with `mask_value` with probability `mask_prob`.\n",
    "\n",
    "    Args:\n",
    "    tensor (torch.Tensor): The input tensor.\n",
    "    mask_value (float): The value to use for masking.\n",
    "    mask_prob (float): The probability of masking each value in the tensor.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: The masked tensor.\n",
    "    torch.Tensor: The original tensor before masking.\n",
    "    \"\"\"\n",
    "    # Create a mask tensor with the same size as the input tensor\n",
    "    # The mask tensor has values of 1 where the input tensor is to be masked\n",
    "    mask = torch.bernoulli(torch.full_like(tensor, mask_prob))\n",
    "\n",
    "    # Create a masked tensor by replacing values where the mask is 1 with `mask_value`\n",
    "    masked_tensor = tensor * (1 - mask) + mask * mask_value\n",
    "\n",
    "    return masked_tensor, tensor\n",
    "\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# learning_rate = 0.01\n",
    "# Define the optimizer and loss function\n",
    "# optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "loss_function = nn.MSELoss(reduction='none')\n",
    "scheduler = StepLR(optimizer, step_size=30, gamma=0.1)\n",
    "\n",
    "# Set the model to training mode\n",
    "model.train()\n",
    "percent_masked = 0.1\n",
    "factor = 0.003\n",
    "# myshape = (32, 2, 512)\n",
    "# Create a weight tensor that has higher values for the early part of the impulse response\n",
    "# weights = torch.ones_like(myshape)\n",
    "# weights[:, :200] *= 5  # Increase the weight for the first 200 samples\n",
    "# # # move to cuda\n",
    "# weights = weights.to(device)\n",
    "# torch.autograd.set_detect_anomaly(True)\n",
    "# Loop over each epoch\n",
    "\n",
    "best_val_loss = 100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Training Loss: 0.4561279947657671 | Validation Loss: 0.4146750320053831 | Learning Rate: [0.001] | Percentage Masked: 0.101 | Elements Masked: 51\n",
      "Epoch 2 | Training Loss: 0.1831001012937679 | Validation Loss: 0.15277886579105604 | Learning Rate: [0.001] | Percentage Masked: 0.10200000000000001 | Elements Masked: 52\n",
      "Epoch 3 | Training Loss: 0.06362177504427685 | Validation Loss: 0.04996196721990957 | Learning Rate: [0.001] | Percentage Masked: 0.10300000000000001 | Elements Masked: 52\n",
      "Epoch 4 | Training Loss: 0.021274773133446594 | Validation Loss: 0.01871472668576531 | Learning Rate: [0.001] | Percentage Masked: 0.10400000000000001 | Elements Masked: 53\n",
      "Epoch 5 | Training Loss: 0.009784003837363947 | Validation Loss: 0.011501118172628168 | Learning Rate: [0.001] | Percentage Masked: 0.10500000000000001 | Elements Masked: 53\n",
      "Epoch 6 | Training Loss: 0.00745084709873713 | Validation Loss: 0.010405823747309221 | Learning Rate: [0.001] | Percentage Masked: 0.10600000000000001 | Elements Masked: 54\n",
      "Epoch 7 | Training Loss: 0.007116183465173955 | Validation Loss: 0.01029834263232265 | Learning Rate: [0.001] | Percentage Masked: 0.10700000000000001 | Elements Masked: 54\n",
      "Epoch 8 | Training Loss: 0.007056323886515461 | Validation Loss: 0.010288591854657666 | Learning Rate: [0.001] | Percentage Masked: 0.10800000000000001 | Elements Masked: 55\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, num_epochs):\n",
    "    # Initialize the epoch loss\n",
    "    epoch_loss = 0.0\n",
    "    model.train()\n",
    "    # Loop over each batch\n",
    "    for i, batch in enumerate(dataloader):\n",
    "        # Get the src and tgt sequences from the batch\n",
    "        src, _, angle = batch\n",
    "        \n",
    "        src, true_values = mask_values(src, -2, percent_masked)\n",
    "        mask = (src == -2).float()\n",
    "        # Masked values are weighted 4 times more\n",
    "        weights = mask * 3 + torch.ones_like(src)\n",
    "        weights = weights.to(device)\n",
    "        \n",
    "\n",
    "        # Move data to the same device as the model\n",
    "        src = src.to(device)\n",
    "        angle = angle.to(device)\n",
    "        true_values = true_values.to(device)\n",
    "        # print(src.shape, tgt.shape, angle.shape)\n",
    "        # convert to floats\n",
    "        angle = angle.float()\n",
    "        src = src.float()\n",
    "        true_values = true_values.float()\n",
    "\n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass through the model\n",
    "        output = model(src, angle, true_values)\n",
    "        \n",
    "        # remove the last feature dimension from output\n",
    "        # [batch_size, d_model, seq_length] --> [batch_size, d_model-1, seq_length]\n",
    "        output = output[:, :-1, :]\n",
    "        loss = loss_function(output, true_values)\n",
    "        loss = loss * weights\n",
    "        loss = loss.mean()\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update the weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumulate the batch loss\n",
    "        epoch_loss += loss.item()\n",
    "    val_loss = 0\n",
    "    scheduler.step()\n",
    "    # Validate the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(val_loader):\n",
    "            src, _, angle = batch\n",
    "            src = src.to(device)\n",
    "            src, true_values = mask_values(src, -2, percent_masked)\n",
    "            mask = (src == -2).float()\n",
    "            # Masked values are weighted 10 times more\n",
    "            weights = mask * 9 + torch.ones_like(src)\n",
    "            weights = weights.to(device)\n",
    "            angle = angle.to(device)\n",
    "            angle = angle.float()\n",
    "            src = src.float()\n",
    "            true_values = true_values.to(device)\n",
    "            true_values = true_values.float()\n",
    "            output = model(src, angle, true_values)\n",
    "            # remove the last feature dimension from output\n",
    "            output = output[:, :-1, :]\n",
    "            #print(\"Before loss val: \",output.shape, tgt.shape)\n",
    "            loss = loss_function(output, true_values)\n",
    "            loss = loss * weights\n",
    "            loss = loss.mean()\n",
    "            val_loss += loss.item()\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        percent_masked += 0.001 # Add 1 %\n",
    "    # Print the average loss for this epoch\n",
    "    print(f'Epoch {epoch} | Training Loss: {epoch_loss / len(dataloader)} | Validation Loss: {val_loss / len(val_loader)} | Learning Rate: {scheduler.get_last_lr()} | Percentage Masked: {percent_masked} | Elements Masked: {int((percent_masked) * 512)}')\n",
    "    if epoch % 2 == 0:\n",
    "        torch.save(model.state_dict(), f'{target_folder}model_{epoch}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
